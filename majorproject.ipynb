{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (6898, 75, 50, 1)\n",
      "Spectrograms, labels, and patient IDs saved to D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\\spectrograms\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from cryptography.hazmat.decrepit.ciphers.algorithms import TripleDES, Blowfish\n",
    "from cryptography.utils import CryptographyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=CryptographyDeprecationWarning)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf  # Use soundfile directly\n",
    "import librosa\n",
    "from scipy.signal import get_window\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "audio_dir = os.path.join(base_dir, \"audio_and_txt_files\")\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Create spectrograms directory if it doesn't exist\n",
    "os.makedirs(spectrograms_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "TARGET_SR = 4000\n",
    "FIXED_DURATION = 2.7\n",
    "SAMPLES_PER_CYCLE = int(TARGET_SR * FIXED_DURATION)\n",
    "\n",
    "# Preprocessing\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    return {\n",
    "        \"patient_id\": int(parts[0]),\n",
    "        \"recording_idx\": parts[1],\n",
    "        \"chest_location\": parts[2],\n",
    "        \"acquisition_mode\": parts[3],\n",
    "        \"equipment\": parts[4].replace('.wav', '')\n",
    "    }\n",
    "\n",
    "def preprocess_audio(audio_path, annotation_path):\n",
    "    # Use soundfile instead of librosa.load to avoid audioread\n",
    "    y, sr = sf.read(audio_path)\n",
    "    y_resampled = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)\n",
    "    annotations = pd.read_csv(annotation_path, delimiter='\\t', \n",
    "                              names=['start', 'end', 'crackles', 'wheezes'])\n",
    "    \n",
    "    cycles, labels, patient_ids = [], [], []\n",
    "    file_info = parse_filename(os.path.basename(audio_path))\n",
    "    \n",
    "    for _, row in annotations.iterrows():\n",
    "        start_sample = int(row['start'] * TARGET_SR)\n",
    "        end_sample = int(row['end'] * TARGET_SR)\n",
    "        cycle = y_resampled[start_sample:end_sample]\n",
    "        if len(cycle) > SAMPLES_PER_CYCLE:\n",
    "            cycle = cycle[:SAMPLES_PER_CYCLE]\n",
    "        elif len(cycle) < SAMPLES_PER_CYCLE:\n",
    "            cycle = np.pad(cycle, (0, SAMPLES_PER_CYCLE - len(cycle)), 'constant')\n",
    "        cycles.append(cycle)\n",
    "        if row['crackles'] == 1 and row['wheezes'] == 1:\n",
    "            labels.append(3)\n",
    "        elif row['crackles'] == 1:\n",
    "            labels.append(1)\n",
    "        elif row['wheezes'] == 1:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        patient_ids.append(file_info['patient_id'])\n",
    "    return np.array(cycles), np.array(labels), np.array(patient_ids)\n",
    "\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith('.wav')]\n",
    "cycles, labels, patient_ids = [], [], []\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    annotation_path = audio_path.replace('.wav', '.txt')\n",
    "    c, l, p = preprocess_audio(audio_path, annotation_path)\n",
    "    cycles.append(c)\n",
    "    labels.append(l)\n",
    "    patient_ids.append(p)\n",
    "\n",
    "cycles = np.concatenate(cycles, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "patient_ids = np.concatenate(patient_ids, axis=0)\n",
    "\n",
    "# Compute spectrograms\n",
    "def compute_spectrogram(cycle):\n",
    "    window = get_window('hann', 256)\n",
    "    stft = librosa.stft(cycle, n_fft=256, hop_length=128, window=window)\n",
    "    spectrogram = np.abs(stft) ** 2\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return spectrogram\n",
    "\n",
    "spectrograms = np.array([compute_spectrogram(cycle) for cycle in cycles])\n",
    "spectrograms_resized = np.array([resize(spec, (75, 50), mode='constant') for spec in spectrograms])\n",
    "spectrograms_resized = np.expand_dims(spectrograms_resized, axis=-1)\n",
    "\n",
    "print(\"Spectrograms shape:\", spectrograms_resized.shape)\n",
    "\n",
    "# Save to the spectrograms folder\n",
    "np.save(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"), spectrograms_resized)\n",
    "np.save(os.path.join(spectrograms_dir, \"labels.npy\"), labels)\n",
    "np.save(os.path.join(spectrograms_dir, \"patient_ids.npy\"), patient_ids)\n",
    "\n",
    "print(f\"Spectrograms, labels, and patient IDs saved to {spectrograms_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spectrograms shape: (6898, 75, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "spectrograms_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\\spectrograms\"\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "patient_ids = np.load(os.path.join(spectrograms_dir, \"patient_ids.npy\"))\n",
    "\n",
    "print(\"Loaded spectrograms shape:\", spectrograms_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (6898, 75, 50, 1)\n",
      "Labels shape: (6898,)\n",
      "Patient IDs shape: (6898,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Load spectrograms, labels, and patient IDs\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "patient_ids = np.load(os.path.join(spectrograms_dir, \"patient_ids.npy\"))\n",
    "\n",
    "print(\"Spectrograms shape:\", spectrograms_resized.shape)  # Should be (6898, 75, 50, 1)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Patient IDs shape:\", patient_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the first spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(spectrograms_resized[0, :, :, 0], cmap='viridis', aspect='auto', origin='lower')\n",
    "plt.title(f\"Spectrogram (Label: {['Normal', 'Crackles', 'Wheezes', 'Both'][labels[0]]})\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m36,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m54\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m93,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,420</span> (907.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,420\u001b[0m (907.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,100</span> (906.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,100\u001b[0m (906.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "from cryptography.hazmat.decrepit.ciphers.algorithms import TripleDES, Blowfish\n",
    "from cryptography.utils import CryptographyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=CryptographyDeprecationWarning)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import get_window\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, LSTM, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# (Previous preprocessing and spectrogram computation code here)\n",
    "# Assuming spectrograms_resized and labels are already defined\n",
    "\n",
    "# Define focal loss\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1.0 - y_pred, gamma) * y_true\n",
    "        return tf.reduce_mean(alpha * weight * cross_entropy)\n",
    "    return focal_loss_fn\n",
    "\n",
    "# Define model with Input layer\n",
    "def build_model(input_shape=(75, 50, 1), num_classes=4):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        Dropout(0.2),\n",
    "        Reshape((32, -1)),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = build_model()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(gamma=2.0), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "folds = list(gkf.split(spectrograms_resized, labels, groups=patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 134ms/step - accuracy: 0.5059 - loss: 0.0391 - val_accuracy: 0.6031 - val_loss: 0.0401\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.5427 - loss: 0.0362 - val_accuracy: 0.5918 - val_loss: 0.0394\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.5350 - loss: 0.0356 - val_accuracy: 0.6031 - val_loss: 0.0385\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.5486 - loss: 0.0345 - val_accuracy: 0.5709 - val_loss: 0.0393\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.5442 - loss: 0.0348 - val_accuracy: 0.5346 - val_loss: 0.0382\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 139ms/step - accuracy: 0.5434 - loss: 0.0351 - val_accuracy: 0.5419 - val_loss: 0.0393\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.5414 - loss: 0.0348 - val_accuracy: 0.5910 - val_loss: 0.0387\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.5474 - loss: 0.0345 - val_accuracy: 0.5362 - val_loss: 0.0372\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.5521 - loss: 0.0345 - val_accuracy: 0.5531 - val_loss: 0.0363\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.5640 - loss: 0.0332 - val_accuracy: 0.5242 - val_loss: 0.0355\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.5626 - loss: 0.0328 - val_accuracy: 0.4895 - val_loss: 0.0375\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.5635 - loss: 0.0316 - val_accuracy: 0.5443 - val_loss: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step - accuracy: 0.5761 - loss: 0.0306 - val_accuracy: 0.5548 - val_loss: 0.0344\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - accuracy: 0.5800 - loss: 0.0301 - val_accuracy: 0.5274 - val_loss: 0.0341\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 145ms/step - accuracy: 0.5943 - loss: 0.0288 - val_accuracy: 0.4960 - val_loss: 0.0359\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 110ms/step - accuracy: 0.5938 - loss: 0.0293 - val_accuracy: 0.5676 - val_loss: 0.0355\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.5951 - loss: 0.0281 - val_accuracy: 0.5411 - val_loss: 0.0354\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.6005 - loss: 0.0275 - val_accuracy: 0.5821 - val_loss: 0.0349\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.5927 - loss: 0.0270 - val_accuracy: 0.5314 - val_loss: 0.0344\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.6036 - loss: 0.0266 - val_accuracy: 0.5604 - val_loss: 0.0341\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.6003 - loss: 0.0260 - val_accuracy: 0.4936 - val_loss: 0.0364\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.6207 - loss: 0.0251 - val_accuracy: 0.5499 - val_loss: 0.0356\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.6035 - loss: 0.0259 - val_accuracy: 0.5668 - val_loss: 0.0366\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.6324 - loss: 0.0247 - val_accuracy: 0.5411 - val_loss: 0.0393\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.6261 - loss: 0.0247 - val_accuracy: 0.5974 - val_loss: 0.0359\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.6322 - loss: 0.0242 - val_accuracy: 0.5926 - val_loss: 0.0358\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.6339 - loss: 0.0229 - val_accuracy: 0.6031 - val_loss: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.6450 - loss: 0.0230 - val_accuracy: 0.5942 - val_loss: 0.0369\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.6438 - loss: 0.0228 - val_accuracy: 0.5765 - val_loss: 0.0380\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.6509 - loss: 0.0225 - val_accuracy: 0.5886 - val_loss: 0.0394\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.6580 - loss: 0.0221 - val_accuracy: 0.5813 - val_loss: 0.0406\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.6594 - loss: 0.0209 - val_accuracy: 0.5982 - val_loss: 0.0362\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.6600 - loss: 0.0214 - val_accuracy: 0.5644 - val_loss: 0.0387\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.6656 - loss: 0.0208 - val_accuracy: 0.5765 - val_loss: 0.0418\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 113ms/step - accuracy: 0.6739 - loss: 0.0200 - val_accuracy: 0.6095 - val_loss: 0.0393\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.6614 - loss: 0.0200 - val_accuracy: 0.5926 - val_loss: 0.0386\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.6706 - loss: 0.0202 - val_accuracy: 0.5894 - val_loss: 0.0411\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.6837 - loss: 0.0192 - val_accuracy: 0.5781 - val_loss: 0.0439\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 115ms/step - accuracy: 0.6675 - loss: 0.0192 - val_accuracy: 0.5580 - val_loss: 0.0431\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.6698 - loss: 0.0201 - val_accuracy: 0.5604 - val_loss: 0.0442\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 114ms/step - accuracy: 0.6838 - loss: 0.0183 - val_accuracy: 0.6103 - val_loss: 0.0394\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 114ms/step - accuracy: 0.7015 - loss: 0.0176 - val_accuracy: 0.5523 - val_loss: 0.0438\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - accuracy: 0.6908 - loss: 0.0185 - val_accuracy: 0.6039 - val_loss: 0.0408\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.6930 - loss: 0.0182 - val_accuracy: 0.6135 - val_loss: 0.0435\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - accuracy: 0.6898 - loss: 0.0173 - val_accuracy: 0.6071 - val_loss: 0.0403\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.6965 - loss: 0.0173 - val_accuracy: 0.5386 - val_loss: 0.0445\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.6950 - loss: 0.0164 - val_accuracy: 0.5894 - val_loss: 0.0458\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - accuracy: 0.6974 - loss: 0.0167 - val_accuracy: 0.5934 - val_loss: 0.0435\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.7121 - loss: 0.0157 - val_accuracy: 0.6055 - val_loss: 0.0437\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - accuracy: 0.7001 - loss: 0.0164 - val_accuracy: 0.5813 - val_loss: 0.0478\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "Fold 1 - Sensitivity: 0.3093, Specificity: 0.7766, Score: 0.5430, Accuracy: 0.3546\n",
      "Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 114ms/step - accuracy: 0.6638 - loss: 0.0222 - val_accuracy: 0.5878 - val_loss: 0.0396\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - accuracy: 0.6639 - loss: 0.0199 - val_accuracy: 0.5652 - val_loss: 0.0399\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - accuracy: 0.6802 - loss: 0.0188 - val_accuracy: 0.5725 - val_loss: 0.0405\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - accuracy: 0.6629 - loss: 0.0196 - val_accuracy: 0.5845 - val_loss: 0.0397\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - accuracy: 0.6766 - loss: 0.0184 - val_accuracy: 0.5652 - val_loss: 0.0433\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 105ms/step - accuracy: 0.6949 - loss: 0.0172 - val_accuracy: 0.5636 - val_loss: 0.0408\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - accuracy: 0.6959 - loss: 0.0175 - val_accuracy: 0.5556 - val_loss: 0.0458\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - accuracy: 0.6950 - loss: 0.0172 - val_accuracy: 0.5789 - val_loss: 0.0432\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 113ms/step - accuracy: 0.6910 - loss: 0.0171 - val_accuracy: 0.5886 - val_loss: 0.0430\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 115ms/step - accuracy: 0.6933 - loss: 0.0173 - val_accuracy: 0.5483 - val_loss: 0.0436\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 115ms/step - accuracy: 0.6873 - loss: 0.0158 - val_accuracy: 0.5628 - val_loss: 0.0452\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - accuracy: 0.7174 - loss: 0.0152 - val_accuracy: 0.5652 - val_loss: 0.0509\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - accuracy: 0.6841 - loss: 0.0173 - val_accuracy: 0.5668 - val_loss: 0.0397\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - accuracy: 0.7060 - loss: 0.0162 - val_accuracy: 0.5443 - val_loss: 0.0438\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.6953 - loss: 0.0152 - val_accuracy: 0.5644 - val_loss: 0.0484\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.7243 - loss: 0.0149 - val_accuracy: 0.5451 - val_loss: 0.0437\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7190 - loss: 0.0143 - val_accuracy: 0.5789 - val_loss: 0.0447\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.7182 - loss: 0.0156 - val_accuracy: 0.5757 - val_loss: 0.0443\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7123 - loss: 0.0151 - val_accuracy: 0.5749 - val_loss: 0.0444\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.7181 - loss: 0.0141 - val_accuracy: 0.5459 - val_loss: 0.0497\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.7108 - loss: 0.0138 - val_accuracy: 0.5717 - val_loss: 0.0463\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.7236 - loss: 0.0133 - val_accuracy: 0.5757 - val_loss: 0.0448\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.7267 - loss: 0.0135 - val_accuracy: 0.5386 - val_loss: 0.0471\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7383 - loss: 0.0130 - val_accuracy: 0.5467 - val_loss: 0.0510\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7179 - loss: 0.0142 - val_accuracy: 0.5636 - val_loss: 0.0483\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7461 - loss: 0.0128 - val_accuracy: 0.5805 - val_loss: 0.0471\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7303 - loss: 0.0124 - val_accuracy: 0.5564 - val_loss: 0.0492\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7481 - loss: 0.0128 - val_accuracy: 0.5548 - val_loss: 0.0470\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.7433 - loss: 0.0129 - val_accuracy: 0.5620 - val_loss: 0.0455\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7405 - loss: 0.0118 - val_accuracy: 0.5733 - val_loss: 0.0485\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7428 - loss: 0.0126 - val_accuracy: 0.6031 - val_loss: 0.0509\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7371 - loss: 0.0121 - val_accuracy: 0.5612 - val_loss: 0.0480\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7402 - loss: 0.0116 - val_accuracy: 0.5676 - val_loss: 0.0518\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7511 - loss: 0.0116 - val_accuracy: 0.5403 - val_loss: 0.0515\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7537 - loss: 0.0114 - val_accuracy: 0.5725 - val_loss: 0.0558\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7596 - loss: 0.0113 - val_accuracy: 0.5499 - val_loss: 0.0513\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.7548 - loss: 0.0114 - val_accuracy: 0.5910 - val_loss: 0.0524\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.7565 - loss: 0.0106 - val_accuracy: 0.5443 - val_loss: 0.0545\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7645 - loss: 0.0106 - val_accuracy: 0.5121 - val_loss: 0.0590\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7573 - loss: 0.0108 - val_accuracy: 0.5612 - val_loss: 0.0548\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7683 - loss: 0.0102 - val_accuracy: 0.5837 - val_loss: 0.0550\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7659 - loss: 0.0110 - val_accuracy: 0.5612 - val_loss: 0.0540\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7773 - loss: 0.0102 - val_accuracy: 0.5564 - val_loss: 0.0544\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.7795 - loss: 0.0094 - val_accuracy: 0.5837 - val_loss: 0.0557\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7820 - loss: 0.0100 - val_accuracy: 0.5700 - val_loss: 0.0556\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.7782 - loss: 0.0100 - val_accuracy: 0.5757 - val_loss: 0.0594\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7758 - loss: 0.0099 - val_accuracy: 0.5741 - val_loss: 0.0565\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7601 - loss: 0.0110 - val_accuracy: 0.5668 - val_loss: 0.0623\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7713 - loss: 0.0105 - val_accuracy: 0.5515 - val_loss: 0.0568\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7833 - loss: 0.0091 - val_accuracy: 0.5620 - val_loss: 0.0572\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "Fold 2 - Sensitivity: 0.5094, Specificity: 0.8352, Score: 0.6723, Accuracy: 0.6816\n",
      "Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7745 - loss: 0.0118 - val_accuracy: 0.5829 - val_loss: 0.0470\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7584 - loss: 0.0119 - val_accuracy: 0.5684 - val_loss: 0.0551\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.7775 - loss: 0.0107 - val_accuracy: 0.5870 - val_loss: 0.0485\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7803 - loss: 0.0109 - val_accuracy: 0.5845 - val_loss: 0.0484\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7630 - loss: 0.0106 - val_accuracy: 0.6111 - val_loss: 0.0483\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.7752 - loss: 0.0100 - val_accuracy: 0.5709 - val_loss: 0.0540\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.7775 - loss: 0.0102 - val_accuracy: 0.5668 - val_loss: 0.0492\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.7798 - loss: 0.0098 - val_accuracy: 0.5684 - val_loss: 0.0550\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.7835 - loss: 0.0091 - val_accuracy: 0.5878 - val_loss: 0.0544\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.7937 - loss: 0.0091 - val_accuracy: 0.5725 - val_loss: 0.0548\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7899 - loss: 0.0092 - val_accuracy: 0.5853 - val_loss: 0.0568\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.7866 - loss: 0.0090 - val_accuracy: 0.5990 - val_loss: 0.0547\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8024 - loss: 0.0094 - val_accuracy: 0.5725 - val_loss: 0.0521\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7899 - loss: 0.0086 - val_accuracy: 0.5443 - val_loss: 0.0612\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.7985 - loss: 0.0086 - val_accuracy: 0.6103 - val_loss: 0.0566\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.7931 - loss: 0.0085 - val_accuracy: 0.5668 - val_loss: 0.0574\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8161 - loss: 0.0086 - val_accuracy: 0.5773 - val_loss: 0.0610\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.8172 - loss: 0.0080 - val_accuracy: 0.5684 - val_loss: 0.0590\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.8091 - loss: 0.0081 - val_accuracy: 0.5588 - val_loss: 0.0580\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.8070 - loss: 0.0082 - val_accuracy: 0.5580 - val_loss: 0.0668\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.8178 - loss: 0.0079 - val_accuracy: 0.5725 - val_loss: 0.0560\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.8016 - loss: 0.0085 - val_accuracy: 0.5757 - val_loss: 0.0565\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.8061 - loss: 0.0080 - val_accuracy: 0.5548 - val_loss: 0.0589\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.8103 - loss: 0.0082 - val_accuracy: 0.5853 - val_loss: 0.0585\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8010 - loss: 0.0083 - val_accuracy: 0.5966 - val_loss: 0.0560\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8190 - loss: 0.0083 - val_accuracy: 0.5878 - val_loss: 0.0557\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.8300 - loss: 0.0076 - val_accuracy: 0.5612 - val_loss: 0.0530\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.8335 - loss: 0.0074 - val_accuracy: 0.5990 - val_loss: 0.0533\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8342 - loss: 0.0075 - val_accuracy: 0.5652 - val_loss: 0.0582\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.8307 - loss: 0.0075 - val_accuracy: 0.5395 - val_loss: 0.0605\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.8291 - loss: 0.0073 - val_accuracy: 0.6047 - val_loss: 0.0607\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.8284 - loss: 0.0072 - val_accuracy: 0.5813 - val_loss: 0.0598\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.8251 - loss: 0.0075 - val_accuracy: 0.5709 - val_loss: 0.0652\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.8165 - loss: 0.0079 - val_accuracy: 0.5725 - val_loss: 0.0581\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.8339 - loss: 0.0072 - val_accuracy: 0.5878 - val_loss: 0.0612\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8354 - loss: 0.0065 - val_accuracy: 0.5862 - val_loss: 0.0619\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.8394 - loss: 0.0069 - val_accuracy: 0.5733 - val_loss: 0.0652\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8502 - loss: 0.0068 - val_accuracy: 0.5604 - val_loss: 0.0582\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.8349 - loss: 0.0076 - val_accuracy: 0.5878 - val_loss: 0.0610\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.8369 - loss: 0.0068 - val_accuracy: 0.6087 - val_loss: 0.0684\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8527 - loss: 0.0065 - val_accuracy: 0.6216 - val_loss: 0.0573\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8525 - loss: 0.0063 - val_accuracy: 0.5878 - val_loss: 0.0606\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8444 - loss: 0.0067 - val_accuracy: 0.6151 - val_loss: 0.0594\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.8449 - loss: 0.0067 - val_accuracy: 0.5853 - val_loss: 0.0622\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8417 - loss: 0.0066 - val_accuracy: 0.6006 - val_loss: 0.0643\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8523 - loss: 0.0065 - val_accuracy: 0.5604 - val_loss: 0.0637\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.8547 - loss: 0.0065 - val_accuracy: 0.6143 - val_loss: 0.0642\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8466 - loss: 0.0064 - val_accuracy: 0.5813 - val_loss: 0.0637\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8622 - loss: 0.0060 - val_accuracy: 0.5451 - val_loss: 0.0732\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8607 - loss: 0.0057 - val_accuracy: 0.5717 - val_loss: 0.0610\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Fold 3 - Sensitivity: 0.6504, Specificity: 0.8868, Score: 0.7686, Accuracy: 0.6773\n",
      "Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8277 - loss: 0.0079 - val_accuracy: 0.5853 - val_loss: 0.0540\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.8591 - loss: 0.0070 - val_accuracy: 0.5588 - val_loss: 0.0637\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.8640 - loss: 0.0065 - val_accuracy: 0.5757 - val_loss: 0.0593\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.8516 - loss: 0.0069 - val_accuracy: 0.6143 - val_loss: 0.0644\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8577 - loss: 0.0066 - val_accuracy: 0.5717 - val_loss: 0.0662\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8520 - loss: 0.0064 - val_accuracy: 0.5668 - val_loss: 0.0617\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.8531 - loss: 0.0064 - val_accuracy: 0.6047 - val_loss: 0.0647\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8682 - loss: 0.0058 - val_accuracy: 0.5942 - val_loss: 0.0694\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.8648 - loss: 0.0062 - val_accuracy: 0.5757 - val_loss: 0.0644\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.8779 - loss: 0.0054 - val_accuracy: 0.5805 - val_loss: 0.0608\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.8715 - loss: 0.0061 - val_accuracy: 0.5942 - val_loss: 0.0642\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8609 - loss: 0.0067 - val_accuracy: 0.6135 - val_loss: 0.0657\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8691 - loss: 0.0060 - val_accuracy: 0.5789 - val_loss: 0.0675\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8550 - loss: 0.0068 - val_accuracy: 0.5773 - val_loss: 0.0660\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.8719 - loss: 0.0056 - val_accuracy: 0.6055 - val_loss: 0.0625\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.8818 - loss: 0.0054 - val_accuracy: 0.5781 - val_loss: 0.0636\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8784 - loss: 0.0053 - val_accuracy: 0.5870 - val_loss: 0.0666\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8816 - loss: 0.0057 - val_accuracy: 0.5757 - val_loss: 0.0637\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.8962 - loss: 0.0047 - val_accuracy: 0.5588 - val_loss: 0.0589\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8765 - loss: 0.0055 - val_accuracy: 0.5684 - val_loss: 0.0630\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.8834 - loss: 0.0056 - val_accuracy: 0.5765 - val_loss: 0.0626\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8616 - loss: 0.0059 - val_accuracy: 0.5628 - val_loss: 0.0654\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8998 - loss: 0.0044 - val_accuracy: 0.5942 - val_loss: 0.0669\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8954 - loss: 0.0045 - val_accuracy: 0.5741 - val_loss: 0.0756\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9028 - loss: 0.0049 - val_accuracy: 0.5733 - val_loss: 0.0657\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.8812 - loss: 0.0048 - val_accuracy: 0.5966 - val_loss: 0.0708\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8879 - loss: 0.0052 - val_accuracy: 0.5966 - val_loss: 0.0654\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 131ms/step - accuracy: 0.8890 - loss: 0.0050 - val_accuracy: 0.5725 - val_loss: 0.0679\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8890 - loss: 0.0059 - val_accuracy: 0.5910 - val_loss: 0.0670\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8823 - loss: 0.0051 - val_accuracy: 0.5483 - val_loss: 0.0626\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.8998 - loss: 0.0044 - val_accuracy: 0.6031 - val_loss: 0.0754\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8868 - loss: 0.0051 - val_accuracy: 0.5886 - val_loss: 0.0719\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8888 - loss: 0.0047 - val_accuracy: 0.5588 - val_loss: 0.0738\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.8944 - loss: 0.0047 - val_accuracy: 0.5580 - val_loss: 0.0640\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.8995 - loss: 0.0046 - val_accuracy: 0.5813 - val_loss: 0.0655\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8940 - loss: 0.0047 - val_accuracy: 0.5636 - val_loss: 0.0665\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.8976 - loss: 0.0047 - val_accuracy: 0.5934 - val_loss: 0.0721\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9012 - loss: 0.0044 - val_accuracy: 0.5950 - val_loss: 0.0761\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9024 - loss: 0.0041 - val_accuracy: 0.5548 - val_loss: 0.0694\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9007 - loss: 0.0045 - val_accuracy: 0.5862 - val_loss: 0.0757\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.9106 - loss: 0.0041 - val_accuracy: 0.5773 - val_loss: 0.0710\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9117 - loss: 0.0040 - val_accuracy: 0.6039 - val_loss: 0.0742\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9092 - loss: 0.0044 - val_accuracy: 0.5459 - val_loss: 0.0715\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9116 - loss: 0.0038 - val_accuracy: 0.5749 - val_loss: 0.0757\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9025 - loss: 0.0047 - val_accuracy: 0.5676 - val_loss: 0.0665\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9087 - loss: 0.0045 - val_accuracy: 0.5733 - val_loss: 0.0722\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9151 - loss: 0.0040 - val_accuracy: 0.5725 - val_loss: 0.0740\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9080 - loss: 0.0040 - val_accuracy: 0.5636 - val_loss: 0.0724\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - accuracy: 0.9066 - loss: 0.0041 - val_accuracy: 0.5958 - val_loss: 0.0713\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9213 - loss: 0.0040 - val_accuracy: 0.5684 - val_loss: 0.0830\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Fold 4 - Sensitivity: 0.6974, Specificity: 0.8764, Score: 0.7869, Accuracy: 0.7149\n",
      "Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.8896 - loss: 0.0058 - val_accuracy: 0.6208 - val_loss: 0.0686\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.8961 - loss: 0.0047 - val_accuracy: 0.5692 - val_loss: 0.0660\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.8958 - loss: 0.0049 - val_accuracy: 0.5829 - val_loss: 0.0676\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.8854 - loss: 0.0048 - val_accuracy: 0.6135 - val_loss: 0.0667\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.8993 - loss: 0.0046 - val_accuracy: 0.6014 - val_loss: 0.0686\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.8956 - loss: 0.0048 - val_accuracy: 0.5749 - val_loss: 0.0691\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.8834 - loss: 0.0050 - val_accuracy: 0.5950 - val_loss: 0.0667\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9085 - loss: 0.0041 - val_accuracy: 0.5813 - val_loss: 0.0752\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9104 - loss: 0.0039 - val_accuracy: 0.5733 - val_loss: 0.0798\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9069 - loss: 0.0043 - val_accuracy: 0.6079 - val_loss: 0.0709\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9090 - loss: 0.0040 - val_accuracy: 0.5805 - val_loss: 0.0670\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.9183 - loss: 0.0037 - val_accuracy: 0.6047 - val_loss: 0.0715\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9125 - loss: 0.0037 - val_accuracy: 0.6232 - val_loss: 0.0709\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9124 - loss: 0.0042 - val_accuracy: 0.5926 - val_loss: 0.0695\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9209 - loss: 0.0037 - val_accuracy: 0.6079 - val_loss: 0.0810\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9200 - loss: 0.0038 - val_accuracy: 0.5902 - val_loss: 0.0735\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9119 - loss: 0.0041 - val_accuracy: 0.5572 - val_loss: 0.0741\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9152 - loss: 0.0039 - val_accuracy: 0.5974 - val_loss: 0.0739\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9210 - loss: 0.0036 - val_accuracy: 0.6063 - val_loss: 0.0729\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9276 - loss: 0.0032 - val_accuracy: 0.5700 - val_loss: 0.0779\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9253 - loss: 0.0035 - val_accuracy: 0.6095 - val_loss: 0.0726\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9184 - loss: 0.0036 - val_accuracy: 0.6167 - val_loss: 0.0764\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9257 - loss: 0.0033 - val_accuracy: 0.5749 - val_loss: 0.0749\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9134 - loss: 0.0040 - val_accuracy: 0.5741 - val_loss: 0.0750\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9229 - loss: 0.0038 - val_accuracy: 0.6079 - val_loss: 0.0749\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9207 - loss: 0.0035 - val_accuracy: 0.6353 - val_loss: 0.0758\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9274 - loss: 0.0035 - val_accuracy: 0.5789 - val_loss: 0.0723\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9247 - loss: 0.0034 - val_accuracy: 0.5958 - val_loss: 0.0716\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9380 - loss: 0.0030 - val_accuracy: 0.5636 - val_loss: 0.0757\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9198 - loss: 0.0034 - val_accuracy: 0.5821 - val_loss: 0.0738\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9348 - loss: 0.0028 - val_accuracy: 0.6095 - val_loss: 0.0755\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9398 - loss: 0.0031 - val_accuracy: 0.5789 - val_loss: 0.0745\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9358 - loss: 0.0031 - val_accuracy: 0.5668 - val_loss: 0.0813\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9309 - loss: 0.0029 - val_accuracy: 0.6232 - val_loss: 0.0788\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9333 - loss: 0.0030 - val_accuracy: 0.5620 - val_loss: 0.0807\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9271 - loss: 0.0037 - val_accuracy: 0.5298 - val_loss: 0.0679\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9401 - loss: 0.0028 - val_accuracy: 0.5797 - val_loss: 0.0744\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9423 - loss: 0.0026 - val_accuracy: 0.5821 - val_loss: 0.0791\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9351 - loss: 0.0031 - val_accuracy: 0.5717 - val_loss: 0.0753\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9368 - loss: 0.0029 - val_accuracy: 0.6208 - val_loss: 0.0796\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9323 - loss: 0.0030 - val_accuracy: 0.5918 - val_loss: 0.0797\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9395 - loss: 0.0027 - val_accuracy: 0.5998 - val_loss: 0.0767\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9460 - loss: 0.0025 - val_accuracy: 0.6184 - val_loss: 0.0785\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - accuracy: 0.9389 - loss: 0.0028 - val_accuracy: 0.5910 - val_loss: 0.0785\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9376 - loss: 0.0027 - val_accuracy: 0.6006 - val_loss: 0.0826\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9417 - loss: 0.0031 - val_accuracy: 0.6006 - val_loss: 0.0813\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9441 - loss: 0.0024 - val_accuracy: 0.6127 - val_loss: 0.0857\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9339 - loss: 0.0036 - val_accuracy: 0.5837 - val_loss: 0.0804\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9418 - loss: 0.0031 - val_accuracy: 0.5515 - val_loss: 0.0798\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9479 - loss: 0.0023 - val_accuracy: 0.5813 - val_loss: 0.0831\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "Fold 5 - Sensitivity: 0.8542, Specificity: 0.9098, Score: 0.8820, Accuracy: 0.8072\n",
      "Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9315 - loss: 0.0034 - val_accuracy: 0.6433 - val_loss: 0.0720\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9377 - loss: 0.0030 - val_accuracy: 0.6562 - val_loss: 0.0738\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9343 - loss: 0.0033 - val_accuracy: 0.6159 - val_loss: 0.0700\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9361 - loss: 0.0031 - val_accuracy: 0.6433 - val_loss: 0.0710\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9432 - loss: 0.0027 - val_accuracy: 0.6481 - val_loss: 0.0739\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9437 - loss: 0.0028 - val_accuracy: 0.6087 - val_loss: 0.0708\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9369 - loss: 0.0030 - val_accuracy: 0.6329 - val_loss: 0.0768\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9397 - loss: 0.0028 - val_accuracy: 0.6143 - val_loss: 0.0731\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9315 - loss: 0.0032 - val_accuracy: 0.6449 - val_loss: 0.0790\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9456 - loss: 0.0024 - val_accuracy: 0.6167 - val_loss: 0.0718\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9454 - loss: 0.0026 - val_accuracy: 0.6095 - val_loss: 0.0697\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9347 - loss: 0.0030 - val_accuracy: 0.6159 - val_loss: 0.0726\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9542 - loss: 0.0022 - val_accuracy: 0.6208 - val_loss: 0.0683\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9524 - loss: 0.0024 - val_accuracy: 0.6055 - val_loss: 0.0734\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9509 - loss: 0.0026 - val_accuracy: 0.5982 - val_loss: 0.0764\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9382 - loss: 0.0030 - val_accuracy: 0.6296 - val_loss: 0.0711\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9386 - loss: 0.0028 - val_accuracy: 0.6224 - val_loss: 0.0737\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9409 - loss: 0.0026 - val_accuracy: 0.6232 - val_loss: 0.0709\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9353 - loss: 0.0031 - val_accuracy: 0.6055 - val_loss: 0.0742\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9567 - loss: 0.0022 - val_accuracy: 0.6320 - val_loss: 0.0755\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9428 - loss: 0.0028 - val_accuracy: 0.6103 - val_loss: 0.0860\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9425 - loss: 0.0026 - val_accuracy: 0.6079 - val_loss: 0.0704\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.9424 - loss: 0.0026 - val_accuracy: 0.5862 - val_loss: 0.0761\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9503 - loss: 0.0023 - val_accuracy: 0.5990 - val_loss: 0.0762\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9467 - loss: 0.0025 - val_accuracy: 0.6353 - val_loss: 0.0746\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9471 - loss: 0.0025 - val_accuracy: 0.5966 - val_loss: 0.0762\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9505 - loss: 0.0024 - val_accuracy: 0.6240 - val_loss: 0.0802\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9522 - loss: 0.0025 - val_accuracy: 0.6071 - val_loss: 0.0721\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9408 - loss: 0.0030 - val_accuracy: 0.5845 - val_loss: 0.0775\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9539 - loss: 0.0022 - val_accuracy: 0.6417 - val_loss: 0.0824\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9583 - loss: 0.0023 - val_accuracy: 0.5813 - val_loss: 0.0859\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9517 - loss: 0.0023 - val_accuracy: 0.6345 - val_loss: 0.0797\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9562 - loss: 0.0020 - val_accuracy: 0.6151 - val_loss: 0.0820\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9541 - loss: 0.0023 - val_accuracy: 0.6047 - val_loss: 0.0798\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9491 - loss: 0.0024 - val_accuracy: 0.6264 - val_loss: 0.0768\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9402 - loss: 0.0028 - val_accuracy: 0.6167 - val_loss: 0.0874\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9494 - loss: 0.0025 - val_accuracy: 0.6071 - val_loss: 0.0799\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9535 - loss: 0.0020 - val_accuracy: 0.5998 - val_loss: 0.0754\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9583 - loss: 0.0021 - val_accuracy: 0.5837 - val_loss: 0.0820\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9491 - loss: 0.0027 - val_accuracy: 0.5950 - val_loss: 0.0802\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9583 - loss: 0.0022 - val_accuracy: 0.6304 - val_loss: 0.0848\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9585 - loss: 0.0022 - val_accuracy: 0.6087 - val_loss: 0.0828\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9579 - loss: 0.0021 - val_accuracy: 0.5644 - val_loss: 0.0756\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9448 - loss: 0.0027 - val_accuracy: 0.6304 - val_loss: 0.0741\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9599 - loss: 0.0020 - val_accuracy: 0.5837 - val_loss: 0.0827\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9531 - loss: 0.0024 - val_accuracy: 0.6103 - val_loss: 0.0849\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9549 - loss: 0.0024 - val_accuracy: 0.6111 - val_loss: 0.0772\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.9612 - loss: 0.0021 - val_accuracy: 0.6014 - val_loss: 0.0767\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9533 - loss: 0.0020 - val_accuracy: 0.6159 - val_loss: 0.0807\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9618 - loss: 0.0018 - val_accuracy: 0.5660 - val_loss: 0.0836\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Fold 6 - Sensitivity: 0.7981, Specificity: 0.9192, Score: 0.8587, Accuracy: 0.8087\n",
      "Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9492 - loss: 0.0027 - val_accuracy: 0.6296 - val_loss: 0.0631\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9432 - loss: 0.0027 - val_accuracy: 0.6167 - val_loss: 0.0628\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9573 - loss: 0.0024 - val_accuracy: 0.6176 - val_loss: 0.0660\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9470 - loss: 0.0027 - val_accuracy: 0.6095 - val_loss: 0.0570\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9492 - loss: 0.0022 - val_accuracy: 0.6280 - val_loss: 0.0608\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9589 - loss: 0.0020 - val_accuracy: 0.6224 - val_loss: 0.0660\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9518 - loss: 0.0022 - val_accuracy: 0.5950 - val_loss: 0.0658\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9513 - loss: 0.0021 - val_accuracy: 0.6111 - val_loss: 0.0629\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9509 - loss: 0.0025 - val_accuracy: 0.6167 - val_loss: 0.0679\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9565 - loss: 0.0025 - val_accuracy: 0.6465 - val_loss: 0.0631\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9584 - loss: 0.0023 - val_accuracy: 0.5966 - val_loss: 0.0634\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9644 - loss: 0.0018 - val_accuracy: 0.6337 - val_loss: 0.0723\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9560 - loss: 0.0022 - val_accuracy: 0.6240 - val_loss: 0.0639\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 131ms/step - accuracy: 0.9568 - loss: 0.0020 - val_accuracy: 0.6200 - val_loss: 0.0636\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9624 - loss: 0.0020 - val_accuracy: 0.5950 - val_loss: 0.0735\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9563 - loss: 0.0022 - val_accuracy: 0.6071 - val_loss: 0.0651\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9627 - loss: 0.0019 - val_accuracy: 0.6167 - val_loss: 0.0604\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9647 - loss: 0.0018 - val_accuracy: 0.6208 - val_loss: 0.0677\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9601 - loss: 0.0021 - val_accuracy: 0.5773 - val_loss: 0.0701\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9552 - loss: 0.0022 - val_accuracy: 0.6184 - val_loss: 0.0674\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9660 - loss: 0.0014 - val_accuracy: 0.6256 - val_loss: 0.0655\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9581 - loss: 0.0022 - val_accuracy: 0.6312 - val_loss: 0.0681\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9670 - loss: 0.0018 - val_accuracy: 0.5853 - val_loss: 0.0627\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9638 - loss: 0.0016 - val_accuracy: 0.6312 - val_loss: 0.0638\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 131ms/step - accuracy: 0.9629 - loss: 0.0020 - val_accuracy: 0.6055 - val_loss: 0.0661\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9573 - loss: 0.0022 - val_accuracy: 0.5942 - val_loss: 0.0653\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9665 - loss: 0.0017 - val_accuracy: 0.6264 - val_loss: 0.0689\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9617 - loss: 0.0019 - val_accuracy: 0.6143 - val_loss: 0.0648\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9636 - loss: 0.0017 - val_accuracy: 0.6256 - val_loss: 0.0696\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9687 - loss: 0.0017 - val_accuracy: 0.6337 - val_loss: 0.0682\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9647 - loss: 0.0020 - val_accuracy: 0.6127 - val_loss: 0.0655\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9692 - loss: 0.0016 - val_accuracy: 0.6176 - val_loss: 0.0650\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9677 - loss: 0.0017 - val_accuracy: 0.6312 - val_loss: 0.0633\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9659 - loss: 0.0017 - val_accuracy: 0.6425 - val_loss: 0.0619\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9692 - loss: 0.0018 - val_accuracy: 0.5926 - val_loss: 0.0688\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9703 - loss: 0.0015 - val_accuracy: 0.6353 - val_loss: 0.0639\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9680 - loss: 0.0018 - val_accuracy: 0.6514 - val_loss: 0.0683\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9656 - loss: 0.0016 - val_accuracy: 0.6280 - val_loss: 0.0753\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9563 - loss: 0.0022 - val_accuracy: 0.6063 - val_loss: 0.0740\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9675 - loss: 0.0015 - val_accuracy: 0.5733 - val_loss: 0.0735\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9670 - loss: 0.0016 - val_accuracy: 0.6377 - val_loss: 0.0729\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9696 - loss: 0.0017 - val_accuracy: 0.6522 - val_loss: 0.0719\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9668 - loss: 0.0016 - val_accuracy: 0.6224 - val_loss: 0.0651\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9663 - loss: 0.0017 - val_accuracy: 0.6071 - val_loss: 0.0746\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9638 - loss: 0.0019 - val_accuracy: 0.6119 - val_loss: 0.0699\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9728 - loss: 0.0015 - val_accuracy: 0.6288 - val_loss: 0.0732\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9689 - loss: 0.0017 - val_accuracy: 0.6288 - val_loss: 0.0694\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.9675 - loss: 0.0016 - val_accuracy: 0.6167 - val_loss: 0.0692\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9642 - loss: 0.0019 - val_accuracy: 0.5813 - val_loss: 0.0685\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9638 - loss: 0.0017 - val_accuracy: 0.6079 - val_loss: 0.0644\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "Fold 7 - Sensitivity: 0.6591, Specificity: 0.9201, Score: 0.7896, Accuracy: 0.8142\n",
      "Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9528 - loss: 0.0032 - val_accuracy: 0.5354 - val_loss: 0.0914\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27737s\u001b[0m 179s/step - accuracy: 0.9494 - loss: 0.0022 - val_accuracy: 0.5628 - val_loss: 0.0876\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9553 - loss: 0.0028 - val_accuracy: 0.5564 - val_loss: 0.0961\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9606 - loss: 0.0019 - val_accuracy: 0.5290 - val_loss: 0.0917\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9663 - loss: 0.0019 - val_accuracy: 0.5676 - val_loss: 0.0999\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9598 - loss: 0.0022 - val_accuracy: 0.5572 - val_loss: 0.0995\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9630 - loss: 0.0017 - val_accuracy: 0.5330 - val_loss: 0.0960\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9655 - loss: 0.0017 - val_accuracy: 0.5548 - val_loss: 0.1005\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9553 - loss: 0.0022 - val_accuracy: 0.5604 - val_loss: 0.0914\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9654 - loss: 0.0015 - val_accuracy: 0.5411 - val_loss: 0.0969\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9664 - loss: 0.0019 - val_accuracy: 0.5733 - val_loss: 0.0959\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9638 - loss: 0.0015 - val_accuracy: 0.5620 - val_loss: 0.0932\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9521 - loss: 0.0022 - val_accuracy: 0.5628 - val_loss: 0.0925\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9555 - loss: 0.0022 - val_accuracy: 0.5548 - val_loss: 0.0934\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9687 - loss: 0.0014 - val_accuracy: 0.5620 - val_loss: 0.0960\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9686 - loss: 0.0014 - val_accuracy: 0.5459 - val_loss: 0.1012\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9690 - loss: 0.0016 - val_accuracy: 0.5741 - val_loss: 0.0994\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9535 - loss: 0.0024 - val_accuracy: 0.5499 - val_loss: 0.1000\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9667 - loss: 0.0016 - val_accuracy: 0.5813 - val_loss: 0.0932\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9731 - loss: 0.0013 - val_accuracy: 0.5548 - val_loss: 0.0967\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9681 - loss: 0.0017 - val_accuracy: 0.5435 - val_loss: 0.0930\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9707 - loss: 0.0018 - val_accuracy: 0.5644 - val_loss: 0.0989\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9641 - loss: 0.0017 - val_accuracy: 0.5749 - val_loss: 0.1002\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9718 - loss: 0.0015 - val_accuracy: 0.5459 - val_loss: 0.0960\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9679 - loss: 0.0018 - val_accuracy: 0.5692 - val_loss: 0.0915\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9688 - loss: 0.0014 - val_accuracy: 0.5692 - val_loss: 0.0968\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9681 - loss: 0.0015 - val_accuracy: 0.5588 - val_loss: 0.1005\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9680 - loss: 0.0016 - val_accuracy: 0.5612 - val_loss: 0.0983\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9607 - loss: 0.0016 - val_accuracy: 0.5620 - val_loss: 0.0998\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9714 - loss: 0.0014 - val_accuracy: 0.5298 - val_loss: 0.0960\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9638 - loss: 0.0016 - val_accuracy: 0.5330 - val_loss: 0.1005\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9656 - loss: 0.0016 - val_accuracy: 0.5459 - val_loss: 0.1053\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9664 - loss: 0.0015 - val_accuracy: 0.5362 - val_loss: 0.0963\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9672 - loss: 0.0019 - val_accuracy: 0.5620 - val_loss: 0.1034\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9723 - loss: 0.0016 - val_accuracy: 0.5580 - val_loss: 0.1020\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9704 - loss: 0.0015 - val_accuracy: 0.5604 - val_loss: 0.0995\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.9669 - loss: 0.0015 - val_accuracy: 0.5692 - val_loss: 0.0975\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9733 - loss: 0.0014 - val_accuracy: 0.5765 - val_loss: 0.1082\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.9721 - loss: 0.0014 - val_accuracy: 0.5499 - val_loss: 0.1025\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9619 - loss: 0.0018 - val_accuracy: 0.5700 - val_loss: 0.0999\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9694 - loss: 0.0016 - val_accuracy: 0.5539 - val_loss: 0.0985\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9720 - loss: 0.0015 - val_accuracy: 0.5676 - val_loss: 0.1028\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9692 - loss: 0.0017 - val_accuracy: 0.5797 - val_loss: 0.1032\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9781 - loss: 0.0013 - val_accuracy: 0.5475 - val_loss: 0.1080\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.9678 - loss: 0.0016 - val_accuracy: 0.5733 - val_loss: 0.0965\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9754 - loss: 0.0012 - val_accuracy: 0.5628 - val_loss: 0.1000\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 121ms/step - accuracy: 0.9807 - loss: 0.0011 - val_accuracy: 0.5725 - val_loss: 0.1028\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9758 - loss: 0.0013 - val_accuracy: 0.5531 - val_loss: 0.1039\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9766 - loss: 0.0011 - val_accuracy: 0.5773 - val_loss: 0.1047\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9657 - loss: 0.0017 - val_accuracy: 0.5507 - val_loss: 0.1038\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Fold 8 - Sensitivity: 0.9798, Specificity: 0.9930, Score: 0.9864, Accuracy: 0.9826\n",
      "Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.9698 - loss: 0.0016 - val_accuracy: 0.5986 - val_loss: 0.0925\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.9690 - loss: 0.0017 - val_accuracy: 0.5986 - val_loss: 0.0910\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - accuracy: 0.9668 - loss: 0.0016 - val_accuracy: 0.6171 - val_loss: 0.0920\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9633 - loss: 0.0019 - val_accuracy: 0.6042 - val_loss: 0.0968\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9716 - loss: 0.0013 - val_accuracy: 0.6042 - val_loss: 0.0954\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9763 - loss: 0.0012 - val_accuracy: 0.5792 - val_loss: 0.1011\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9686 - loss: 0.0016 - val_accuracy: 0.5905 - val_loss: 0.0950\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9749 - loss: 0.0012 - val_accuracy: 0.5986 - val_loss: 0.0984\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9719 - loss: 0.0013 - val_accuracy: 0.5905 - val_loss: 0.0989\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9719 - loss: 0.0014 - val_accuracy: 0.5945 - val_loss: 0.0976\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9741 - loss: 0.0014 - val_accuracy: 0.5881 - val_loss: 0.0947\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9692 - loss: 0.0015 - val_accuracy: 0.5817 - val_loss: 0.1032\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9738 - loss: 0.0012 - val_accuracy: 0.5704 - val_loss: 0.0966\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9733 - loss: 0.0014 - val_accuracy: 0.5873 - val_loss: 0.0953\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9738 - loss: 0.0015 - val_accuracy: 0.6010 - val_loss: 0.0978\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 126ms/step - accuracy: 0.9706 - loss: 0.0019 - val_accuracy: 0.6018 - val_loss: 0.0957\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - accuracy: 0.9698 - loss: 0.0015 - val_accuracy: 0.5929 - val_loss: 0.0970\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.9702 - loss: 0.0014 - val_accuracy: 0.5736 - val_loss: 0.0980\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 157ms/step - accuracy: 0.9703 - loss: 0.0017 - val_accuracy: 0.5969 - val_loss: 0.0984\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 143ms/step - accuracy: 0.9707 - loss: 0.0014 - val_accuracy: 0.6018 - val_loss: 0.0937\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.9730 - loss: 0.0015 - val_accuracy: 0.6066 - val_loss: 0.0978\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 162ms/step - accuracy: 0.9819 - loss: 8.7341e-04 - val_accuracy: 0.5977 - val_loss: 0.0980\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.9724 - loss: 0.0016 - val_accuracy: 0.6050 - val_loss: 0.0943\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9730 - loss: 0.0013 - val_accuracy: 0.6074 - val_loss: 0.0970\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 172ms/step - accuracy: 0.9752 - loss: 0.0013 - val_accuracy: 0.5986 - val_loss: 0.0956\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9781 - loss: 0.0012 - val_accuracy: 0.6106 - val_loss: 0.0901\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.9739 - loss: 0.0013 - val_accuracy: 0.6090 - val_loss: 0.0952\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 167ms/step - accuracy: 0.9781 - loss: 0.0012 - val_accuracy: 0.5905 - val_loss: 0.1034\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9735 - loss: 0.0012 - val_accuracy: 0.5921 - val_loss: 0.0977\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 167ms/step - accuracy: 0.9757 - loss: 0.0014 - val_accuracy: 0.5841 - val_loss: 0.1014\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 153ms/step - accuracy: 0.9748 - loss: 0.0012 - val_accuracy: 0.5792 - val_loss: 0.0956\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 150ms/step - accuracy: 0.9743 - loss: 0.0015 - val_accuracy: 0.6082 - val_loss: 0.1039\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 150ms/step - accuracy: 0.9750 - loss: 0.0012 - val_accuracy: 0.5889 - val_loss: 0.0991\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 145ms/step - accuracy: 0.9757 - loss: 0.0013 - val_accuracy: 0.5905 - val_loss: 0.0966\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 143ms/step - accuracy: 0.9843 - loss: 8.8934e-04 - val_accuracy: 0.6010 - val_loss: 0.1058\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 143ms/step - accuracy: 0.9759 - loss: 0.0013 - val_accuracy: 0.5945 - val_loss: 0.0977\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step - accuracy: 0.9802 - loss: 0.0011 - val_accuracy: 0.5841 - val_loss: 0.0908\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step - accuracy: 0.9758 - loss: 0.0012 - val_accuracy: 0.5865 - val_loss: 0.0975\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 146ms/step - accuracy: 0.9751 - loss: 0.0011 - val_accuracy: 0.5849 - val_loss: 0.1011\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - accuracy: 0.9767 - loss: 0.0011 - val_accuracy: 0.5986 - val_loss: 0.1017\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9742 - loss: 0.0014 - val_accuracy: 0.5994 - val_loss: 0.0975\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 139ms/step - accuracy: 0.9757 - loss: 0.0011 - val_accuracy: 0.5945 - val_loss: 0.1043\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9763 - loss: 0.0013 - val_accuracy: 0.5817 - val_loss: 0.0890\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - accuracy: 0.9749 - loss: 0.0012 - val_accuracy: 0.5768 - val_loss: 0.0964\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9804 - loss: 0.0010 - val_accuracy: 0.6050 - val_loss: 0.1007\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9773 - loss: 0.0013 - val_accuracy: 0.6018 - val_loss: 0.0961\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9757 - loss: 0.0012 - val_accuracy: 0.5768 - val_loss: 0.1048\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9741 - loss: 0.0013 - val_accuracy: 0.5704 - val_loss: 0.1041\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9760 - loss: 0.0014 - val_accuracy: 0.5857 - val_loss: 0.0961\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9845 - loss: 9.6017e-04 - val_accuracy: 0.5929 - val_loss: 0.1041\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "Fold 9 - Sensitivity: 0.9136, Specificity: 0.9546, Score: 0.9341, Accuracy: 0.9212\n",
      "Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.9718 - loss: 0.0013 - val_accuracy: 0.5926 - val_loss: 0.0958\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 139ms/step - accuracy: 0.9720 - loss: 0.0014 - val_accuracy: 0.6006 - val_loss: 0.0944\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 139ms/step - accuracy: 0.9838 - loss: 9.5972e-04 - val_accuracy: 0.5789 - val_loss: 0.1017\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9772 - loss: 0.0013 - val_accuracy: 0.5845 - val_loss: 0.1000\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9751 - loss: 0.0012 - val_accuracy: 0.5845 - val_loss: 0.0924\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 137ms/step - accuracy: 0.9793 - loss: 0.0012 - val_accuracy: 0.5870 - val_loss: 0.0952\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9788 - loss: 0.0012 - val_accuracy: 0.5829 - val_loss: 0.1000\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.9750 - loss: 0.0012 - val_accuracy: 0.6006 - val_loss: 0.1040\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9819 - loss: 9.2668e-04 - val_accuracy: 0.6014 - val_loss: 0.0975\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 135ms/step - accuracy: 0.9804 - loss: 0.0011 - val_accuracy: 0.5749 - val_loss: 0.0972\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.9814 - loss: 9.0113e-04 - val_accuracy: 0.5813 - val_loss: 0.0986\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9769 - loss: 0.0011 - val_accuracy: 0.6055 - val_loss: 0.1080\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9808 - loss: 9.6800e-04 - val_accuracy: 0.6023 - val_loss: 0.1135\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9811 - loss: 0.0013 - val_accuracy: 0.5926 - val_loss: 0.1044\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9803 - loss: 0.0011 - val_accuracy: 0.5741 - val_loss: 0.1007\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.9762 - loss: 9.7624e-04 - val_accuracy: 0.5942 - val_loss: 0.0961\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 124ms/step - accuracy: 0.9706 - loss: 0.0019 - val_accuracy: 0.5709 - val_loss: 0.0960\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9797 - loss: 0.0012 - val_accuracy: 0.5982 - val_loss: 0.0969\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9750 - loss: 0.0012 - val_accuracy: 0.5741 - val_loss: 0.0947\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.9811 - loss: 9.1533e-04 - val_accuracy: 0.5926 - val_loss: 0.0999\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 138ms/step - accuracy: 0.9826 - loss: 7.8504e-04 - val_accuracy: 0.5789 - val_loss: 0.1044\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.9781 - loss: 0.0012 - val_accuracy: 0.5531 - val_loss: 0.1019\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - accuracy: 0.9730 - loss: 0.0014 - val_accuracy: 0.5805 - val_loss: 0.0947\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 145ms/step - accuracy: 0.9821 - loss: 8.3678e-04 - val_accuracy: 0.5982 - val_loss: 0.1054\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.9769 - loss: 0.0014 - val_accuracy: 0.5781 - val_loss: 0.0948\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 148ms/step - accuracy: 0.9821 - loss: 0.0011 - val_accuracy: 0.5765 - val_loss: 0.0914\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 169ms/step - accuracy: 0.9770 - loss: 0.0010 - val_accuracy: 0.5926 - val_loss: 0.0988\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 150ms/step - accuracy: 0.9795 - loss: 0.0012 - val_accuracy: 0.5765 - val_loss: 0.1008\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 163ms/step - accuracy: 0.9815 - loss: 9.8272e-04 - val_accuracy: 0.5805 - val_loss: 0.1045\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 162ms/step - accuracy: 0.9850 - loss: 8.8740e-04 - val_accuracy: 0.5741 - val_loss: 0.1031\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9832 - loss: 9.6343e-04 - val_accuracy: 0.5781 - val_loss: 0.0948\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.9732 - loss: 0.0015 - val_accuracy: 0.5757 - val_loss: 0.0977\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step - accuracy: 0.9785 - loss: 0.0011 - val_accuracy: 0.5717 - val_loss: 0.1060\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 181ms/step - accuracy: 0.9782 - loss: 0.0011 - val_accuracy: 0.5998 - val_loss: 0.1052\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 163ms/step - accuracy: 0.9808 - loss: 9.4523e-04 - val_accuracy: 0.5837 - val_loss: 0.1073\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - accuracy: 0.9795 - loss: 0.0015 - val_accuracy: 0.5676 - val_loss: 0.1029\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 170ms/step - accuracy: 0.9773 - loss: 9.8611e-04 - val_accuracy: 0.5982 - val_loss: 0.0999\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 172ms/step - accuracy: 0.9841 - loss: 8.7751e-04 - val_accuracy: 0.5797 - val_loss: 0.1048\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.9796 - loss: 0.0010 - val_accuracy: 0.5821 - val_loss: 0.1148\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 181ms/step - accuracy: 0.9794 - loss: 8.8894e-04 - val_accuracy: 0.5918 - val_loss: 0.1002\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9826 - loss: 8.5371e-04 - val_accuracy: 0.5700 - val_loss: 0.1049\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.9817 - loss: 0.0010 - val_accuracy: 0.5789 - val_loss: 0.0998\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - accuracy: 0.9800 - loss: 0.0011 - val_accuracy: 0.6023 - val_loss: 0.1038\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - accuracy: 0.9847 - loss: 8.0128e-04 - val_accuracy: 0.6063 - val_loss: 0.1098\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 168ms/step - accuracy: 0.9804 - loss: 0.0010 - val_accuracy: 0.5781 - val_loss: 0.1002\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 165ms/step - accuracy: 0.9874 - loss: 8.0371e-04 - val_accuracy: 0.6006 - val_loss: 0.0977\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9782 - loss: 0.0012 - val_accuracy: 0.5870 - val_loss: 0.1035\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 179ms/step - accuracy: 0.9834 - loss: 0.0010 - val_accuracy: 0.6063 - val_loss: 0.1032\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 181ms/step - accuracy: 0.9834 - loss: 8.5774e-04 - val_accuracy: 0.5717 - val_loss: 0.1137\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9769 - loss: 0.0010 - val_accuracy: 0.5926 - val_loss: 0.1045\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "Fold 10 - Sensitivity: 0.8820, Specificity: 0.9747, Score: 0.9283, Accuracy: 0.9493\n",
      "\n",
      "Average Results Across Folds:\n",
      "Average Sensitivity: 0.7253\n",
      "Average Specificity: 0.9046\n",
      "Average Score: 0.8150\n",
      "Average Accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=4)\n",
    "sensitivity_list, specificity_list, score_list, accuracy_list = [], [], [], []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "    X_train, X_test = spectrograms_resized[train_idx], spectrograms_resized[test_idx]\n",
    "    y_train, y_test = labels_one_hot[train_idx], labels_one_hot[test_idx]\n",
    "    \n",
    "    print(f\"Training fold {fold_idx + 1}/10\")\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    sensitivity = np.mean(TP / (TP + FN + 1e-10))\n",
    "    specificity = np.mean(TN / (TN + FP + 1e-10))\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    score_list.append(score)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1} - Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, \"\n",
    "          f\"Score: {score:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results Across Folds:\")\n",
    "print(f\"Average Sensitivity: {np.mean(sensitivity_list):.4f}\")\n",
    "print(f\"Average Specificity: {np.mean(specificity_list):.4f}\")\n",
    "print(f\"Average Score: {np.mean(score_list):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(spectrograms_resized[0, :, :, 0], aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title('Sample Spectrogram (Normal)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(4), ['Normal', 'Crackles', 'Wheezes', 'Both'])\n",
    "plt.yticks(np.arange(4), ['Normal', 'Crackles', 'Wheezes', 'Both'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms shape: (6898, 75, 50, 1)\n",
      "Labels shape: (6898,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "from cryptography.hazmat.decrepit.ciphers.algorithms import TripleDES, Blowfish\n",
    "from cryptography.utils import CryptographyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=CryptographyDeprecationWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Load spectrograms and labels\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "\n",
    "print(\"Spectrograms shape:\", spectrograms_resized.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Normal', 'Crackles', 'Wheezes', 'Both Crackles and Wheezes']\n",
    "\n",
    "# Select 5 sample indices (one from each class + one extra)\n",
    "sample_indices = []\n",
    "for class_idx in range(4):  # Classes 0 to 3\n",
    "    idx = np.where(labels == class_idx)[0][0]  # First occurrence of each class\n",
    "    sample_indices.append(idx)\n",
    "# Add one more sample (e.g., another Normal for variety)\n",
    "sample_indices.append(np.where(labels == 0)[0][1])  # Second Normal sample\n",
    "\n",
    "# Plot 5 sample spectrograms\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    plt.subplot(2, 3, i + 1)  # 2 rows, 3 columns (only 5 will be filled)\n",
    "    plt.imshow(spectrograms_resized[idx, :, :, 0], cmap='viridis', aspect='auto', origin='lower')\n",
    "    plt.title(f\"Sample {i+1}: {class_names[labels[idx]]}\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.colorbar(label='dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ re_lu_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ re_lu_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ re_lu_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ re_lu_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ re_lu_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ re_lu_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │      \u001b[38;5;34m3,200\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_51 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_52 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_67 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_23 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_53 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_54 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_69 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_24 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_55 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_70 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │     \u001b[38;5;34m73,856\u001b[0m │ re_lu_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_56 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_71 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_72 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │      \u001b[38;5;34m8,320\u001b[0m │ re_lu_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_25 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ conv2d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_57 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_73 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_58 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_74 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_26 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ re_lu_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_59 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_75 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ re_lu_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_60 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_76 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_77 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ re_lu_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_27 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_61 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_78 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_62 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_79 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_28 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_63 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_80 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,180,160\u001b[0m │ re_lu_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_64 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_81 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_82 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m131,584\u001b[0m │ re_lu_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_65 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_83 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_66 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_84 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_67 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m2,052\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,445,764</span> (43.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,445,764\u001b[0m (43.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,437,956</span> (43.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,437,956\u001b[0m (43.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> (30.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,808\u001b[0m (30.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 - Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 317ms/step - accuracy: 0.4772 - loss: 0.0468 - val_accuracy: 0.5998 - val_loss: 0.0386\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 297ms/step - accuracy: 0.5691 - loss: 0.0318 - val_accuracy: 0.5966 - val_loss: 0.0375\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.6070 - loss: 0.0279 - val_accuracy: 0.5950 - val_loss: 0.0380\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 297ms/step - accuracy: 0.6463 - loss: 0.0232 - val_accuracy: 0.4702 - val_loss: 0.0414\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.6977 - loss: 0.0191 - val_accuracy: 0.5201 - val_loss: 0.0438\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.7322 - loss: 0.0164 - val_accuracy: 0.6079 - val_loss: 0.0605\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.7727 - loss: 0.0126 - val_accuracy: 0.5395 - val_loss: 0.0500\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.7988 - loss: 0.0115 - val_accuracy: 0.4855 - val_loss: 0.0585\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.8576 - loss: 0.0072 - val_accuracy: 0.5781 - val_loss: 0.0645\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 0.8890 - loss: 0.0058 - val_accuracy: 0.5217 - val_loss: 0.0569\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 0.8978 - loss: 0.0054 - val_accuracy: 0.5435 - val_loss: 0.0647\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.8376 - loss: 0.0098 - val_accuracy: 0.5008 - val_loss: 0.0623\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9217 - loss: 0.0043 - val_accuracy: 0.5781 - val_loss: 0.0744\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9447 - loss: 0.0027 - val_accuracy: 0.4316 - val_loss: 0.1080\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9541 - loss: 0.0023 - val_accuracy: 0.5040 - val_loss: 0.1064\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 298ms/step - accuracy: 0.9273 - loss: 0.0040 - val_accuracy: 0.5169 - val_loss: 0.0780\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9468 - loss: 0.0029 - val_accuracy: 0.5548 - val_loss: 0.0854\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9741 - loss: 0.0016 - val_accuracy: 0.5781 - val_loss: 0.0993\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9606 - loss: 0.0022 - val_accuracy: 0.4815 - val_loss: 0.0756\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 297ms/step - accuracy: 0.9657 - loss: 0.0020 - val_accuracy: 0.5040 - val_loss: 0.0712\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.9629 - loss: 0.0023 - val_accuracy: 0.4992 - val_loss: 0.0787\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9536 - loss: 0.0028 - val_accuracy: 0.5572 - val_loss: 0.0828\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9552 - loss: 0.0025 - val_accuracy: 0.5636 - val_loss: 0.1071\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9748 - loss: 0.0012 - val_accuracy: 0.5330 - val_loss: 0.0981\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 297ms/step - accuracy: 0.9813 - loss: 0.0011 - val_accuracy: 0.5878 - val_loss: 0.1073\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9089 - loss: 0.0060 - val_accuracy: 0.5105 - val_loss: 0.0970\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9803 - loss: 0.0012 - val_accuracy: 0.5435 - val_loss: 0.0985\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9886 - loss: 6.9851e-04 - val_accuracy: 0.4461 - val_loss: 0.0908\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9838 - loss: 8.6826e-04 - val_accuracy: 0.3986 - val_loss: 0.0873\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 0.9697 - loss: 0.0018 - val_accuracy: 0.5298 - val_loss: 0.1023\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9708 - loss: 0.0017 - val_accuracy: 0.5572 - val_loss: 0.0976\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9856 - loss: 9.1310e-04 - val_accuracy: 0.4783 - val_loss: 0.0974\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9816 - loss: 0.0012 - val_accuracy: 0.4565 - val_loss: 0.0683\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9702 - loss: 0.0015 - val_accuracy: 0.4758 - val_loss: 0.0939\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.9858 - loss: 8.2016e-04 - val_accuracy: 0.5056 - val_loss: 0.1026\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9623 - loss: 0.0021 - val_accuracy: 0.5419 - val_loss: 0.0820\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9781 - loss: 0.0012 - val_accuracy: 0.5491 - val_loss: 0.1041\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9885 - loss: 6.2230e-04 - val_accuracy: 0.4678 - val_loss: 0.0912\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9843 - loss: 8.7914e-04 - val_accuracy: 0.5056 - val_loss: 0.1020\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 0.9793 - loss: 0.0011 - val_accuracy: 0.5330 - val_loss: 0.1145\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9454 - loss: 0.0039 - val_accuracy: 0.5652 - val_loss: 0.0983\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9756 - loss: 0.0017 - val_accuracy: 0.5000 - val_loss: 0.0984\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9893 - loss: 7.0124e-04 - val_accuracy: 0.5717 - val_loss: 0.1034\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9949 - loss: 2.9885e-04 - val_accuracy: 0.4485 - val_loss: 0.1052\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 298ms/step - accuracy: 0.9893 - loss: 5.7655e-04 - val_accuracy: 0.5378 - val_loss: 0.1062\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9935 - loss: 6.1563e-04 - val_accuracy: 0.5129 - val_loss: 0.1006\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9917 - loss: 5.7320e-04 - val_accuracy: 0.4710 - val_loss: 0.1294\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9659 - loss: 0.0022 - val_accuracy: 0.5395 - val_loss: 0.0903\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9845 - loss: 7.9074e-04 - val_accuracy: 0.5395 - val_loss: 0.0936\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9036 - loss: 0.0070 - val_accuracy: 0.4581 - val_loss: 0.0892\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n",
      "ResNet18 - Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.8912 - loss: 0.0103 - val_accuracy: 0.3816 - val_loss: 0.0692\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9615 - loss: 0.0031 - val_accuracy: 0.5153 - val_loss: 0.0714\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9802 - loss: 0.0014 - val_accuracy: 0.4396 - val_loss: 0.0941\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9746 - loss: 0.0014 - val_accuracy: 0.4855 - val_loss: 0.0838\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9731 - loss: 0.0018 - val_accuracy: 0.4783 - val_loss: 0.0957\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 0.9829 - loss: 0.0011 - val_accuracy: 0.5435 - val_loss: 0.0910\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 0.9874 - loss: 9.5492e-04 - val_accuracy: 0.4219 - val_loss: 0.1035\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9608 - loss: 0.0027 - val_accuracy: 0.5298 - val_loss: 0.0772\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9851 - loss: 9.3633e-04 - val_accuracy: 0.5040 - val_loss: 0.0933\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9905 - loss: 5.6919e-04 - val_accuracy: 0.4388 - val_loss: 0.1011\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 0.9748 - loss: 0.0015 - val_accuracy: 0.5483 - val_loss: 0.0969\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 0.9788 - loss: 0.0013 - val_accuracy: 0.4871 - val_loss: 0.1031\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 0.9953 - loss: 3.1628e-04 - val_accuracy: 0.4493 - val_loss: 0.1275\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 0.9938 - loss: 2.9744e-04 - val_accuracy: 0.5056 - val_loss: 0.1053\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 0.9892 - loss: 5.1674e-04 - val_accuracy: 0.5081 - val_loss: 0.0963\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 0.9313 - loss: 0.0045 - val_accuracy: 0.4815 - val_loss: 0.0855\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9870 - loss: 7.4024e-04 - val_accuracy: 0.4461 - val_loss: 0.1061\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9932 - loss: 3.2132e-04 - val_accuracy: 0.4968 - val_loss: 0.1200\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9974 - loss: 1.2373e-04 - val_accuracy: 0.5072 - val_loss: 0.1344\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9982 - loss: 2.1459e-04 - val_accuracy: 0.4767 - val_loss: 0.1111\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9704 - loss: 0.0020 - val_accuracy: 0.4847 - val_loss: 0.1031\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9651 - loss: 0.0024 - val_accuracy: 0.5081 - val_loss: 0.1022\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9929 - loss: 4.8950e-04 - val_accuracy: 0.4839 - val_loss: 0.1147\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9955 - loss: 2.6278e-04 - val_accuracy: 0.4614 - val_loss: 0.1062\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9848 - loss: 8.1851e-04 - val_accuracy: 0.5032 - val_loss: 0.0965\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9866 - loss: 8.0999e-04 - val_accuracy: 0.5242 - val_loss: 0.0969\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9889 - loss: 9.9739e-04 - val_accuracy: 0.5161 - val_loss: 0.0984\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9901 - loss: 4.9813e-04 - val_accuracy: 0.5185 - val_loss: 0.1032\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9956 - loss: 2.9019e-04 - val_accuracy: 0.4823 - val_loss: 0.1087\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9778 - loss: 0.0011 - val_accuracy: 0.4960 - val_loss: 0.1023\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9962 - loss: 1.2328e-04 - val_accuracy: 0.5024 - val_loss: 0.1241\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 298ms/step - accuracy: 0.9883 - loss: 6.7010e-04 - val_accuracy: 0.4396 - val_loss: 0.0930\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9912 - loss: 4.5199e-04 - val_accuracy: 0.5258 - val_loss: 0.1154\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9952 - loss: 3.5523e-04 - val_accuracy: 0.4936 - val_loss: 0.1115\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9960 - loss: 2.3880e-04 - val_accuracy: 0.5169 - val_loss: 0.1213\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.8874 - loss: 0.0068 - val_accuracy: 0.4960 - val_loss: 0.1005\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 0.9678 - loss: 0.0020 - val_accuracy: 0.5089 - val_loss: 0.0968\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9921 - loss: 3.9758e-04 - val_accuracy: 0.4911 - val_loss: 0.0957\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9972 - loss: 1.8732e-04 - val_accuracy: 0.5081 - val_loss: 0.1180\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.6174e-05 - val_accuracy: 0.5032 - val_loss: 0.1269\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.0370e-05 - val_accuracy: 0.5072 - val_loss: 0.1313\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 5.4897e-06 - val_accuracy: 0.4944 - val_loss: 0.1333\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 3.6796e-06 - val_accuracy: 0.4919 - val_loss: 0.1347\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 5.3622e-06 - val_accuracy: 0.5008 - val_loss: 0.1373\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 1.7288e-06 - val_accuracy: 0.5072 - val_loss: 0.1380\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 1.8608e-06 - val_accuracy: 0.5024 - val_loss: 0.1414\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 2.0636e-06 - val_accuracy: 0.5072 - val_loss: 0.1444\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 1.3101e-06 - val_accuracy: 0.4911 - val_loss: 0.1467\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 3.0573e-06 - val_accuracy: 0.5056 - val_loss: 0.1500\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 6.4300e-06 - val_accuracy: 0.5081 - val_loss: 0.1544\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step\n",
      "ResNet18 - Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9026 - loss: 0.0085 - val_accuracy: 0.5539 - val_loss: 0.0664\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.9687 - loss: 0.0019 - val_accuracy: 0.5548 - val_loss: 0.0876\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 291ms/step - accuracy: 0.9949 - loss: 3.3468e-04 - val_accuracy: 0.4984 - val_loss: 0.0953\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.9941 - loss: 4.6786e-04 - val_accuracy: 0.5048 - val_loss: 0.0992\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9900 - loss: 7.3444e-04 - val_accuracy: 0.4251 - val_loss: 0.0833\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9898 - loss: 5.5952e-04 - val_accuracy: 0.4501 - val_loss: 0.1061\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9627 - loss: 0.0028 - val_accuracy: 0.5459 - val_loss: 0.0790\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9770 - loss: 0.0014 - val_accuracy: 0.5676 - val_loss: 0.0965\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9864 - loss: 7.5294e-04 - val_accuracy: 0.5499 - val_loss: 0.0989\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9967 - loss: 2.3146e-04 - val_accuracy: 0.4493 - val_loss: 0.0904\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9963 - loss: 2.1534e-04 - val_accuracy: 0.5185 - val_loss: 0.1105\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9970 - loss: 2.3353e-04 - val_accuracy: 0.4903 - val_loss: 0.0776\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9887 - loss: 6.6266e-04 - val_accuracy: 0.5330 - val_loss: 0.0890\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 294ms/step - accuracy: 0.9981 - loss: 1.6647e-04 - val_accuracy: 0.5564 - val_loss: 0.0967\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9958 - loss: 2.3564e-04 - val_accuracy: 0.5209 - val_loss: 0.1005\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9900 - loss: 5.1185e-04 - val_accuracy: 0.5282 - val_loss: 0.0897\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 293ms/step - accuracy: 0.9923 - loss: 5.6830e-04 - val_accuracy: 0.4911 - val_loss: 0.1079\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 291ms/step - accuracy: 0.9980 - loss: 8.5860e-05 - val_accuracy: 0.5024 - val_loss: 0.1181\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 291ms/step - accuracy: 0.9992 - loss: 2.8130e-05 - val_accuracy: 0.5435 - val_loss: 0.1171\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9907 - loss: 5.8473e-04 - val_accuracy: 0.5282 - val_loss: 0.0783\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9805 - loss: 0.0012 - val_accuracy: 0.5250 - val_loss: 0.0711\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 293ms/step - accuracy: 0.9921 - loss: 4.9040e-04 - val_accuracy: 0.5274 - val_loss: 0.1008\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 296ms/step - accuracy: 0.9997 - loss: 2.7651e-05 - val_accuracy: 0.5491 - val_loss: 0.1103\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 8.3350e-06 - val_accuracy: 0.5403 - val_loss: 0.1168\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 5.5394e-06 - val_accuracy: 0.5395 - val_loss: 0.1248\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 3.0135e-06 - val_accuracy: 0.5290 - val_loss: 0.1279\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 2.8011e-06 - val_accuracy: 0.5346 - val_loss: 0.1307\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.1016e-06 - val_accuracy: 0.5298 - val_loss: 0.1332\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.1147e-06 - val_accuracy: 0.5233 - val_loss: 0.1356\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 1.5055e-06 - val_accuracy: 0.5370 - val_loss: 0.1368\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.2651e-06 - val_accuracy: 0.5338 - val_loss: 0.1379\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 7.6867e-07 - val_accuracy: 0.5314 - val_loss: 0.1392\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 9.2736e-07 - val_accuracy: 0.5411 - val_loss: 0.1394\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9829 - loss: 0.0012 - val_accuracy: 0.4903 - val_loss: 0.0737\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9408 - loss: 0.0037 - val_accuracy: 0.5862 - val_loss: 0.0701\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9896 - loss: 7.1729e-04 - val_accuracy: 0.5040 - val_loss: 0.1077\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9977 - loss: 1.8051e-04 - val_accuracy: 0.5902 - val_loss: 0.1100\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9867 - loss: 7.0483e-04 - val_accuracy: 0.5362 - val_loss: 0.1066\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9961 - loss: 3.3209e-04 - val_accuracy: 0.5370 - val_loss: 0.1094\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9990 - loss: 8.0221e-05 - val_accuracy: 0.5451 - val_loss: 0.1187\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9942 - loss: 3.4205e-04 - val_accuracy: 0.5105 - val_loss: 0.1002\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9876 - loss: 8.9451e-04 - val_accuracy: 0.4887 - val_loss: 0.0878\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9972 - loss: 3.0390e-04 - val_accuracy: 0.5000 - val_loss: 0.0931\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9981 - loss: 7.2388e-05 - val_accuracy: 0.4702 - val_loss: 0.1046\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9510 - loss: 0.0034 - val_accuracy: 0.5217 - val_loss: 0.1017\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9943 - loss: 4.2936e-04 - val_accuracy: 0.5636 - val_loss: 0.0931\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9958 - loss: 3.3169e-04 - val_accuracy: 0.5370 - val_loss: 0.0931\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9997 - loss: 4.2400e-05 - val_accuracy: 0.5185 - val_loss: 0.1121\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.6656e-05 - val_accuracy: 0.5129 - val_loss: 0.1197\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 5.7469e-06 - val_accuracy: 0.5145 - val_loss: 0.1240\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step\n",
      "ResNet18 - Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9673 - loss: 0.0034 - val_accuracy: 0.5548 - val_loss: 0.0786\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9937 - loss: 5.0102e-04 - val_accuracy: 0.5338 - val_loss: 0.0838\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9544 - loss: 0.0033 - val_accuracy: 0.5314 - val_loss: 0.0868\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9966 - loss: 2.2165e-04 - val_accuracy: 0.5427 - val_loss: 0.0990\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9921 - loss: 9.0403e-04 - val_accuracy: 0.5427 - val_loss: 0.1022\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9998 - loss: 3.9296e-05 - val_accuracy: 0.5419 - val_loss: 0.1073\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9995 - loss: 1.9016e-05 - val_accuracy: 0.5435 - val_loss: 0.1085\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 5.3000e-06 - val_accuracy: 0.5604 - val_loss: 0.1160\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 2.9817e-06 - val_accuracy: 0.5596 - val_loss: 0.1162\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 3.2623e-06 - val_accuracy: 0.5660 - val_loss: 0.1185\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.7477e-06 - val_accuracy: 0.5564 - val_loss: 0.1203\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.1278e-06 - val_accuracy: 0.5580 - val_loss: 0.1215\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 3.7925e-06 - val_accuracy: 0.5676 - val_loss: 0.1222\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.9933e-06 - val_accuracy: 0.5556 - val_loss: 0.1273\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.8321e-06 - val_accuracy: 0.5628 - val_loss: 0.1241\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 8.8964e-07 - val_accuracy: 0.5556 - val_loss: 0.1261\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.4115e-06 - val_accuracy: 0.5507 - val_loss: 0.1282\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 2.4769e-06 - val_accuracy: 0.5378 - val_loss: 0.1334\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 2.6269e-06 - val_accuracy: 0.5515 - val_loss: 0.1337\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 6.6293e-07 - val_accuracy: 0.5507 - val_loss: 0.1369\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 4.8769e-07 - val_accuracy: 0.5588 - val_loss: 0.1352\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 3.1679e-07 - val_accuracy: 0.5564 - val_loss: 0.1372\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.1400e-07 - val_accuracy: 0.5596 - val_loss: 0.1381\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 6.1532e-07 - val_accuracy: 0.5531 - val_loss: 0.1421\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 4.5064e-07 - val_accuracy: 0.5491 - val_loss: 0.1434\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 3.2604e-07 - val_accuracy: 0.5531 - val_loss: 0.1442\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 3.7666e-07 - val_accuracy: 0.5548 - val_loss: 0.1443\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.7583e-07 - val_accuracy: 0.5539 - val_loss: 0.1452\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.2275e-07 - val_accuracy: 0.5580 - val_loss: 0.1453\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.6334e-07 - val_accuracy: 0.5564 - val_loss: 0.1454\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 2.4123e-07 - val_accuracy: 0.5531 - val_loss: 0.1452\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 7.0382e-08 - val_accuracy: 0.5539 - val_loss: 0.1469\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.2658e-07 - val_accuracy: 0.5572 - val_loss: 0.1475\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 9.2425e-08 - val_accuracy: 0.5467 - val_loss: 0.1474\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 6.2520e-08 - val_accuracy: 0.5556 - val_loss: 0.1493\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 6.3669e-08 - val_accuracy: 0.5531 - val_loss: 0.1507\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.7005e-07 - val_accuracy: 0.5539 - val_loss: 0.1531\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.3898e-07 - val_accuracy: 0.5564 - val_loss: 0.1535\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.4235e-08 - val_accuracy: 0.5531 - val_loss: 0.1531\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.0180e-07 - val_accuracy: 0.5644 - val_loss: 0.1556\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9478 - loss: 0.0046 - val_accuracy: 0.4678 - val_loss: 0.0713\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9498 - loss: 0.0031 - val_accuracy: 0.5548 - val_loss: 0.0914\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9882 - loss: 5.8465e-04 - val_accuracy: 0.5507 - val_loss: 0.1023\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9909 - loss: 6.6778e-04 - val_accuracy: 0.5298 - val_loss: 0.1034\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9972 - loss: 2.1754e-04 - val_accuracy: 0.5129 - val_loss: 0.1066\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9969 - loss: 2.4160e-04 - val_accuracy: 0.5024 - val_loss: 0.1074\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9995 - loss: 8.3473e-05 - val_accuracy: 0.5362 - val_loss: 0.1291\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9980 - loss: 1.4444e-04 - val_accuracy: 0.4863 - val_loss: 0.1193\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9878 - loss: 8.1876e-04 - val_accuracy: 0.5056 - val_loss: 0.0922\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9946 - loss: 4.6837e-04 - val_accuracy: 0.5386 - val_loss: 0.1165\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n",
      "ResNet18 - Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9785 - loss: 0.0015 - val_accuracy: 0.5097 - val_loss: 0.0961\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9914 - loss: 4.7071e-04 - val_accuracy: 0.5419 - val_loss: 0.1147\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9976 - loss: 1.9328e-04 - val_accuracy: 0.5000 - val_loss: 0.1247\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9994 - loss: 3.3129e-05 - val_accuracy: 0.5306 - val_loss: 0.1290\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9966 - loss: 2.8510e-04 - val_accuracy: 0.5290 - val_loss: 0.1184\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9984 - loss: 1.2241e-04 - val_accuracy: 0.5169 - val_loss: 0.1296\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9997 - loss: 2.0350e-05 - val_accuracy: 0.5298 - val_loss: 0.1339\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 6.6604e-06 - val_accuracy: 0.5242 - val_loss: 0.1434\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 5.0679e-06 - val_accuracy: 0.5282 - val_loss: 0.1460\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 0.9998 - loss: 8.8683e-06 - val_accuracy: 0.5266 - val_loss: 0.1493\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 5.2188e-06 - val_accuracy: 0.5169 - val_loss: 0.1580\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 2.4702e-06 - val_accuracy: 0.5193 - val_loss: 0.1587\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 1.7985e-06 - val_accuracy: 0.5153 - val_loss: 0.1615\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 8.1145e-07 - val_accuracy: 0.5145 - val_loss: 0.1609\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 2.3610e-06 - val_accuracy: 0.5000 - val_loss: 0.1620\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 5.2755e-07 - val_accuracy: 0.5161 - val_loss: 0.1648\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 7.6745e-07 - val_accuracy: 0.5129 - val_loss: 0.1646\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 4.8058e-07 - val_accuracy: 0.5193 - val_loss: 0.1658\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 2.7954e-07 - val_accuracy: 0.5217 - val_loss: 0.1672\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 2.7201e-07 - val_accuracy: 0.5032 - val_loss: 0.1651\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9112 - loss: 0.0073 - val_accuracy: 0.4436 - val_loss: 0.0800\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9826 - loss: 8.4910e-04 - val_accuracy: 0.5266 - val_loss: 0.1020\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9981 - loss: 1.2345e-04 - val_accuracy: 0.5322 - val_loss: 0.1056\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9997 - loss: 7.4649e-05 - val_accuracy: 0.5081 - val_loss: 0.1170\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 330ms/step - accuracy: 0.9982 - loss: 8.4880e-05 - val_accuracy: 0.5008 - val_loss: 0.1143\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9952 - loss: 4.7259e-04 - val_accuracy: 0.5612 - val_loss: 0.1212\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9958 - loss: 2.2812e-04 - val_accuracy: 0.5314 - val_loss: 0.1025\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9990 - loss: 1.1001e-04 - val_accuracy: 0.5298 - val_loss: 0.1282\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9979 - loss: 1.1366e-04 - val_accuracy: 0.5129 - val_loss: 0.1318\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9987 - loss: 9.8387e-05 - val_accuracy: 0.5209 - val_loss: 0.1321\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9955 - loss: 3.0702e-04 - val_accuracy: 0.5177 - val_loss: 0.1003\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9956 - loss: 2.8057e-04 - val_accuracy: 0.5362 - val_loss: 0.0791\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9846 - loss: 9.2986e-04 - val_accuracy: 0.5419 - val_loss: 0.1113\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9901 - loss: 7.1837e-04 - val_accuracy: 0.4936 - val_loss: 0.1100\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9943 - loss: 3.7511e-04 - val_accuracy: 0.5040 - val_loss: 0.1104\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9993 - loss: 7.1182e-05 - val_accuracy: 0.5201 - val_loss: 0.1232\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9985 - loss: 1.2666e-04 - val_accuracy: 0.4831 - val_loss: 0.1092\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9985 - loss: 8.2588e-05 - val_accuracy: 0.5145 - val_loss: 0.1160\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9971 - loss: 1.4215e-04 - val_accuracy: 0.5169 - val_loss: 0.1332\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 1.2168e-05 - val_accuracy: 0.5225 - val_loss: 0.1367\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.2846e-05 - val_accuracy: 0.5209 - val_loss: 0.1445\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.9605e-06 - val_accuracy: 0.5145 - val_loss: 0.1474\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 2.2318e-06 - val_accuracy: 0.5089 - val_loss: 0.1513\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 2.1925e-06 - val_accuracy: 0.5089 - val_loss: 0.1519\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.4921e-06 - val_accuracy: 0.5097 - val_loss: 0.1535\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 4.4160e-07 - val_accuracy: 0.5097 - val_loss: 0.1548\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 5.8548e-07 - val_accuracy: 0.5137 - val_loss: 0.1560\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 5.3111e-07 - val_accuracy: 0.5145 - val_loss: 0.1575\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.0166e-07 - val_accuracy: 0.5137 - val_loss: 0.1584\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 3.5972e-07 - val_accuracy: 0.5145 - val_loss: 0.1591\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step\n",
      "ResNet18 - Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9668 - loss: 0.0027 - val_accuracy: 0.4734 - val_loss: 0.0780\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9729 - loss: 0.0017 - val_accuracy: 0.5113 - val_loss: 0.0882\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9937 - loss: 3.5984e-04 - val_accuracy: 0.5612 - val_loss: 0.0985\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 1.9368e-05 - val_accuracy: 0.5580 - val_loss: 0.1155\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 7.8398e-06 - val_accuracy: 0.5572 - val_loss: 0.1200\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 5.9701e-06 - val_accuracy: 0.5636 - val_loss: 0.1225\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 2.2673e-06 - val_accuracy: 0.5564 - val_loss: 0.1253\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 2.0037e-06 - val_accuracy: 0.5612 - val_loss: 0.1278\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 1.9617e-06 - val_accuracy: 0.5604 - val_loss: 0.1291\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 1.9376e-06 - val_accuracy: 0.5580 - val_loss: 0.1307\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 1.1906e-06 - val_accuracy: 0.5564 - val_loss: 0.1328\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 5.9113e-07 - val_accuracy: 0.5572 - val_loss: 0.1340\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 1.0899e-06 - val_accuracy: 0.5733 - val_loss: 0.1343\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 1.4032e-06 - val_accuracy: 0.5644 - val_loss: 0.1362\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 7.2547e-07 - val_accuracy: 0.5636 - val_loss: 0.1376\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 4.1885e-07 - val_accuracy: 0.5660 - val_loss: 0.1386\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 1.0923e-06 - val_accuracy: 0.5636 - val_loss: 0.1403\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 3.0784e-07 - val_accuracy: 0.5668 - val_loss: 0.1413\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 5.5605e-07 - val_accuracy: 0.5676 - val_loss: 0.1423\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 1.3320e-06 - val_accuracy: 0.5837 - val_loss: 0.1395\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9191 - loss: 0.0077 - val_accuracy: 0.4710 - val_loss: 0.0905\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 0.9935 - loss: 5.6565e-04 - val_accuracy: 0.5169 - val_loss: 0.0955\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 0.9978 - loss: 1.1815e-04 - val_accuracy: 0.5185 - val_loss: 0.1209\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 2.3922e-05 - val_accuracy: 0.5403 - val_loss: 0.1295\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 6.3871e-06 - val_accuracy: 0.5395 - val_loss: 0.1306\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 4.0569e-06 - val_accuracy: 0.5427 - val_loss: 0.1331\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 2.4086e-06 - val_accuracy: 0.5435 - val_loss: 0.1371\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 3.1494e-06 - val_accuracy: 0.5580 - val_loss: 0.1346\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 1.0237e-06 - val_accuracy: 0.5427 - val_loss: 0.1390\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 1.3170e-06 - val_accuracy: 0.5370 - val_loss: 0.1410\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 6.7078e-07 - val_accuracy: 0.5370 - val_loss: 0.1427\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 1.0126e-06 - val_accuracy: 0.5403 - val_loss: 0.1432\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 8.8708e-07 - val_accuracy: 0.5386 - val_loss: 0.1446\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 6.4207e-07 - val_accuracy: 0.5346 - val_loss: 0.1464\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 7.2639e-07 - val_accuracy: 0.5322 - val_loss: 0.1372\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 0.9277 - loss: 0.0056 - val_accuracy: 0.5250 - val_loss: 0.0951\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9937 - loss: 5.0588e-04 - val_accuracy: 0.4815 - val_loss: 0.1085\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9963 - loss: 3.3574e-04 - val_accuracy: 0.5338 - val_loss: 0.1189\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9997 - loss: 2.8168e-05 - val_accuracy: 0.5419 - val_loss: 0.1218\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 6.6972e-06 - val_accuracy: 0.5411 - val_loss: 0.1286\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 4.7458e-06 - val_accuracy: 0.5403 - val_loss: 0.1329\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 2.0943e-06 - val_accuracy: 0.5330 - val_loss: 0.1357\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.7266e-06 - val_accuracy: 0.5306 - val_loss: 0.1379\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 2.2857e-06 - val_accuracy: 0.5403 - val_loss: 0.1397\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 6.2022e-06 - val_accuracy: 0.5242 - val_loss: 0.1456\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.2733e-06 - val_accuracy: 0.5217 - val_loss: 0.1453\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.3319e-06 - val_accuracy: 0.5250 - val_loss: 0.1461\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 8.1557e-07 - val_accuracy: 0.5274 - val_loss: 0.1471\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 6.2862e-07 - val_accuracy: 0.5258 - val_loss: 0.1481\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9998 - loss: 5.6157e-06 - val_accuracy: 0.5169 - val_loss: 0.1467\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step\n",
      "ResNet18 - Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9533 - loss: 0.0034 - val_accuracy: 0.5435 - val_loss: 0.0771\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9850 - loss: 8.7387e-04 - val_accuracy: 0.5475 - val_loss: 0.0871\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9969 - loss: 1.9854e-04 - val_accuracy: 0.5652 - val_loss: 0.0807\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9989 - loss: 7.4469e-05 - val_accuracy: 0.5644 - val_loss: 0.1001\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9983 - loss: 8.5157e-05 - val_accuracy: 0.5765 - val_loss: 0.1015\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 7.3251e-06 - val_accuracy: 0.5483 - val_loss: 0.1114\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 3.7727e-06 - val_accuracy: 0.5475 - val_loss: 0.1150\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 2.7824e-06 - val_accuracy: 0.5523 - val_loss: 0.1167\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 5.1954e-06 - val_accuracy: 0.5564 - val_loss: 0.1164\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.9627e-06 - val_accuracy: 0.5572 - val_loss: 0.1189\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.2823e-06 - val_accuracy: 0.5523 - val_loss: 0.1206\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 9.5643e-07 - val_accuracy: 0.5507 - val_loss: 0.1222\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 6.1847e-07 - val_accuracy: 0.5459 - val_loss: 0.1232\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 6.2376e-07 - val_accuracy: 0.5443 - val_loss: 0.1242\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.9462e-07 - val_accuracy: 0.5459 - val_loss: 0.1252\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 4.3271e-07 - val_accuracy: 0.5515 - val_loss: 0.1266\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 3.9216e-07 - val_accuracy: 0.5556 - val_loss: 0.1273\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 4.4139e-07 - val_accuracy: 0.5499 - val_loss: 0.1281\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 3.4395e-07 - val_accuracy: 0.5467 - val_loss: 0.1286\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.8758e-07 - val_accuracy: 0.5507 - val_loss: 0.1290\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 3.3644e-07 - val_accuracy: 0.5475 - val_loss: 0.1295\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.5894e-07 - val_accuracy: 0.5491 - val_loss: 0.1302\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.4050e-07 - val_accuracy: 0.5483 - val_loss: 0.1312\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.6798e-07 - val_accuracy: 0.5459 - val_loss: 0.1320\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 3.0829e-07 - val_accuracy: 0.5588 - val_loss: 0.1315\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9989 - loss: 9.8213e-05 - val_accuracy: 0.5040 - val_loss: 0.0680\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9055 - loss: 0.0064 - val_accuracy: 0.4758 - val_loss: 0.0708\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9925 - loss: 4.6736e-04 - val_accuracy: 0.5684 - val_loss: 0.1150\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9969 - loss: 1.9500e-04 - val_accuracy: 0.5378 - val_loss: 0.1033\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9995 - loss: 4.8397e-05 - val_accuracy: 0.5556 - val_loss: 0.1071\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9939 - loss: 3.3607e-04 - val_accuracy: 0.5016 - val_loss: 0.1068\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9967 - loss: 2.5233e-04 - val_accuracy: 0.5467 - val_loss: 0.1040\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.4398e-05 - val_accuracy: 0.5475 - val_loss: 0.1168\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 5.3219e-06 - val_accuracy: 0.5395 - val_loss: 0.1209\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 2.5141e-06 - val_accuracy: 0.5427 - val_loss: 0.1234\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.2813e-06 - val_accuracy: 0.5443 - val_loss: 0.1240\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.7517e-06 - val_accuracy: 0.5451 - val_loss: 0.1262\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 1.5629e-06 - val_accuracy: 0.5386 - val_loss: 0.1266\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 7.1192e-07 - val_accuracy: 0.5435 - val_loss: 0.1283\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 8.8116e-07 - val_accuracy: 0.5395 - val_loss: 0.1288\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 6.8708e-07 - val_accuracy: 0.5403 - val_loss: 0.1305\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.7855e-07 - val_accuracy: 0.5419 - val_loss: 0.1318\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 3.4431e-07 - val_accuracy: 0.5386 - val_loss: 0.1330\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 4.0104e-07 - val_accuracy: 0.5403 - val_loss: 0.1327\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 3.3203e-07 - val_accuracy: 0.5403 - val_loss: 0.1353\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 2.5297e-07 - val_accuracy: 0.5435 - val_loss: 0.1350\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 2.3969e-07 - val_accuracy: 0.5395 - val_loss: 0.1351\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 2.8365e-07 - val_accuracy: 0.5370 - val_loss: 0.1360\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.3208e-07 - val_accuracy: 0.5395 - val_loss: 0.1370\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 2.1546e-07 - val_accuracy: 0.5378 - val_loss: 0.1373\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step\n",
      "ResNet18 - Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9302 - loss: 0.0056 - val_accuracy: 0.5105 - val_loss: 0.0840\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9761 - loss: 0.0017 - val_accuracy: 0.5072 - val_loss: 0.1132\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9954 - loss: 2.1484e-04 - val_accuracy: 0.5153 - val_loss: 0.1466\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9966 - loss: 2.3170e-04 - val_accuracy: 0.4928 - val_loss: 0.1286\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9992 - loss: 7.0717e-05 - val_accuracy: 0.4936 - val_loss: 0.1490\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 1.3487e-05 - val_accuracy: 0.5008 - val_loss: 0.1527\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 6.1603e-06 - val_accuracy: 0.4903 - val_loss: 0.1571\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 2.5242e-06 - val_accuracy: 0.5000 - val_loss: 0.1590\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9997 - loss: 8.6469e-06 - val_accuracy: 0.4936 - val_loss: 0.1601\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9991 - loss: 2.1411e-04 - val_accuracy: 0.5185 - val_loss: 0.1458\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 8.6606e-06 - val_accuracy: 0.5185 - val_loss: 0.1394\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 2.9266e-06 - val_accuracy: 0.5129 - val_loss: 0.1635\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.4508e-06 - val_accuracy: 0.5040 - val_loss: 0.1691\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.6361e-06 - val_accuracy: 0.5016 - val_loss: 0.1723\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 1.6146e-06 - val_accuracy: 0.4968 - val_loss: 0.1745\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 7.6447e-07 - val_accuracy: 0.5032 - val_loss: 0.1722\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.0678e-06 - val_accuracy: 0.4968 - val_loss: 0.1755\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 5.2147e-07 - val_accuracy: 0.5024 - val_loss: 0.1779\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.0189e-07 - val_accuracy: 0.5064 - val_loss: 0.1796\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 4.1856e-07 - val_accuracy: 0.5048 - val_loss: 0.1796\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 2.6950e-07 - val_accuracy: 0.5040 - val_loss: 0.1804\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 4.3434e-07 - val_accuracy: 0.4976 - val_loss: 0.1835\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.1747e-06 - val_accuracy: 0.4968 - val_loss: 0.1770\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9559 - loss: 0.0039 - val_accuracy: 0.4670 - val_loss: 0.1256\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9827 - loss: 9.3846e-04 - val_accuracy: 0.4952 - val_loss: 0.1263\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9959 - loss: 2.2073e-04 - val_accuracy: 0.4928 - val_loss: 0.1190\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 2.6364e-05 - val_accuracy: 0.4646 - val_loss: 0.1539\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9998 - loss: 1.6792e-05 - val_accuracy: 0.4847 - val_loss: 0.1549\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 7.5306e-06 - val_accuracy: 0.4992 - val_loss: 0.1562\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 3.7677e-06 - val_accuracy: 0.4919 - val_loss: 0.1560\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9998 - loss: 9.4784e-06 - val_accuracy: 0.5250 - val_loss: 0.1376\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9955 - loss: 3.2059e-04 - val_accuracy: 0.4678 - val_loss: 0.1464\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9896 - loss: 7.1006e-04 - val_accuracy: 0.4702 - val_loss: 0.1093\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9953 - loss: 2.5364e-04 - val_accuracy: 0.5056 - val_loss: 0.1035\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9952 - loss: 5.7767e-04 - val_accuracy: 0.4968 - val_loss: 0.1130\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9957 - loss: 2.1849e-04 - val_accuracy: 0.5024 - val_loss: 0.1422\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9981 - loss: 1.4893e-04 - val_accuracy: 0.5048 - val_loss: 0.1208\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9888 - loss: 6.2648e-04 - val_accuracy: 0.4726 - val_loss: 0.1091\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9961 - loss: 1.9313e-04 - val_accuracy: 0.5274 - val_loss: 0.1358\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9996 - loss: 3.3802e-05 - val_accuracy: 0.5097 - val_loss: 0.1380\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 6.2221e-06 - val_accuracy: 0.5121 - val_loss: 0.1437\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 2.3531e-06 - val_accuracy: 0.5161 - val_loss: 0.1442\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.2048e-06 - val_accuracy: 0.5145 - val_loss: 0.1461\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.3795e-06 - val_accuracy: 0.5153 - val_loss: 0.1472\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.1115e-06 - val_accuracy: 0.5137 - val_loss: 0.1495\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.3505e-06 - val_accuracy: 0.5072 - val_loss: 0.1527\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 8.2832e-07 - val_accuracy: 0.5121 - val_loss: 0.1506\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 6.1790e-07 - val_accuracy: 0.5145 - val_loss: 0.1536\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 9.5578e-07 - val_accuracy: 0.5225 - val_loss: 0.1517\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.6128e-06 - val_accuracy: 0.5121 - val_loss: 0.1534\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "ResNet18 - Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9580 - loss: 0.0031 - val_accuracy: 0.4851 - val_loss: 0.0937\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9802 - loss: 9.5769e-04 - val_accuracy: 0.5575 - val_loss: 0.1208\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9964 - loss: 2.2780e-04 - val_accuracy: 0.5237 - val_loss: 0.1328\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.3310e-05 - val_accuracy: 0.5447 - val_loss: 0.1378\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 6.2351e-06 - val_accuracy: 0.5398 - val_loss: 0.1373\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 3.4377e-06 - val_accuracy: 0.5390 - val_loss: 0.1415\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 2.6327e-06 - val_accuracy: 0.5390 - val_loss: 0.1446\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.3221e-06 - val_accuracy: 0.5382 - val_loss: 0.1448\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.9651e-06 - val_accuracy: 0.5390 - val_loss: 0.1466\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 1.0314e-06 - val_accuracy: 0.5390 - val_loss: 0.1482\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 1.2311e-06 - val_accuracy: 0.5390 - val_loss: 0.1491\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 8.2235e-07 - val_accuracy: 0.5390 - val_loss: 0.1511\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 7.8761e-07 - val_accuracy: 0.5366 - val_loss: 0.1521\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 7.4544e-07 - val_accuracy: 0.5390 - val_loss: 0.1525\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 4.9289e-07 - val_accuracy: 0.5366 - val_loss: 0.1549\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 6.0787e-07 - val_accuracy: 0.5350 - val_loss: 0.1562\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 4.4694e-07 - val_accuracy: 0.5358 - val_loss: 0.1567\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 2.4509e-07 - val_accuracy: 0.5358 - val_loss: 0.1575\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 4.6065e-07 - val_accuracy: 0.5350 - val_loss: 0.1598\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 2.0653e-07 - val_accuracy: 0.5374 - val_loss: 0.1596\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 1.7033e-07 - val_accuracy: 0.5374 - val_loss: 0.1603\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 2.8757e-07 - val_accuracy: 0.5358 - val_loss: 0.1610\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 4.2690e-07 - val_accuracy: 0.5479 - val_loss: 0.1583\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 2.3545e-07 - val_accuracy: 0.5350 - val_loss: 0.1632\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.7070e-07 - val_accuracy: 0.5302 - val_loss: 0.1642\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.4072e-07 - val_accuracy: 0.5302 - val_loss: 0.1650\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 9.2674e-07 - val_accuracy: 0.5093 - val_loss: 0.1579\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9725 - loss: 0.0025 - val_accuracy: 0.5318 - val_loss: 0.0757\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9789 - loss: 0.0014 - val_accuracy: 0.5543 - val_loss: 0.0836\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9981 - loss: 1.6968e-04 - val_accuracy: 0.5125 - val_loss: 0.1129\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9996 - loss: 3.1678e-05 - val_accuracy: 0.5406 - val_loss: 0.1219\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 334ms/step - accuracy: 0.9985 - loss: 8.7407e-05 - val_accuracy: 0.5294 - val_loss: 0.1144\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 335ms/step - accuracy: 0.9989 - loss: 5.4040e-05 - val_accuracy: 0.5575 - val_loss: 0.1337\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9998 - loss: 9.7695e-06 - val_accuracy: 0.5567 - val_loss: 0.1274\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 5.8801e-06 - val_accuracy: 0.5575 - val_loss: 0.1346\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9996 - loss: 4.2417e-05 - val_accuracy: 0.5245 - val_loss: 0.1317\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9951 - loss: 3.8190e-04 - val_accuracy: 0.4964 - val_loss: 0.1055\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9913 - loss: 4.9371e-04 - val_accuracy: 0.5302 - val_loss: 0.1008\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9990 - loss: 8.5125e-05 - val_accuracy: 0.5447 - val_loss: 0.1199\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9996 - loss: 3.9423e-05 - val_accuracy: 0.5245 - val_loss: 0.1361\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9998 - loss: 1.3878e-05 - val_accuracy: 0.5286 - val_loss: 0.1462\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 3.1426e-06 - val_accuracy: 0.5463 - val_loss: 0.1439\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9997 - loss: 9.7694e-06 - val_accuracy: 0.5479 - val_loss: 0.1453\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9997 - loss: 9.9934e-05 - val_accuracy: 0.5044 - val_loss: 0.1015\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9875 - loss: 8.0190e-04 - val_accuracy: 0.5245 - val_loss: 0.1135\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9982 - loss: 9.6287e-05 - val_accuracy: 0.5511 - val_loss: 0.1251\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9967 - loss: 1.8615e-04 - val_accuracy: 0.5656 - val_loss: 0.1308\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9974 - loss: 3.5846e-04 - val_accuracy: 0.5286 - val_loss: 0.0845\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9888 - loss: 5.6408e-04 - val_accuracy: 0.5414 - val_loss: 0.1113\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9972 - loss: 9.8305e-05 - val_accuracy: 0.5350 - val_loss: 0.1200\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
      "ResNet18 - Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 0.9947 - loss: 2.6787e-04 - val_accuracy: 0.5362 - val_loss: 0.1200\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9932 - loss: 3.4205e-04 - val_accuracy: 0.5435 - val_loss: 0.1181\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9997 - loss: 3.5686e-05 - val_accuracy: 0.5306 - val_loss: 0.1311\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 4.7948e-06 - val_accuracy: 0.5274 - val_loss: 0.1332\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 2.3883e-06 - val_accuracy: 0.5322 - val_loss: 0.1371\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 3.7073e-06 - val_accuracy: 0.5282 - val_loss: 0.1371\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.5154e-06 - val_accuracy: 0.5298 - val_loss: 0.1403\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.3570e-06 - val_accuracy: 0.5290 - val_loss: 0.1415\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 6.5789e-07 - val_accuracy: 0.5298 - val_loss: 0.1429\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 1.2425e-06 - val_accuracy: 0.5242 - val_loss: 0.1520\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.6664e-06 - val_accuracy: 0.5298 - val_loss: 0.1475\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 5.7129e-07 - val_accuracy: 0.5322 - val_loss: 0.1466\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 6.8354e-07 - val_accuracy: 0.5290 - val_loss: 0.1465\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 5.7262e-07 - val_accuracy: 0.5354 - val_loss: 0.1491\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 4.5757e-07 - val_accuracy: 0.5322 - val_loss: 0.1499\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.4021e-06 - val_accuracy: 0.5290 - val_loss: 0.1520\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 2.3111e-07 - val_accuracy: 0.5370 - val_loss: 0.1488\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9595 - loss: 0.0030 - val_accuracy: 0.4855 - val_loss: 0.0966\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 0.9925 - loss: 4.9601e-04 - val_accuracy: 0.5548 - val_loss: 0.1225\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9967 - loss: 3.4973e-04 - val_accuracy: 0.5193 - val_loss: 0.1105\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9957 - loss: 3.0488e-04 - val_accuracy: 0.5274 - val_loss: 0.1249\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9995 - loss: 4.7892e-05 - val_accuracy: 0.5290 - val_loss: 0.1322\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 5.5404e-06 - val_accuracy: 0.5378 - val_loss: 0.1340\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 2.3914e-06 - val_accuracy: 0.5314 - val_loss: 0.1385\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.7160e-06 - val_accuracy: 0.5314 - val_loss: 0.1407\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.4972e-06 - val_accuracy: 0.5330 - val_loss: 0.1414\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 1.0441e-06 - val_accuracy: 0.5314 - val_loss: 0.1423\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 8.4913e-07 - val_accuracy: 0.5322 - val_loss: 0.1448\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 9.4360e-07 - val_accuracy: 0.5290 - val_loss: 0.1469\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 7.8966e-07 - val_accuracy: 0.5314 - val_loss: 0.1479\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 7.7792e-07 - val_accuracy: 0.5354 - val_loss: 0.1485\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 3.2261e-07 - val_accuracy: 0.5338 - val_loss: 0.1492\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 4.3114e-07 - val_accuracy: 0.5306 - val_loss: 0.1500\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 3.9818e-07 - val_accuracy: 0.5314 - val_loss: 0.1527\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 0.9874 - loss: 9.3719e-04 - val_accuracy: 0.4960 - val_loss: 0.0888\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 0.9814 - loss: 0.0012 - val_accuracy: 0.5089 - val_loss: 0.1109\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 0.9865 - loss: 9.4705e-04 - val_accuracy: 0.5201 - val_loss: 0.1091\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9962 - loss: 4.0103e-04 - val_accuracy: 0.5072 - val_loss: 0.1155\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9966 - loss: 2.7458e-04 - val_accuracy: 0.5242 - val_loss: 0.1385\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 0.9999 - loss: 1.1200e-05 - val_accuracy: 0.5064 - val_loss: 0.1421\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 6.0148e-06 - val_accuracy: 0.5225 - val_loss: 0.1435\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 2.1290e-06 - val_accuracy: 0.5233 - val_loss: 0.1467\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 3.3479e-06 - val_accuracy: 0.5217 - val_loss: 0.1485\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.1548e-06 - val_accuracy: 0.5225 - val_loss: 0.1503\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 9.2614e-07 - val_accuracy: 0.5225 - val_loss: 0.1524\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 9.4371e-07 - val_accuracy: 0.5225 - val_loss: 0.1539\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9994 - loss: 1.0873e-04 - val_accuracy: 0.5056 - val_loss: 0.1337\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9990 - loss: 1.4337e-04 - val_accuracy: 0.5483 - val_loss: 0.1367\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9993 - loss: 2.4339e-05 - val_accuracy: 0.4895 - val_loss: 0.1471\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9993 - loss: 1.8715e-05 - val_accuracy: 0.5242 - val_loss: 0.1433\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step\n",
      "\n",
      "ResNet18 Average Results:\n",
      "Average Sensitivity: 0.7166\n",
      "Average Specificity: 0.9126\n",
      "Average Score: 0.8146\n",
      "Average Accuracy: 0.7889\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Focal loss definition\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1.0 - y_pred, gamma) * y_true\n",
    "        return tf.reduce_mean(alpha * weight * cross_entropy)\n",
    "    return focal_loss_fn\n",
    "\n",
    "# ResNet block\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1):\n",
    "    y = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = tf.keras.activations.relu(y)\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    if stride > 1 or x.shape[-1] != filters:\n",
    "        x = Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
    "    return tf.keras.activations.relu(Add()([x, y]))\n",
    "\n",
    "# ResNet18 model\n",
    "def build_resnet18(input_shape=(75, 50, 1), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 128, stride=2)\n",
    "    x = resnet_block(x, 128)\n",
    "    x = resnet_block(x, 256, stride=2)\n",
    "    x = resnet_block(x, 256)\n",
    "    x = resnet_block(x, 512, stride=2)\n",
    "    x = resnet_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Load spectrograms and labels\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "patient_ids = np.load(os.path.join(spectrograms_dir, \"patient_ids.npy\"))\n",
    "\n",
    "# Prepare data\n",
    "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=4)\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "folds = list(gkf.split(spectrograms_resized, labels, groups=patient_ids))\n",
    "\n",
    "# Train and evaluate ResNet18\n",
    "resnet18 = build_resnet18()\n",
    "resnet18.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(gamma=2.0), metrics=['accuracy'])\n",
    "resnet18.summary()\n",
    "\n",
    "sensitivity_list, specificity_list, score_list, accuracy_list = [], [], [], []\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "    X_train, X_test = spectrograms_resized[train_idx], spectrograms_resized[test_idx]\n",
    "    y_train, y_test = labels_one_hot[train_idx], labels_one_hot[test_idx]\n",
    "    \n",
    "    print(f\"ResNet18 - Training fold {fold_idx + 1}/10\")\n",
    "    resnet18.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    y_pred = resnet18.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    sensitivity = np.mean(TP / (TP + FN + 1e-10))\n",
    "    specificity = np.mean(TN / (TN + FP + 1e-10))\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    score_list.append(score)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "print(\"\\nResNet18 Average Results:\")\n",
    "print(f\"Average Sensitivity: {np.mean(sensitivity_list):.4f}\")\n",
    "print(f\"Average Specificity: {np.mean(specificity_list):.4f}\")\n",
    "print(f\"Average Score: {np.mean(score_list):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-Mel - Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.4368 - loss: 0.3497 - val_accuracy: 0.6006 - val_loss: 0.0440\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.4808 - loss: 0.0413 - val_accuracy: 0.6031 - val_loss: 0.0421\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4991 - loss: 0.0397 - val_accuracy: 0.5998 - val_loss: 0.0444\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5012 - loss: 0.0403 - val_accuracy: 0.6031 - val_loss: 0.0429\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5229 - loss: 0.0386 - val_accuracy: 0.6031 - val_loss: 0.0437\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5244 - loss: 0.0390 - val_accuracy: 0.6031 - val_loss: 0.0435\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5291 - loss: 0.0386 - val_accuracy: 0.6031 - val_loss: 0.0424\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5377 - loss: 0.0381 - val_accuracy: 0.6031 - val_loss: 0.0419\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5348 - loss: 0.0379 - val_accuracy: 0.6031 - val_loss: 0.0414\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5270 - loss: 0.0382 - val_accuracy: 0.6031 - val_loss: 0.0414\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5428 - loss: 0.0379 - val_accuracy: 0.6031 - val_loss: 0.0426\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5297 - loss: 0.0383 - val_accuracy: 0.6031 - val_loss: 0.0401\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5349 - loss: 0.0385 - val_accuracy: 0.6031 - val_loss: 0.0403\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5376 - loss: 0.0379 - val_accuracy: 0.6031 - val_loss: 0.0409\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5351 - loss: 0.0378 - val_accuracy: 0.6031 - val_loss: 0.0400\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5463 - loss: 0.0367 - val_accuracy: 0.6031 - val_loss: 0.0405\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5404 - loss: 0.0375 - val_accuracy: 0.6031 - val_loss: 0.0398\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5346 - loss: 0.0374 - val_accuracy: 0.6031 - val_loss: 0.0395\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5478 - loss: 0.0367 - val_accuracy: 0.6031 - val_loss: 0.0384\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5394 - loss: 0.0375 - val_accuracy: 0.6031 - val_loss: 0.0388\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5452 - loss: 0.0362 - val_accuracy: 0.6031 - val_loss: 0.0389\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5237 - loss: 0.0374 - val_accuracy: 0.6031 - val_loss: 0.0382\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5278 - loss: 0.0369 - val_accuracy: 0.6031 - val_loss: 0.0372\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5448 - loss: 0.0366 - val_accuracy: 0.6031 - val_loss: 0.0378\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5467 - loss: 0.0360 - val_accuracy: 0.6031 - val_loss: 0.0379\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5496 - loss: 0.0355 - val_accuracy: 0.6031 - val_loss: 0.0383\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.0361 - val_accuracy: 0.6031 - val_loss: 0.0385\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5420 - loss: 0.0360 - val_accuracy: 0.6031 - val_loss: 0.0391\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5343 - loss: 0.0357 - val_accuracy: 0.6031 - val_loss: 0.0396\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5355 - loss: 0.0364 - val_accuracy: 0.6031 - val_loss: 0.0391\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5510 - loss: 0.0362 - val_accuracy: 0.6031 - val_loss: 0.0402\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5373 - loss: 0.0357 - val_accuracy: 0.6031 - val_loss: 0.0411\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5269 - loss: 0.0364 - val_accuracy: 0.6031 - val_loss: 0.0405\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5327 - loss: 0.0355 - val_accuracy: 0.6031 - val_loss: 0.0400\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5434 - loss: 0.0354 - val_accuracy: 0.6031 - val_loss: 0.0408\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5430 - loss: 0.0350 - val_accuracy: 0.6031 - val_loss: 0.0406\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5553 - loss: 0.0343 - val_accuracy: 0.6039 - val_loss: 0.0402\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5363 - loss: 0.0348 - val_accuracy: 0.6031 - val_loss: 0.0415\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5434 - loss: 0.0343 - val_accuracy: 0.6031 - val_loss: 0.0396\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5513 - loss: 0.0342 - val_accuracy: 0.6031 - val_loss: 0.0405\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5388 - loss: 0.0345 - val_accuracy: 0.6031 - val_loss: 0.0388\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5413 - loss: 0.0349 - val_accuracy: 0.6031 - val_loss: 0.0398\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5390 - loss: 0.0336 - val_accuracy: 0.6031 - val_loss: 0.0393\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5389 - loss: 0.0340 - val_accuracy: 0.6047 - val_loss: 0.0394\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5332 - loss: 0.0338 - val_accuracy: 0.6031 - val_loss: 0.0393\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5353 - loss: 0.0340 - val_accuracy: 0.6023 - val_loss: 0.0374\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5378 - loss: 0.0344 - val_accuracy: 0.5998 - val_loss: 0.0374\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5310 - loss: 0.0342 - val_accuracy: 0.6039 - val_loss: 0.0356\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5363 - loss: 0.0330 - val_accuracy: 0.6031 - val_loss: 0.0361\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5405 - loss: 0.0320 - val_accuracy: 0.6047 - val_loss: 0.0344\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "CNN-Mel - Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5116 - loss: 0.0337 - val_accuracy: 0.5813 - val_loss: 0.0356\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5144 - loss: 0.0338 - val_accuracy: 0.5797 - val_loss: 0.0346\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5172 - loss: 0.0327 - val_accuracy: 0.5821 - val_loss: 0.0341\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5346 - loss: 0.0318 - val_accuracy: 0.5789 - val_loss: 0.0348\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5003 - loss: 0.0328 - val_accuracy: 0.5837 - val_loss: 0.0350\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5246 - loss: 0.0312 - val_accuracy: 0.5709 - val_loss: 0.0349\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5170 - loss: 0.0324 - val_accuracy: 0.5781 - val_loss: 0.0340\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5284 - loss: 0.0309 - val_accuracy: 0.5741 - val_loss: 0.0342\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5086 - loss: 0.0308 - val_accuracy: 0.5781 - val_loss: 0.0346\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5347 - loss: 0.0296 - val_accuracy: 0.5628 - val_loss: 0.0339\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5235 - loss: 0.0307 - val_accuracy: 0.5813 - val_loss: 0.0359\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5333 - loss: 0.0298 - val_accuracy: 0.5660 - val_loss: 0.0347\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5356 - loss: 0.0298 - val_accuracy: 0.5507 - val_loss: 0.0348\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5403 - loss: 0.0287 - val_accuracy: 0.5805 - val_loss: 0.0351\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5481 - loss: 0.0292 - val_accuracy: 0.5700 - val_loss: 0.0343\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5599 - loss: 0.0285 - val_accuracy: 0.5757 - val_loss: 0.0336\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5389 - loss: 0.0280 - val_accuracy: 0.5692 - val_loss: 0.0333\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.5459 - loss: 0.0275 - val_accuracy: 0.5660 - val_loss: 0.0348\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.5544 - loss: 0.0266 - val_accuracy: 0.5628 - val_loss: 0.0350\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5511 - loss: 0.0278 - val_accuracy: 0.5725 - val_loss: 0.0368\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5812 - loss: 0.0259 - val_accuracy: 0.5636 - val_loss: 0.0354\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5851 - loss: 0.0257 - val_accuracy: 0.5572 - val_loss: 0.0348\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5799 - loss: 0.0253 - val_accuracy: 0.5628 - val_loss: 0.0354\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5819 - loss: 0.0251 - val_accuracy: 0.5733 - val_loss: 0.0365\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5865 - loss: 0.0254 - val_accuracy: 0.5475 - val_loss: 0.0354\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.5926 - loss: 0.0249 - val_accuracy: 0.5628 - val_loss: 0.0353\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6054 - loss: 0.0241 - val_accuracy: 0.5612 - val_loss: 0.0369\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6134 - loss: 0.0234 - val_accuracy: 0.5676 - val_loss: 0.0363\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6011 - loss: 0.0245 - val_accuracy: 0.5515 - val_loss: 0.0358\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6167 - loss: 0.0236 - val_accuracy: 0.5652 - val_loss: 0.0360\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6294 - loss: 0.0222 - val_accuracy: 0.5298 - val_loss: 0.0363\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6284 - loss: 0.0229 - val_accuracy: 0.5564 - val_loss: 0.0373\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6474 - loss: 0.0215 - val_accuracy: 0.5539 - val_loss: 0.0367\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6312 - loss: 0.0222 - val_accuracy: 0.5515 - val_loss: 0.0377\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6437 - loss: 0.0219 - val_accuracy: 0.5491 - val_loss: 0.0363\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6512 - loss: 0.0209 - val_accuracy: 0.5395 - val_loss: 0.0366\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6451 - loss: 0.0221 - val_accuracy: 0.5700 - val_loss: 0.0383\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6341 - loss: 0.0212 - val_accuracy: 0.5628 - val_loss: 0.0372\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6526 - loss: 0.0206 - val_accuracy: 0.5475 - val_loss: 0.0383\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6594 - loss: 0.0210 - val_accuracy: 0.5692 - val_loss: 0.0374\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6739 - loss: 0.0195 - val_accuracy: 0.5411 - val_loss: 0.0353\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6810 - loss: 0.0190 - val_accuracy: 0.5548 - val_loss: 0.0392\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6555 - loss: 0.0195 - val_accuracy: 0.5378 - val_loss: 0.0391\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6775 - loss: 0.0194 - val_accuracy: 0.5459 - val_loss: 0.0371\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6995 - loss: 0.0183 - val_accuracy: 0.5548 - val_loss: 0.0397\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6807 - loss: 0.0184 - val_accuracy: 0.5451 - val_loss: 0.0395\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6847 - loss: 0.0186 - val_accuracy: 0.5362 - val_loss: 0.0388\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6915 - loss: 0.0180 - val_accuracy: 0.5459 - val_loss: 0.0432\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6863 - loss: 0.0185 - val_accuracy: 0.5475 - val_loss: 0.0386\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6943 - loss: 0.0183 - val_accuracy: 0.5354 - val_loss: 0.0428\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CNN-Mel - Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6939 - loss: 0.0198 - val_accuracy: 0.5612 - val_loss: 0.0367\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.6869 - loss: 0.0191 - val_accuracy: 0.5660 - val_loss: 0.0367\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7141 - loss: 0.0174 - val_accuracy: 0.5821 - val_loss: 0.0358\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.6913 - loss: 0.0179 - val_accuracy: 0.5910 - val_loss: 0.0368\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7203 - loss: 0.0170 - val_accuracy: 0.5564 - val_loss: 0.0362\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7179 - loss: 0.0166 - val_accuracy: 0.5531 - val_loss: 0.0383\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7263 - loss: 0.0163 - val_accuracy: 0.5709 - val_loss: 0.0373\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7250 - loss: 0.0158 - val_accuracy: 0.5668 - val_loss: 0.0370\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7341 - loss: 0.0158 - val_accuracy: 0.5636 - val_loss: 0.0376\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7275 - loss: 0.0158 - val_accuracy: 0.5926 - val_loss: 0.0405\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7243 - loss: 0.0154 - val_accuracy: 0.5403 - val_loss: 0.0393\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7340 - loss: 0.0152 - val_accuracy: 0.5580 - val_loss: 0.0390\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7343 - loss: 0.0148 - val_accuracy: 0.5749 - val_loss: 0.0398\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7528 - loss: 0.0139 - val_accuracy: 0.5322 - val_loss: 0.0400\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7465 - loss: 0.0144 - val_accuracy: 0.5483 - val_loss: 0.0404\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7376 - loss: 0.0145 - val_accuracy: 0.5564 - val_loss: 0.0381\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7506 - loss: 0.0140 - val_accuracy: 0.5515 - val_loss: 0.0388\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7659 - loss: 0.0128 - val_accuracy: 0.5652 - val_loss: 0.0397\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7608 - loss: 0.0131 - val_accuracy: 0.5588 - val_loss: 0.0375\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7617 - loss: 0.0131 - val_accuracy: 0.5612 - val_loss: 0.0410\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7649 - loss: 0.0131 - val_accuracy: 0.5733 - val_loss: 0.0400\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7682 - loss: 0.0131 - val_accuracy: 0.5636 - val_loss: 0.0407\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7774 - loss: 0.0123 - val_accuracy: 0.5676 - val_loss: 0.0406\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7795 - loss: 0.0128 - val_accuracy: 0.5741 - val_loss: 0.0445\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7824 - loss: 0.0120 - val_accuracy: 0.5741 - val_loss: 0.0453\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.7781 - loss: 0.0118 - val_accuracy: 0.5821 - val_loss: 0.0426\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7929 - loss: 0.0112 - val_accuracy: 0.5845 - val_loss: 0.0418\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7995 - loss: 0.0106 - val_accuracy: 0.5499 - val_loss: 0.0445\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7931 - loss: 0.0111 - val_accuracy: 0.5773 - val_loss: 0.0430\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7842 - loss: 0.0108 - val_accuracy: 0.6006 - val_loss: 0.0457\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7888 - loss: 0.0112 - val_accuracy: 0.5684 - val_loss: 0.0447\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8141 - loss: 0.0100 - val_accuracy: 0.5733 - val_loss: 0.0447\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8083 - loss: 0.0101 - val_accuracy: 0.5564 - val_loss: 0.0449\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8063 - loss: 0.0103 - val_accuracy: 0.5862 - val_loss: 0.0426\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8099 - loss: 0.0102 - val_accuracy: 0.5757 - val_loss: 0.0448\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8091 - loss: 0.0096 - val_accuracy: 0.5837 - val_loss: 0.0456\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8053 - loss: 0.0098 - val_accuracy: 0.5644 - val_loss: 0.0489\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8184 - loss: 0.0090 - val_accuracy: 0.5676 - val_loss: 0.0472\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8143 - loss: 0.0093 - val_accuracy: 0.5531 - val_loss: 0.0479\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8317 - loss: 0.0090 - val_accuracy: 0.5612 - val_loss: 0.0468\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8245 - loss: 0.0087 - val_accuracy: 0.5829 - val_loss: 0.0498\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8245 - loss: 0.0090 - val_accuracy: 0.5870 - val_loss: 0.0494\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8302 - loss: 0.0087 - val_accuracy: 0.5467 - val_loss: 0.0511\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8238 - loss: 0.0089 - val_accuracy: 0.5773 - val_loss: 0.0504\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8447 - loss: 0.0084 - val_accuracy: 0.5765 - val_loss: 0.0536\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8336 - loss: 0.0081 - val_accuracy: 0.5684 - val_loss: 0.0507\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8360 - loss: 0.0086 - val_accuracy: 0.5620 - val_loss: 0.0519\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8481 - loss: 0.0081 - val_accuracy: 0.5548 - val_loss: 0.0525\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8423 - loss: 0.0080 - val_accuracy: 0.5676 - val_loss: 0.0525\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8487 - loss: 0.0076 - val_accuracy: 0.5507 - val_loss: 0.0540\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "CNN-Mel - Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.7956 - loss: 0.0130 - val_accuracy: 0.6006 - val_loss: 0.0499\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8235 - loss: 0.0102 - val_accuracy: 0.5870 - val_loss: 0.0483\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8223 - loss: 0.0104 - val_accuracy: 0.6192 - val_loss: 0.0493\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8349 - loss: 0.0091 - val_accuracy: 0.5942 - val_loss: 0.0499\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8353 - loss: 0.0090 - val_accuracy: 0.5894 - val_loss: 0.0537\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8248 - loss: 0.0095 - val_accuracy: 0.5813 - val_loss: 0.0517\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8524 - loss: 0.0084 - val_accuracy: 0.5781 - val_loss: 0.0490\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8546 - loss: 0.0077 - val_accuracy: 0.5789 - val_loss: 0.0521\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8502 - loss: 0.0083 - val_accuracy: 0.5709 - val_loss: 0.0543\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8496 - loss: 0.0082 - val_accuracy: 0.5733 - val_loss: 0.0530\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.8462 - loss: 0.0079 - val_accuracy: 0.5894 - val_loss: 0.0512\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8659 - loss: 0.0068 - val_accuracy: 0.5813 - val_loss: 0.0536\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8560 - loss: 0.0073 - val_accuracy: 0.5829 - val_loss: 0.0557\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8581 - loss: 0.0073 - val_accuracy: 0.5797 - val_loss: 0.0543\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8642 - loss: 0.0071 - val_accuracy: 0.5829 - val_loss: 0.0519\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8593 - loss: 0.0073 - val_accuracy: 0.5773 - val_loss: 0.0581\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8713 - loss: 0.0066 - val_accuracy: 0.5789 - val_loss: 0.0590\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8660 - loss: 0.0067 - val_accuracy: 0.5918 - val_loss: 0.0651\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8757 - loss: 0.0066 - val_accuracy: 0.5821 - val_loss: 0.0594\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8781 - loss: 0.0065 - val_accuracy: 0.5684 - val_loss: 0.0537\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8760 - loss: 0.0060 - val_accuracy: 0.5741 - val_loss: 0.0670\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8769 - loss: 0.0062 - val_accuracy: 0.5789 - val_loss: 0.0621\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8828 - loss: 0.0061 - val_accuracy: 0.5692 - val_loss: 0.0613\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8726 - loss: 0.0063 - val_accuracy: 0.5781 - val_loss: 0.0633\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8840 - loss: 0.0060 - val_accuracy: 0.5813 - val_loss: 0.0666\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8812 - loss: 0.0056 - val_accuracy: 0.5845 - val_loss: 0.0646\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8802 - loss: 0.0060 - val_accuracy: 0.5813 - val_loss: 0.0620\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8849 - loss: 0.0056 - val_accuracy: 0.5837 - val_loss: 0.0665\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8881 - loss: 0.0059 - val_accuracy: 0.5837 - val_loss: 0.0673\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8795 - loss: 0.0058 - val_accuracy: 0.5829 - val_loss: 0.0643\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8959 - loss: 0.0056 - val_accuracy: 0.5837 - val_loss: 0.0627\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8956 - loss: 0.0055 - val_accuracy: 0.5749 - val_loss: 0.0657\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8945 - loss: 0.0055 - val_accuracy: 0.5765 - val_loss: 0.0684\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8988 - loss: 0.0051 - val_accuracy: 0.5628 - val_loss: 0.0646\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8932 - loss: 0.0054 - val_accuracy: 0.5773 - val_loss: 0.0675\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9031 - loss: 0.0051 - val_accuracy: 0.5789 - val_loss: 0.0671\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9013 - loss: 0.0050 - val_accuracy: 0.5781 - val_loss: 0.0721\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9107 - loss: 0.0046 - val_accuracy: 0.5765 - val_loss: 0.0634\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9064 - loss: 0.0044 - val_accuracy: 0.5668 - val_loss: 0.0716\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9084 - loss: 0.0044 - val_accuracy: 0.5837 - val_loss: 0.0662\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9098 - loss: 0.0045 - val_accuracy: 0.5725 - val_loss: 0.0728\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9070 - loss: 0.0047 - val_accuracy: 0.5749 - val_loss: 0.0625\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9074 - loss: 0.0047 - val_accuracy: 0.5636 - val_loss: 0.0717\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9146 - loss: 0.0040 - val_accuracy: 0.5870 - val_loss: 0.0715\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9128 - loss: 0.0042 - val_accuracy: 0.5765 - val_loss: 0.0667\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9127 - loss: 0.0042 - val_accuracy: 0.5676 - val_loss: 0.0729\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9158 - loss: 0.0044 - val_accuracy: 0.5628 - val_loss: 0.0731\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9181 - loss: 0.0038 - val_accuracy: 0.5700 - val_loss: 0.0744\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9187 - loss: 0.0042 - val_accuracy: 0.5692 - val_loss: 0.0699\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9188 - loss: 0.0042 - val_accuracy: 0.5660 - val_loss: 0.0757\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CNN-Mel - Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8844 - loss: 0.0068 - val_accuracy: 0.5717 - val_loss: 0.0639\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8792 - loss: 0.0067 - val_accuracy: 0.5757 - val_loss: 0.0780\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8988 - loss: 0.0057 - val_accuracy: 0.5773 - val_loss: 0.0737\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9024 - loss: 0.0054 - val_accuracy: 0.5749 - val_loss: 0.0732\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8970 - loss: 0.0054 - val_accuracy: 0.5692 - val_loss: 0.0751\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.8959 - loss: 0.0053 - val_accuracy: 0.5878 - val_loss: 0.0769\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.8965 - loss: 0.0049 - val_accuracy: 0.5845 - val_loss: 0.0695\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9084 - loss: 0.0046 - val_accuracy: 0.5853 - val_loss: 0.0751\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9132 - loss: 0.0043 - val_accuracy: 0.5910 - val_loss: 0.0783\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9275 - loss: 0.0040 - val_accuracy: 0.5918 - val_loss: 0.0723\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9163 - loss: 0.0045 - val_accuracy: 0.5910 - val_loss: 0.0797\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9138 - loss: 0.0047 - val_accuracy: 0.5652 - val_loss: 0.0775\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9152 - loss: 0.0046 - val_accuracy: 0.5926 - val_loss: 0.0756\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9251 - loss: 0.0041 - val_accuracy: 0.5894 - val_loss: 0.0777\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9148 - loss: 0.0043 - val_accuracy: 0.5902 - val_loss: 0.0800\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9229 - loss: 0.0043 - val_accuracy: 0.5717 - val_loss: 0.0827\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9210 - loss: 0.0042 - val_accuracy: 0.5725 - val_loss: 0.0794\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9216 - loss: 0.0041 - val_accuracy: 0.5709 - val_loss: 0.0789\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9245 - loss: 0.0040 - val_accuracy: 0.5870 - val_loss: 0.0709\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9177 - loss: 0.0041 - val_accuracy: 0.5837 - val_loss: 0.0778\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9273 - loss: 0.0038 - val_accuracy: 0.5700 - val_loss: 0.0760\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9165 - loss: 0.0045 - val_accuracy: 0.5902 - val_loss: 0.0861\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9236 - loss: 0.0037 - val_accuracy: 0.5942 - val_loss: 0.0777\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9309 - loss: 0.0035 - val_accuracy: 0.5934 - val_loss: 0.0883\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9385 - loss: 0.0034 - val_accuracy: 0.5845 - val_loss: 0.0888\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9379 - loss: 0.0032 - val_accuracy: 0.5886 - val_loss: 0.0837\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9346 - loss: 0.0032 - val_accuracy: 0.5700 - val_loss: 0.0822\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9299 - loss: 0.0038 - val_accuracy: 0.5862 - val_loss: 0.0820\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9353 - loss: 0.0034 - val_accuracy: 0.5692 - val_loss: 0.0836\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9259 - loss: 0.0039 - val_accuracy: 0.5781 - val_loss: 0.0838\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9349 - loss: 0.0034 - val_accuracy: 0.5797 - val_loss: 0.0859\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9428 - loss: 0.0030 - val_accuracy: 0.5781 - val_loss: 0.0877\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9341 - loss: 0.0031 - val_accuracy: 0.5660 - val_loss: 0.0837\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.9427 - loss: 0.0032 - val_accuracy: 0.5845 - val_loss: 0.0794\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9378 - loss: 0.0031 - val_accuracy: 0.5652 - val_loss: 0.0811\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9436 - loss: 0.0030 - val_accuracy: 0.5845 - val_loss: 0.0822\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9525 - loss: 0.0027 - val_accuracy: 0.5845 - val_loss: 0.0792\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9378 - loss: 0.0033 - val_accuracy: 0.5845 - val_loss: 0.0869\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9478 - loss: 0.0027 - val_accuracy: 0.5733 - val_loss: 0.0888\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9350 - loss: 0.0032 - val_accuracy: 0.5757 - val_loss: 0.0867\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9332 - loss: 0.0032 - val_accuracy: 0.5612 - val_loss: 0.0855\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9317 - loss: 0.0042 - val_accuracy: 0.5652 - val_loss: 0.0881\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9448 - loss: 0.0031 - val_accuracy: 0.5773 - val_loss: 0.0854\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9490 - loss: 0.0026 - val_accuracy: 0.5725 - val_loss: 0.0904\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9418 - loss: 0.0033 - val_accuracy: 0.5725 - val_loss: 0.0894\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9454 - loss: 0.0028 - val_accuracy: 0.5894 - val_loss: 0.0928\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9492 - loss: 0.0026 - val_accuracy: 0.5749 - val_loss: 0.0972\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9410 - loss: 0.0030 - val_accuracy: 0.5781 - val_loss: 0.0890\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9501 - loss: 0.0025 - val_accuracy: 0.5805 - val_loss: 0.0830\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9526 - loss: 0.0029 - val_accuracy: 0.5709 - val_loss: 0.0838\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CNN-Mel - Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9325 - loss: 0.0037 - val_accuracy: 0.6023 - val_loss: 0.0697\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.9420 - loss: 0.0033 - val_accuracy: 0.5958 - val_loss: 0.0730\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9414 - loss: 0.0032 - val_accuracy: 0.6119 - val_loss: 0.0756\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9458 - loss: 0.0034 - val_accuracy: 0.6014 - val_loss: 0.0679\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9403 - loss: 0.0029 - val_accuracy: 0.6006 - val_loss: 0.0706\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9412 - loss: 0.0030 - val_accuracy: 0.6159 - val_loss: 0.0742\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9455 - loss: 0.0028 - val_accuracy: 0.6111 - val_loss: 0.0749\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9461 - loss: 0.0028 - val_accuracy: 0.6208 - val_loss: 0.0735\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9457 - loss: 0.0026 - val_accuracy: 0.6264 - val_loss: 0.0797\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9441 - loss: 0.0025 - val_accuracy: 0.6143 - val_loss: 0.0692\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9397 - loss: 0.0028 - val_accuracy: 0.6111 - val_loss: 0.0825\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.9572 - loss: 0.0022 - val_accuracy: 0.6095 - val_loss: 0.0729\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9476 - loss: 0.0029 - val_accuracy: 0.6184 - val_loss: 0.0851\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9480 - loss: 0.0025 - val_accuracy: 0.6095 - val_loss: 0.0770\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.9549 - loss: 0.0025 - val_accuracy: 0.6184 - val_loss: 0.0790\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9509 - loss: 0.0023 - val_accuracy: 0.6063 - val_loss: 0.0780\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9535 - loss: 0.0025 - val_accuracy: 0.6063 - val_loss: 0.0793\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9488 - loss: 0.0031 - val_accuracy: 0.6031 - val_loss: 0.0759\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9491 - loss: 0.0027 - val_accuracy: 0.6031 - val_loss: 0.0774\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9519 - loss: 0.0023 - val_accuracy: 0.6039 - val_loss: 0.0780\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9588 - loss: 0.0022 - val_accuracy: 0.6103 - val_loss: 0.0717\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9573 - loss: 0.0022 - val_accuracy: 0.5942 - val_loss: 0.0819\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9545 - loss: 0.0024 - val_accuracy: 0.6071 - val_loss: 0.0818\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9571 - loss: 0.0023 - val_accuracy: 0.6159 - val_loss: 0.0840\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9572 - loss: 0.0022 - val_accuracy: 0.6143 - val_loss: 0.0789\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.9521 - loss: 0.0024 - val_accuracy: 0.6208 - val_loss: 0.0810\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9568 - loss: 0.0022 - val_accuracy: 0.6063 - val_loss: 0.0830\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9506 - loss: 0.0024 - val_accuracy: 0.6006 - val_loss: 0.0773\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9537 - loss: 0.0025 - val_accuracy: 0.6143 - val_loss: 0.0789\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9533 - loss: 0.0023 - val_accuracy: 0.6296 - val_loss: 0.0833\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9617 - loss: 0.0022 - val_accuracy: 0.6103 - val_loss: 0.0780\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9585 - loss: 0.0019 - val_accuracy: 0.6095 - val_loss: 0.0837\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9564 - loss: 0.0024 - val_accuracy: 0.6159 - val_loss: 0.0766\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9616 - loss: 0.0021 - val_accuracy: 0.6039 - val_loss: 0.0749\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9668 - loss: 0.0021 - val_accuracy: 0.5974 - val_loss: 0.0787\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9591 - loss: 0.0020 - val_accuracy: 0.6111 - val_loss: 0.0837\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9576 - loss: 0.0023 - val_accuracy: 0.6014 - val_loss: 0.0829\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9547 - loss: 0.0021 - val_accuracy: 0.6111 - val_loss: 0.0815\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9655 - loss: 0.0019 - val_accuracy: 0.6143 - val_loss: 0.0863\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9617 - loss: 0.0020 - val_accuracy: 0.6103 - val_loss: 0.0851\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9511 - loss: 0.0021 - val_accuracy: 0.6119 - val_loss: 0.0869\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9627 - loss: 0.0019 - val_accuracy: 0.6006 - val_loss: 0.0806\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9565 - loss: 0.0022 - val_accuracy: 0.5878 - val_loss: 0.0852\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9648 - loss: 0.0020 - val_accuracy: 0.6095 - val_loss: 0.0850\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9595 - loss: 0.0019 - val_accuracy: 0.6111 - val_loss: 0.0936\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9680 - loss: 0.0018 - val_accuracy: 0.5974 - val_loss: 0.0868\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9609 - loss: 0.0020 - val_accuracy: 0.5998 - val_loss: 0.0847\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9653 - loss: 0.0019 - val_accuracy: 0.6127 - val_loss: 0.0834\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9610 - loss: 0.0020 - val_accuracy: 0.6224 - val_loss: 0.0829\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9686 - loss: 0.0017 - val_accuracy: 0.6208 - val_loss: 0.0829\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CNN-Mel - Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.9546 - loss: 0.0022 - val_accuracy: 0.6087 - val_loss: 0.0635\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9565 - loss: 0.0021 - val_accuracy: 0.6264 - val_loss: 0.0700\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9592 - loss: 0.0023 - val_accuracy: 0.6264 - val_loss: 0.0661\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9495 - loss: 0.0023 - val_accuracy: 0.6224 - val_loss: 0.0626\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9649 - loss: 0.0020 - val_accuracy: 0.6167 - val_loss: 0.0644\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9646 - loss: 0.0020 - val_accuracy: 0.6127 - val_loss: 0.0642\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9534 - loss: 0.0023 - val_accuracy: 0.6087 - val_loss: 0.0573\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9611 - loss: 0.0021 - val_accuracy: 0.6320 - val_loss: 0.0657\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9635 - loss: 0.0020 - val_accuracy: 0.6127 - val_loss: 0.0658\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9641 - loss: 0.0016 - val_accuracy: 0.6095 - val_loss: 0.0648\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9684 - loss: 0.0018 - val_accuracy: 0.6095 - val_loss: 0.0637\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9631 - loss: 0.0019 - val_accuracy: 0.6135 - val_loss: 0.0664\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9636 - loss: 0.0021 - val_accuracy: 0.6111 - val_loss: 0.0643\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9684 - loss: 0.0017 - val_accuracy: 0.6063 - val_loss: 0.0676\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9583 - loss: 0.0023 - val_accuracy: 0.6119 - val_loss: 0.0701\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9664 - loss: 0.0020 - val_accuracy: 0.6143 - val_loss: 0.0678\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9622 - loss: 0.0018 - val_accuracy: 0.6063 - val_loss: 0.0640\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9568 - loss: 0.0022 - val_accuracy: 0.6176 - val_loss: 0.0677\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9610 - loss: 0.0023 - val_accuracy: 0.6071 - val_loss: 0.0707\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9704 - loss: 0.0014 - val_accuracy: 0.6095 - val_loss: 0.0681\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9680 - loss: 0.0015 - val_accuracy: 0.6039 - val_loss: 0.0633\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9655 - loss: 0.0019 - val_accuracy: 0.6103 - val_loss: 0.0681\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9606 - loss: 0.0022 - val_accuracy: 0.6095 - val_loss: 0.0690\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9643 - loss: 0.0017 - val_accuracy: 0.6272 - val_loss: 0.0668\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9676 - loss: 0.0018 - val_accuracy: 0.6071 - val_loss: 0.0623\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9692 - loss: 0.0015 - val_accuracy: 0.6320 - val_loss: 0.0693\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9679 - loss: 0.0017 - val_accuracy: 0.6232 - val_loss: 0.0735\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9655 - loss: 0.0018 - val_accuracy: 0.6087 - val_loss: 0.0710\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9626 - loss: 0.0018 - val_accuracy: 0.6280 - val_loss: 0.0662\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9645 - loss: 0.0019 - val_accuracy: 0.6176 - val_loss: 0.0679\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9682 - loss: 0.0017 - val_accuracy: 0.6240 - val_loss: 0.0713\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9592 - loss: 0.0019 - val_accuracy: 0.6047 - val_loss: 0.0705\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9706 - loss: 0.0017 - val_accuracy: 0.6014 - val_loss: 0.0688\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9640 - loss: 0.0021 - val_accuracy: 0.6079 - val_loss: 0.0705\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9699 - loss: 0.0014 - val_accuracy: 0.6014 - val_loss: 0.0719\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9729 - loss: 0.0014 - val_accuracy: 0.6095 - val_loss: 0.0753\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9761 - loss: 0.0012 - val_accuracy: 0.6176 - val_loss: 0.0715\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9711 - loss: 0.0017 - val_accuracy: 0.6095 - val_loss: 0.0659\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9694 - loss: 0.0017 - val_accuracy: 0.6014 - val_loss: 0.0693\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9756 - loss: 0.0013 - val_accuracy: 0.6264 - val_loss: 0.0646\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9707 - loss: 0.0016 - val_accuracy: 0.6264 - val_loss: 0.0724\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9724 - loss: 0.0017 - val_accuracy: 0.6176 - val_loss: 0.0706\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9718 - loss: 0.0018 - val_accuracy: 0.6127 - val_loss: 0.0714\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9685 - loss: 0.0017 - val_accuracy: 0.6159 - val_loss: 0.0669\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9729 - loss: 0.0017 - val_accuracy: 0.6111 - val_loss: 0.0706\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9694 - loss: 0.0018 - val_accuracy: 0.6055 - val_loss: 0.0702\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9689 - loss: 0.0016 - val_accuracy: 0.6232 - val_loss: 0.0747\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9702 - loss: 0.0015 - val_accuracy: 0.6184 - val_loss: 0.0720\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9657 - loss: 0.0018 - val_accuracy: 0.6127 - val_loss: 0.0685\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9737 - loss: 0.0012 - val_accuracy: 0.6103 - val_loss: 0.0766\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "CNN-Mel - Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9545 - loss: 0.0030 - val_accuracy: 0.5564 - val_loss: 0.0927\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9611 - loss: 0.0022 - val_accuracy: 0.5628 - val_loss: 0.1000\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9601 - loss: 0.0022 - val_accuracy: 0.5749 - val_loss: 0.0972\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9629 - loss: 0.0021 - val_accuracy: 0.5564 - val_loss: 0.1037\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9682 - loss: 0.0017 - val_accuracy: 0.5636 - val_loss: 0.1029\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9660 - loss: 0.0018 - val_accuracy: 0.5652 - val_loss: 0.1019\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9671 - loss: 0.0017 - val_accuracy: 0.5604 - val_loss: 0.1042\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9651 - loss: 0.0018 - val_accuracy: 0.5652 - val_loss: 0.1120\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9686 - loss: 0.0018 - val_accuracy: 0.5709 - val_loss: 0.1045\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9666 - loss: 0.0016 - val_accuracy: 0.5564 - val_loss: 0.1021\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9735 - loss: 0.0016 - val_accuracy: 0.5644 - val_loss: 0.1021\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9691 - loss: 0.0016 - val_accuracy: 0.5692 - val_loss: 0.0985\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9652 - loss: 0.0017 - val_accuracy: 0.5628 - val_loss: 0.1116\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9690 - loss: 0.0016 - val_accuracy: 0.5612 - val_loss: 0.1063\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9655 - loss: 0.0017 - val_accuracy: 0.5692 - val_loss: 0.1076\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9731 - loss: 0.0014 - val_accuracy: 0.5676 - val_loss: 0.1142\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9736 - loss: 0.0015 - val_accuracy: 0.5733 - val_loss: 0.1066\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9676 - loss: 0.0015 - val_accuracy: 0.5684 - val_loss: 0.1147\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0019 - val_accuracy: 0.5709 - val_loss: 0.1087\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9741 - loss: 0.0013 - val_accuracy: 0.5580 - val_loss: 0.1101\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9717 - loss: 0.0014 - val_accuracy: 0.5829 - val_loss: 0.1174\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9676 - loss: 0.0015 - val_accuracy: 0.5700 - val_loss: 0.1134\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9764 - loss: 0.0015 - val_accuracy: 0.5717 - val_loss: 0.1152\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9750 - loss: 0.0013 - val_accuracy: 0.5765 - val_loss: 0.1081\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9739 - loss: 0.0014 - val_accuracy: 0.5668 - val_loss: 0.1099\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9754 - loss: 0.0013 - val_accuracy: 0.5700 - val_loss: 0.1177\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9719 - loss: 0.0015 - val_accuracy: 0.5660 - val_loss: 0.1098\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9801 - loss: 9.8827e-04 - val_accuracy: 0.5572 - val_loss: 0.1152\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9753 - loss: 0.0014 - val_accuracy: 0.5773 - val_loss: 0.1121\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9780 - loss: 0.0013 - val_accuracy: 0.5821 - val_loss: 0.1120\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9741 - loss: 0.0015 - val_accuracy: 0.5725 - val_loss: 0.1205\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9747 - loss: 0.0012 - val_accuracy: 0.5709 - val_loss: 0.1187\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9721 - loss: 0.0014 - val_accuracy: 0.5660 - val_loss: 0.1130\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9756 - loss: 0.0012 - val_accuracy: 0.5757 - val_loss: 0.1187\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9786 - loss: 0.0010 - val_accuracy: 0.5692 - val_loss: 0.1090\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9759 - loss: 0.0011 - val_accuracy: 0.5548 - val_loss: 0.1184\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9756 - loss: 0.0011 - val_accuracy: 0.5652 - val_loss: 0.1154\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9740 - loss: 0.0013 - val_accuracy: 0.5644 - val_loss: 0.1122\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9716 - loss: 0.0016 - val_accuracy: 0.5789 - val_loss: 0.1110\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9707 - loss: 0.0013 - val_accuracy: 0.5733 - val_loss: 0.1236\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9760 - loss: 0.0013 - val_accuracy: 0.5700 - val_loss: 0.1081\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9773 - loss: 0.0014 - val_accuracy: 0.5837 - val_loss: 0.1167\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9780 - loss: 0.0011 - val_accuracy: 0.5805 - val_loss: 0.1176\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9720 - loss: 0.0014 - val_accuracy: 0.5660 - val_loss: 0.1165\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9774 - loss: 0.0013 - val_accuracy: 0.5709 - val_loss: 0.1143\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9760 - loss: 0.0014 - val_accuracy: 0.5829 - val_loss: 0.1160\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9807 - loss: 9.5633e-04 - val_accuracy: 0.5700 - val_loss: 0.1204\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9770 - loss: 0.0013 - val_accuracy: 0.5684 - val_loss: 0.1190\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9753 - loss: 0.0013 - val_accuracy: 0.5765 - val_loss: 0.1100\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9761 - loss: 0.0013 - val_accuracy: 0.5652 - val_loss: 0.1213\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "CNN-Mel - Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9711 - loss: 0.0016 - val_accuracy: 0.6042 - val_loss: 0.0984\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9664 - loss: 0.0018 - val_accuracy: 0.6026 - val_loss: 0.1132\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9736 - loss: 0.0014 - val_accuracy: 0.6130 - val_loss: 0.1139\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9736 - loss: 0.0013 - val_accuracy: 0.6106 - val_loss: 0.1147\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9767 - loss: 0.0013 - val_accuracy: 0.6082 - val_loss: 0.1062\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9689 - loss: 0.0014 - val_accuracy: 0.6058 - val_loss: 0.1076\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9774 - loss: 0.0013 - val_accuracy: 0.6098 - val_loss: 0.0950\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9667 - loss: 0.0019 - val_accuracy: 0.6211 - val_loss: 0.1090\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9786 - loss: 0.0013 - val_accuracy: 0.5929 - val_loss: 0.0988\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9721 - loss: 0.0012 - val_accuracy: 0.6050 - val_loss: 0.0948\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9740 - loss: 0.0012 - val_accuracy: 0.6082 - val_loss: 0.1070\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9791 - loss: 0.0012 - val_accuracy: 0.6227 - val_loss: 0.1150\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9750 - loss: 0.0011 - val_accuracy: 0.6171 - val_loss: 0.1179\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9729 - loss: 0.0014 - val_accuracy: 0.6074 - val_loss: 0.1125\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9735 - loss: 0.0015 - val_accuracy: 0.5961 - val_loss: 0.1077\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9748 - loss: 0.0013 - val_accuracy: 0.6042 - val_loss: 0.1045\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9737 - loss: 0.0012 - val_accuracy: 0.6042 - val_loss: 0.1080\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9799 - loss: 0.0012 - val_accuracy: 0.6187 - val_loss: 0.1163\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9819 - loss: 9.9950e-04 - val_accuracy: 0.6098 - val_loss: 0.1145\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9779 - loss: 0.0012 - val_accuracy: 0.6002 - val_loss: 0.1142\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9777 - loss: 0.0014 - val_accuracy: 0.6050 - val_loss: 0.1124\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9765 - loss: 0.0011 - val_accuracy: 0.6219 - val_loss: 0.1166\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9729 - loss: 0.0012 - val_accuracy: 0.6187 - val_loss: 0.1187\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9765 - loss: 0.0013 - val_accuracy: 0.6042 - val_loss: 0.1087\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9824 - loss: 8.9026e-04 - val_accuracy: 0.6171 - val_loss: 0.1039\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9771 - loss: 0.0014 - val_accuracy: 0.6275 - val_loss: 0.1146\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9732 - loss: 0.0014 - val_accuracy: 0.6098 - val_loss: 0.1108\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9785 - loss: 0.0012 - val_accuracy: 0.6122 - val_loss: 0.1076\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9785 - loss: 0.0012 - val_accuracy: 0.6098 - val_loss: 0.1146\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9772 - loss: 0.0014 - val_accuracy: 0.6042 - val_loss: 0.1051\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9783 - loss: 0.0012 - val_accuracy: 0.6042 - val_loss: 0.1070\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9769 - loss: 0.0013 - val_accuracy: 0.6058 - val_loss: 0.1123\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9777 - loss: 0.0012 - val_accuracy: 0.6122 - val_loss: 0.0949\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9783 - loss: 0.0014 - val_accuracy: 0.6163 - val_loss: 0.1103\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9791 - loss: 0.0011 - val_accuracy: 0.6179 - val_loss: 0.1206\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9785 - loss: 0.0012 - val_accuracy: 0.6026 - val_loss: 0.1127\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9758 - loss: 0.0013 - val_accuracy: 0.6042 - val_loss: 0.1149\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9788 - loss: 0.0014 - val_accuracy: 0.6018 - val_loss: 0.0998\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9745 - loss: 0.0015 - val_accuracy: 0.6018 - val_loss: 0.1137\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9793 - loss: 0.0012 - val_accuracy: 0.6098 - val_loss: 0.1144\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9800 - loss: 0.0010 - val_accuracy: 0.5986 - val_loss: 0.1116\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9766 - loss: 0.0014 - val_accuracy: 0.5945 - val_loss: 0.1127\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9823 - loss: 8.3267e-04 - val_accuracy: 0.6066 - val_loss: 0.1178\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9855 - loss: 6.4814e-04 - val_accuracy: 0.6163 - val_loss: 0.1232\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9773 - loss: 0.0011 - val_accuracy: 0.6082 - val_loss: 0.1114\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9840 - loss: 9.4832e-04 - val_accuracy: 0.5969 - val_loss: 0.1167\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9717 - loss: 0.0013 - val_accuracy: 0.6114 - val_loss: 0.1039\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9779 - loss: 0.0010 - val_accuracy: 0.6050 - val_loss: 0.1173\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9846 - loss: 8.8716e-04 - val_accuracy: 0.6090 - val_loss: 0.1077\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9797 - loss: 0.0012 - val_accuracy: 0.6010 - val_loss: 0.1163\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "CNN-Mel - Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9792 - loss: 0.0012 - val_accuracy: 0.6031 - val_loss: 0.1169\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9790 - loss: 0.0011 - val_accuracy: 0.5934 - val_loss: 0.1212\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9786 - loss: 0.0012 - val_accuracy: 0.5878 - val_loss: 0.1148\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9783 - loss: 0.0013 - val_accuracy: 0.5958 - val_loss: 0.1084\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9781 - loss: 0.0011 - val_accuracy: 0.5934 - val_loss: 0.0959\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9821 - loss: 0.0010 - val_accuracy: 0.5821 - val_loss: 0.1023\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9785 - loss: 0.0010 - val_accuracy: 0.5757 - val_loss: 0.1099\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9825 - loss: 0.0011 - val_accuracy: 0.5966 - val_loss: 0.1017\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9842 - loss: 8.2076e-04 - val_accuracy: 0.5910 - val_loss: 0.1062\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9793 - loss: 0.0013 - val_accuracy: 0.5958 - val_loss: 0.1144\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9780 - loss: 0.0013 - val_accuracy: 0.5958 - val_loss: 0.1148\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9808 - loss: 9.8239e-04 - val_accuracy: 0.5990 - val_loss: 0.1056\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9865 - loss: 8.3851e-04 - val_accuracy: 0.5966 - val_loss: 0.1161\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9825 - loss: 8.7451e-04 - val_accuracy: 0.5974 - val_loss: 0.1202\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9791 - loss: 0.0012 - val_accuracy: 0.5797 - val_loss: 0.1124\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9782 - loss: 0.0011 - val_accuracy: 0.5781 - val_loss: 0.1198\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9845 - loss: 9.1538e-04 - val_accuracy: 0.5910 - val_loss: 0.1250\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9810 - loss: 0.0012 - val_accuracy: 0.5870 - val_loss: 0.1114\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9804 - loss: 9.4796e-04 - val_accuracy: 0.5749 - val_loss: 0.1181\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9820 - loss: 9.2935e-04 - val_accuracy: 0.5829 - val_loss: 0.1145\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9848 - loss: 9.4207e-04 - val_accuracy: 0.5733 - val_loss: 0.1024\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9816 - loss: 8.9857e-04 - val_accuracy: 0.5773 - val_loss: 0.1011\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9752 - loss: 0.0013 - val_accuracy: 0.5853 - val_loss: 0.1147\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9836 - loss: 9.4725e-04 - val_accuracy: 0.5773 - val_loss: 0.1224\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9804 - loss: 0.0011 - val_accuracy: 0.5749 - val_loss: 0.1105\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9777 - loss: 0.0013 - val_accuracy: 0.5862 - val_loss: 0.1114\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9858 - loss: 8.9647e-04 - val_accuracy: 0.5733 - val_loss: 0.1050\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9796 - loss: 0.0011 - val_accuracy: 0.5862 - val_loss: 0.1118\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9794 - loss: 0.0010 - val_accuracy: 0.5886 - val_loss: 0.1054\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9819 - loss: 0.0010 - val_accuracy: 0.5700 - val_loss: 0.1134\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9775 - loss: 0.0013 - val_accuracy: 0.5797 - val_loss: 0.1129\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9843 - loss: 8.9741e-04 - val_accuracy: 0.5878 - val_loss: 0.1109\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9774 - loss: 0.0013 - val_accuracy: 0.5684 - val_loss: 0.1143\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9822 - loss: 0.0010 - val_accuracy: 0.5829 - val_loss: 0.1129\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9829 - loss: 9.6717e-04 - val_accuracy: 0.5862 - val_loss: 0.1175\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9816 - loss: 0.0010 - val_accuracy: 0.5950 - val_loss: 0.1106\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9808 - loss: 8.8272e-04 - val_accuracy: 0.5797 - val_loss: 0.1130\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9831 - loss: 9.7532e-04 - val_accuracy: 0.5837 - val_loss: 0.1150\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9849 - loss: 8.5896e-04 - val_accuracy: 0.5805 - val_loss: 0.1162\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9829 - loss: 0.0010 - val_accuracy: 0.5910 - val_loss: 0.1116\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9820 - loss: 9.2949e-04 - val_accuracy: 0.5878 - val_loss: 0.1170\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9836 - loss: 0.0010 - val_accuracy: 0.5797 - val_loss: 0.1114\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9828 - loss: 9.9675e-04 - val_accuracy: 0.5789 - val_loss: 0.1208\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.9826 - loss: 9.0408e-04 - val_accuracy: 0.5837 - val_loss: 0.1249\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 72ms/step - accuracy: 0.9811 - loss: 9.7473e-04 - val_accuracy: 0.5717 - val_loss: 0.1113\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9818 - loss: 8.3979e-04 - val_accuracy: 0.5878 - val_loss: 0.1175\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9844 - loss: 8.0457e-04 - val_accuracy: 0.5862 - val_loss: 0.1189\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9831 - loss: 9.7223e-04 - val_accuracy: 0.5878 - val_loss: 0.1084\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9863 - loss: 6.4104e-04 - val_accuracy: 0.5910 - val_loss: 0.1196\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.9871 - loss: 8.4862e-04 - val_accuracy: 0.5990 - val_loss: 0.1171\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "CNN-Mel Average Results:\n",
      "Average Sensitivity: 0.6852\n",
      "Average Specificity: 0.9004\n",
      "Average Score: 0.7928\n",
      "Average Accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "# Compute Mel-spectrograms\n",
    "TARGET_SR = 4000\n",
    "FIXED_DURATION = 2.7\n",
    "SAMPLES_PER_CYCLE = int(TARGET_SR * FIXED_DURATION)\n",
    "\n",
    "def compute_mel_spectrogram(cycle):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=cycle, sr=TARGET_SR, n_mels=128, fmax=2000)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "# Load raw cycles if not in memory, otherwise assume 'cycles' is available\n",
    "# If not, recompute from audio files (assuming cycles was temporary)\n",
    "cycles = np.concatenate([preprocess_audio(os.path.join(audio_dir, f), \n",
    "                                          os.path.join(audio_dir, f.replace('.wav', '.txt')))[0] \n",
    "                         for f in audio_files], axis=0)\n",
    "\n",
    "mel_spectrograms = np.array([compute_mel_spectrogram(cycle) for cycle in cycles])\n",
    "mel_spectrograms_resized = np.array([resize(spec, (75, 50), mode='constant') for spec in mel_spectrograms])\n",
    "mel_spectrograms_resized = np.expand_dims(mel_spectrograms_resized, axis=-1)\n",
    "\n",
    "# Save Mel-spectrograms\n",
    "np.save(os.path.join(spectrograms_dir, \"mel_spectrograms_resized.npy\"), mel_spectrograms_resized)\n",
    "\n",
    "# Define CNN model\n",
    "def build_cnn_mel(input_shape=(75, 50, 1), num_classes=4):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "cnn_mel = build_cnn_mel()\n",
    "cnn_mel.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(gamma=2.0), metrics=['accuracy'])\n",
    "\n",
    "# Train and evaluate\n",
    "sensitivity_list, specificity_list, score_list, accuracy_list = [], [], [], []\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "    X_train, X_test = mel_spectrograms_resized[train_idx], mel_spectrograms_resized[test_idx]\n",
    "    y_train, y_test = labels_one_hot[train_idx], labels_one_hot[test_idx]\n",
    "    \n",
    "    print(f\"CNN-Mel - Training fold {fold_idx + 1}/10\")\n",
    "    cnn_mel.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    y_pred = cnn_mel.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    sensitivity = np.mean(TP / (TP + FN + 1e-10))\n",
    "    specificity = np.mean(TN / (TN + FP + 1e-10))\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    score_list.append(score)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "print(\"\\nCNN-Mel Average Results:\")\n",
    "print(f\"Average Sensitivity: {np.mean(sensitivity_list):.4f}\")\n",
    "print(f\"Average Specificity: {np.mean(specificity_list):.4f}\")\n",
    "print(f\"Average Score: {np.mean(score_list):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-Transformer architecture for lung sound classification\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation of CNN-Transformer architecture for lung sound classification.\n",
    "This module replaces the LSTM component with a Transformer encoder for better sequence modeling.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Transformer encoder block with multi-head self-attention and feed-forward network\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss function implementation as described in the paper\n",
    "    FL = ∑(i=1 to M) yi(1-ŷi)^γ log(ŷi), γ≥0\n",
    "    \n",
    "    Args:\n",
    "        gamma: Focusing parameter (default: 2.0)\n",
    "        alpha: Weighting factor (default: 0.25)\n",
    "        \n",
    "    Returns:\n",
    "        Focal loss function\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        \n",
    "        # Calculate the modulating factor (1-p)^gamma\n",
    "        modulating_factor = K.pow(1.0 - y_pred, gamma)\n",
    "        \n",
    "        # Apply the focal term\n",
    "        loss = alpha * modulating_factor * cross_entropy\n",
    "        \n",
    "        # Sum over all classes\n",
    "        return K.sum(loss, axis=-1)\n",
    "    \n",
    "    return focal_loss_fixed\n",
    "\n",
    "def create_cnn_transformer_model(input_shape=(75, 50, 3), num_classes=4, \n",
    "                                dropout_rate=0.2, learning_rate=0.0001,\n",
    "                                embed_dim=64, num_heads=2, ff_dim=128,\n",
    "                                num_transformer_blocks=2):\n",
    "    \"\"\"\n",
    "    Create a CNN-Transformer model for lung sound classification\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input shape of the spectrograms (default: (75, 50, 3))\n",
    "        num_classes: Number of output classes (default: 4)\n",
    "        dropout_rate: Dropout rate (default: 0.2)\n",
    "        learning_rate: Learning rate (default: 0.0001)\n",
    "        embed_dim: Embedding dimension for transformer (default: 64)\n",
    "        num_heads: Number of attention heads (default: 2)\n",
    "        ff_dim: Feed-forward network dimension (default: 128)\n",
    "        num_transformer_blocks: Number of transformer blocks (default: 2)\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN part of the network (same as the base model)\n",
    "    # First convolutional block\n",
    "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Fourth convolutional block\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Reshape for Transformer part\n",
    "    shape = K.int_shape(x)\n",
    "    # Reshape to (batch_size, sequence_length, features)\n",
    "    x = layers.Reshape((shape[1], shape[2] * shape[3]))(x)\n",
    "    \n",
    "    # Position embedding for transformer\n",
    "    x = layers.Dense(embed_dim)(x)\n",
    "    \n",
    "    # Transformer part (replacing LSTM)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim, dropout_rate)(x)\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Final dense layers\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile model with focal loss\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=focal_loss(gamma=2.0),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=50, callbacks=None):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \n",
    "    Args:\n",
    "        model: Compiled Keras model\n",
    "        X_train: Training data\n",
    "        y_train: Training labels\n",
    "        X_val: Validation data\n",
    "        y_val: Validation labels\n",
    "        batch_size: Batch size (default: 32)\n",
    "        epochs: Number of epochs (default: 50)\n",
    "        callbacks: List of Keras callbacks (default: None)\n",
    "        \n",
    "    Returns:\n",
    "        Training history\n",
    "    \"\"\"\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        X_test: Test data\n",
    "        y_test: Test labels\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Calculate sensitivity, specificity, score, and accuracy as per paper\n",
    "    # For multi-class, we calculate micro-average values\n",
    "    \n",
    "    # Initialize counters\n",
    "    tp_total = 0\n",
    "    tn_total = 0\n",
    "    fp_total = 0\n",
    "    fn_total = 0\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN for each class\n",
    "    num_classes = len(cm)\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        tn = np.sum(cm) - tp - fp - fn\n",
    "        \n",
    "        tp_total += tp\n",
    "        tn_total += tn\n",
    "        fp_total += fp\n",
    "        fn_total += fn\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sensitivity = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
    "    specificity = tn_total / (tn_total + fp_total) if (tn_total + fp_total) > 0 else 0\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    return {\n",
    "        'confusion_matrix': cm,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'score': score,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    print(\"CNN-Transformer architecture for lung sound classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spectrograms shape: (6898, 75, 50, 1)\n",
      "Loaded labels shape: (6898,)\n",
      "Labels after one-hot encoding shape: (6898, 4)\n",
      "Loaded patient IDs shape: (6898,)\n",
      "Spectrograms after channel conversion: (6898, 75, 50, 3)\n",
      "\n",
      "Training Fold 1/10\n",
      "X_train shape: (5866, 75, 50, 3), y_train shape: (5866, 4)\n",
      "X_test shape: (1032, 75, 50, 3), y_test shape: (1032, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 276ms/step - accuracy: 0.3073 - loss: 4.2930 - val_accuracy: 0.5126 - val_loss: 2.6956\n",
      "Epoch 2/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 270ms/step - accuracy: 0.4983 - loss: 2.3642 - val_accuracy: 0.5368 - val_loss: 1.5572\n",
      "Epoch 3/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 273ms/step - accuracy: 0.5072 - loss: 1.3934 - val_accuracy: 0.5417 - val_loss: 0.9820\n",
      "Epoch 4/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 260ms/step - accuracy: 0.5400 - loss: 0.8962 - val_accuracy: 0.5436 - val_loss: 0.6821\n",
      "Epoch 5/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 256ms/step - accuracy: 0.5516 - loss: 0.6374 - val_accuracy: 0.5262 - val_loss: 0.5199\n",
      "Epoch 6/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 240ms/step - accuracy: 0.5476 - loss: 0.4933 - val_accuracy: 0.5213 - val_loss: 0.4231\n",
      "Epoch 7/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 248ms/step - accuracy: 0.5459 - loss: 0.4059 - val_accuracy: 0.5223 - val_loss: 0.3559\n",
      "Epoch 8/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 265ms/step - accuracy: 0.5557 - loss: 0.3415 - val_accuracy: 0.5126 - val_loss: 0.3089\n",
      "Epoch 9/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 275ms/step - accuracy: 0.5618 - loss: 0.2969 - val_accuracy: 0.5194 - val_loss: 0.2719\n",
      "Epoch 10/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 276ms/step - accuracy: 0.5678 - loss: 0.2611 - val_accuracy: 0.5203 - val_loss: 0.2451\n",
      "Epoch 11/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 248ms/step - accuracy: 0.5657 - loss: 0.2350 - val_accuracy: 0.5252 - val_loss: 0.2260\n",
      "Epoch 12/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 239ms/step - accuracy: 0.5688 - loss: 0.2141 - val_accuracy: 0.5223 - val_loss: 0.2097\n",
      "Epoch 13/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 240ms/step - accuracy: 0.5780 - loss: 0.1988 - val_accuracy: 0.5126 - val_loss: 0.1974\n",
      "Epoch 14/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 276ms/step - accuracy: 0.5720 - loss: 0.1863 - val_accuracy: 0.5213 - val_loss: 0.1887\n",
      "Epoch 15/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 297ms/step - accuracy: 0.5834 - loss: 0.1773 - val_accuracy: 0.5233 - val_loss: 0.1826\n",
      "Epoch 16/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 243ms/step - accuracy: 0.5885 - loss: 0.1695 - val_accuracy: 0.5116 - val_loss: 0.1760\n",
      "Epoch 17/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 239ms/step - accuracy: 0.5952 - loss: 0.1631 - val_accuracy: 0.5155 - val_loss: 0.1719\n",
      "Epoch 18/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 256ms/step - accuracy: 0.5930 - loss: 0.1580 - val_accuracy: 0.5184 - val_loss: 0.1697\n",
      "Epoch 19/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 278ms/step - accuracy: 0.5953 - loss: 0.1542 - val_accuracy: 0.5078 - val_loss: 0.1684\n",
      "Epoch 20/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 276ms/step - accuracy: 0.5944 - loss: 0.1518 - val_accuracy: 0.5097 - val_loss: 0.1655\n",
      "Epoch 21/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 238ms/step - accuracy: 0.6051 - loss: 0.1483 - val_accuracy: 0.5097 - val_loss: 0.1638\n",
      "Epoch 22/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 243ms/step - accuracy: 0.6080 - loss: 0.1454 - val_accuracy: 0.5029 - val_loss: 0.1634\n",
      "Epoch 23/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 256ms/step - accuracy: 0.6192 - loss: 0.1430 - val_accuracy: 0.4981 - val_loss: 0.1616\n",
      "Epoch 24/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 278ms/step - accuracy: 0.6122 - loss: 0.1409 - val_accuracy: 0.5048 - val_loss: 0.1612\n",
      "Epoch 25/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 267ms/step - accuracy: 0.6264 - loss: 0.1405 - val_accuracy: 0.4961 - val_loss: 0.1615\n",
      "Epoch 26/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 244ms/step - accuracy: 0.6278 - loss: 0.1385 - val_accuracy: 0.4922 - val_loss: 0.1622\n",
      "Epoch 27/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 253ms/step - accuracy: 0.6308 - loss: 0.1367 - val_accuracy: 0.4942 - val_loss: 0.1625\n",
      "Epoch 28/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 263ms/step - accuracy: 0.6299 - loss: 0.1365 - val_accuracy: 0.4932 - val_loss: 0.1637\n",
      "Epoch 29/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 277ms/step - accuracy: 0.6353 - loss: 0.1341 - val_accuracy: 0.4990 - val_loss: 0.1626\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Fold 1 Test accuracy: 50.48%\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step\n",
      "Fold 1 - Sensitivity: 0.5048, Specificity: 0.8349, Score: 0.6699, Accuracy: 0.7524\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      0.60      0.57       519\n",
      "    Crackles       0.46      0.55      0.50       379\n",
      "     Wheezes       0.23      0.04      0.07        75\n",
      "        Both       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.50      1032\n",
      "   macro avg       0.31      0.30      0.28      1032\n",
      "weighted avg       0.46      0.50      0.48      1032\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\lung\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "Training Fold 2/10\n",
      "X_train shape: (6227, 75, 50, 3), y_train shape: (6227, 4)\n",
      "X_test shape: (671, 75, 50, 3), y_test shape: (671, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 231ms/step - accuracy: 0.3298 - loss: 4.2638 - val_accuracy: 0.3741 - val_loss: 2.6486\n",
      "Epoch 2/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 227ms/step - accuracy: 0.5137 - loss: 2.2764 - val_accuracy: 0.3949 - val_loss: 1.5195\n",
      "Epoch 3/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 230ms/step - accuracy: 0.5290 - loss: 1.3113 - val_accuracy: 0.4098 - val_loss: 0.9651\n",
      "Epoch 4/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 263ms/step - accuracy: 0.5375 - loss: 0.8369 - val_accuracy: 0.4143 - val_loss: 0.6862\n",
      "Epoch 5/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 267ms/step - accuracy: 0.5479 - loss: 0.5928 - val_accuracy: 0.4113 - val_loss: 0.5367\n",
      "Epoch 6/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 225ms/step - accuracy: 0.5550 - loss: 0.4568 - val_accuracy: 0.4083 - val_loss: 0.4484\n",
      "Epoch 7/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 227ms/step - accuracy: 0.5656 - loss: 0.3716 - val_accuracy: 0.4039 - val_loss: 0.3831\n",
      "Epoch 8/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 239ms/step - accuracy: 0.5577 - loss: 0.3146 - val_accuracy: 0.4098 - val_loss: 0.3394\n",
      "Epoch 9/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 263ms/step - accuracy: 0.5575 - loss: 0.2705 - val_accuracy: 0.3920 - val_loss: 0.3070\n",
      "Epoch 10/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 257ms/step - accuracy: 0.5637 - loss: 0.2384 - val_accuracy: 0.3949 - val_loss: 0.2865\n",
      "Epoch 11/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 224ms/step - accuracy: 0.5767 - loss: 0.2134 - val_accuracy: 0.4024 - val_loss: 0.2684\n",
      "Epoch 12/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 226ms/step - accuracy: 0.5734 - loss: 0.1970 - val_accuracy: 0.4083 - val_loss: 0.2537\n",
      "Epoch 13/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 250ms/step - accuracy: 0.5711 - loss: 0.1831 - val_accuracy: 0.3949 - val_loss: 0.2472\n",
      "Epoch 14/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 261ms/step - accuracy: 0.5761 - loss: 0.1713 - val_accuracy: 0.4024 - val_loss: 0.2413\n",
      "Epoch 15/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 245ms/step - accuracy: 0.5942 - loss: 0.1638 - val_accuracy: 0.4039 - val_loss: 0.2351\n",
      "Epoch 16/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 225ms/step - accuracy: 0.5870 - loss: 0.1569 - val_accuracy: 0.4098 - val_loss: 0.2359\n",
      "Epoch 17/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 232ms/step - accuracy: 0.5882 - loss: 0.1522 - val_accuracy: 0.4113 - val_loss: 0.2307\n",
      "Epoch 18/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 278ms/step - accuracy: 0.5836 - loss: 0.1478 - val_accuracy: 0.4098 - val_loss: 0.2326\n",
      "Epoch 19/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 275ms/step - accuracy: 0.5968 - loss: 0.1458 - val_accuracy: 0.4113 - val_loss: 0.2320\n",
      "Epoch 20/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 243ms/step - accuracy: 0.6108 - loss: 0.1415 - val_accuracy: 0.4069 - val_loss: 0.2271\n",
      "Epoch 21/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 240ms/step - accuracy: 0.5915 - loss: 0.1394 - val_accuracy: 0.4113 - val_loss: 0.2298\n",
      "Epoch 22/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 266ms/step - accuracy: 0.6038 - loss: 0.1379 - val_accuracy: 0.4069 - val_loss: 0.2292\n",
      "Epoch 23/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 277ms/step - accuracy: 0.5994 - loss: 0.1359 - val_accuracy: 0.3949 - val_loss: 0.2318\n",
      "Epoch 24/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 258ms/step - accuracy: 0.6062 - loss: 0.1350 - val_accuracy: 0.4039 - val_loss: 0.2300\n",
      "Epoch 25/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 239ms/step - accuracy: 0.6149 - loss: 0.1323 - val_accuracy: 0.4009 - val_loss: 0.2336\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Fold 2 Test accuracy: 40.69%\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step\n",
      "Fold 2 - Sensitivity: 0.4069, Specificity: 0.8023, Score: 0.6046, Accuracy: 0.7034\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.45      0.82      0.58       281\n",
      "    Crackles       0.28      0.31      0.29       138\n",
      "     Wheezes       0.00      0.00      0.00       149\n",
      "        Both       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.41       671\n",
      "   macro avg       0.18      0.28      0.22       671\n",
      "weighted avg       0.24      0.41      0.30       671\n",
      "\n",
      "\n",
      "Training Fold 3/10\n",
      "X_train shape: (6600, 75, 50, 3), y_train shape: (6600, 4)\n",
      "X_test shape: (298, 75, 50, 3), y_test shape: (298, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 242ms/step - accuracy: 0.3940 - loss: 4.1612 - val_accuracy: 0.8121 - val_loss: 2.4031\n",
      "Epoch 2/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 259ms/step - accuracy: 0.4798 - loss: 2.1198 - val_accuracy: 0.8624 - val_loss: 1.2803\n",
      "Epoch 3/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 251ms/step - accuracy: 0.5058 - loss: 1.1801 - val_accuracy: 0.8725 - val_loss: 0.7632\n",
      "Epoch 4/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 226ms/step - accuracy: 0.5066 - loss: 0.7445 - val_accuracy: 0.8792 - val_loss: 0.5118\n",
      "Epoch 5/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 235ms/step - accuracy: 0.5176 - loss: 0.5324 - val_accuracy: 0.8826 - val_loss: 0.3813\n",
      "Epoch 6/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 259ms/step - accuracy: 0.5253 - loss: 0.4167 - val_accuracy: 0.8826 - val_loss: 0.3022\n",
      "Epoch 7/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 257ms/step - accuracy: 0.5275 - loss: 0.3430 - val_accuracy: 0.8826 - val_loss: 0.2442\n",
      "Epoch 8/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 226ms/step - accuracy: 0.5390 - loss: 0.2925 - val_accuracy: 0.8826 - val_loss: 0.2061\n",
      "Epoch 9/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 238ms/step - accuracy: 0.5471 - loss: 0.2569 - val_accuracy: 0.8826 - val_loss: 0.1799\n",
      "Epoch 10/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 265ms/step - accuracy: 0.5422 - loss: 0.2293 - val_accuracy: 0.8859 - val_loss: 0.1593\n",
      "Epoch 11/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 261ms/step - accuracy: 0.5427 - loss: 0.2094 - val_accuracy: 0.8826 - val_loss: 0.1447\n",
      "Epoch 12/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 226ms/step - accuracy: 0.5494 - loss: 0.1941 - val_accuracy: 0.8826 - val_loss: 0.1350\n",
      "Epoch 13/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 225ms/step - accuracy: 0.5486 - loss: 0.1827 - val_accuracy: 0.8792 - val_loss: 0.1232\n",
      "Epoch 14/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 263ms/step - accuracy: 0.5545 - loss: 0.1727 - val_accuracy: 0.8826 - val_loss: 0.1165\n",
      "Epoch 15/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 260ms/step - accuracy: 0.5558 - loss: 0.1673 - val_accuracy: 0.8826 - val_loss: 0.1149\n",
      "Epoch 16/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 232ms/step - accuracy: 0.5528 - loss: 0.1619 - val_accuracy: 0.8859 - val_loss: 0.1073\n",
      "Epoch 17/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 226ms/step - accuracy: 0.5596 - loss: 0.1574 - val_accuracy: 0.8859 - val_loss: 0.1045\n",
      "Epoch 18/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 258ms/step - accuracy: 0.5537 - loss: 0.1550 - val_accuracy: 0.8792 - val_loss: 0.1027\n",
      "Epoch 19/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 260ms/step - accuracy: 0.5635 - loss: 0.1508 - val_accuracy: 0.8826 - val_loss: 0.0999\n",
      "Epoch 20/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 233ms/step - accuracy: 0.5681 - loss: 0.1483 - val_accuracy: 0.8792 - val_loss: 0.1018\n",
      "Epoch 21/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 226ms/step - accuracy: 0.5621 - loss: 0.1477 - val_accuracy: 0.8725 - val_loss: 0.1012\n",
      "Epoch 22/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 249ms/step - accuracy: 0.5678 - loss: 0.1459 - val_accuracy: 0.8725 - val_loss: 0.0997\n",
      "Epoch 23/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 260ms/step - accuracy: 0.5659 - loss: 0.1452 - val_accuracy: 0.8691 - val_loss: 0.0999\n",
      "Epoch 24/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 239ms/step - accuracy: 0.5741 - loss: 0.1429 - val_accuracy: 0.8725 - val_loss: 0.0972\n",
      "Epoch 25/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 225ms/step - accuracy: 0.5833 - loss: 0.1404 - val_accuracy: 0.8658 - val_loss: 0.0973\n",
      "Epoch 26/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 245ms/step - accuracy: 0.5781 - loss: 0.1413 - val_accuracy: 0.8624 - val_loss: 0.0993\n",
      "Epoch 27/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 263ms/step - accuracy: 0.5834 - loss: 0.1401 - val_accuracy: 0.8557 - val_loss: 0.0976\n",
      "Epoch 28/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 237ms/step - accuracy: 0.5820 - loss: 0.1394 - val_accuracy: 0.8624 - val_loss: 0.0954\n",
      "Epoch 29/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 213ms/step - accuracy: 0.5843 - loss: 0.1383 - val_accuracy: 0.8591 - val_loss: 0.0963\n",
      "Epoch 30/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 215ms/step - accuracy: 0.5810 - loss: 0.1380 - val_accuracy: 0.8591 - val_loss: 0.0962\n",
      "Epoch 31/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 233ms/step - accuracy: 0.5911 - loss: 0.1368 - val_accuracy: 0.8557 - val_loss: 0.0949\n",
      "Epoch 32/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 247ms/step - accuracy: 0.5988 - loss: 0.1354 - val_accuracy: 0.8356 - val_loss: 0.0976\n",
      "Epoch 33/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 227ms/step - accuracy: 0.5977 - loss: 0.1350 - val_accuracy: 0.7919 - val_loss: 0.1019\n",
      "Epoch 34/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 213ms/step - accuracy: 0.5967 - loss: 0.1344 - val_accuracy: 0.8087 - val_loss: 0.1002\n",
      "Epoch 35/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 217ms/step - accuracy: 0.6012 - loss: 0.1336 - val_accuracy: 0.8054 - val_loss: 0.0993\n",
      "Epoch 36/50\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 231ms/step - accuracy: 0.6054 - loss: 0.1327 - val_accuracy: 0.8221 - val_loss: 0.0972\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Fold 3 Test accuracy: 85.57%\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step\n",
      "Fold 3 - Sensitivity: 0.8557, Specificity: 0.9519, Score: 0.9038, Accuracy: 0.9279\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.89      0.97      0.92       263\n",
      "    Crackles       0.33      0.04      0.07        24\n",
      "     Wheezes       0.00      0.00      0.00         7\n",
      "        Both       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.86       298\n",
      "   macro avg       0.30      0.25      0.25       298\n",
      "weighted avg       0.81      0.86      0.82       298\n",
      "\n",
      "\n",
      "Training Fold 4/10\n",
      "X_train shape: (6520, 75, 50, 3), y_train shape: (6520, 4)\n",
      "X_test shape: (378, 75, 50, 3), y_test shape: (378, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 251ms/step - accuracy: 0.3784 - loss: 4.2000 - val_accuracy: 0.6720 - val_loss: 2.4919\n",
      "Epoch 2/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 226ms/step - accuracy: 0.4870 - loss: 2.1848 - val_accuracy: 0.6984 - val_loss: 1.3621\n",
      "Epoch 3/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 215ms/step - accuracy: 0.5053 - loss: 1.2339 - val_accuracy: 0.6746 - val_loss: 0.8304\n",
      "Epoch 4/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 216ms/step - accuracy: 0.5104 - loss: 0.7830 - val_accuracy: 0.7328 - val_loss: 0.5660\n",
      "Epoch 5/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 232ms/step - accuracy: 0.5121 - loss: 0.5604 - val_accuracy: 0.6905 - val_loss: 0.4315\n",
      "Epoch 6/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 249ms/step - accuracy: 0.5111 - loss: 0.4364 - val_accuracy: 0.7222 - val_loss: 0.3418\n",
      "Epoch 7/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 241ms/step - accuracy: 0.5232 - loss: 0.3574 - val_accuracy: 0.7487 - val_loss: 0.2822\n",
      "Epoch 8/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 213ms/step - accuracy: 0.5364 - loss: 0.3038 - val_accuracy: 0.7434 - val_loss: 0.2389\n",
      "Epoch 9/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 217ms/step - accuracy: 0.5292 - loss: 0.2643 - val_accuracy: 0.7540 - val_loss: 0.2076\n",
      "Epoch 10/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 221ms/step - accuracy: 0.5366 - loss: 0.2354 - val_accuracy: 0.7381 - val_loss: 0.1822\n",
      "Epoch 11/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 252ms/step - accuracy: 0.5429 - loss: 0.2133 - val_accuracy: 0.7275 - val_loss: 0.1678\n",
      "Epoch 12/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 249ms/step - accuracy: 0.5451 - loss: 0.1971 - val_accuracy: 0.7116 - val_loss: 0.1554\n",
      "Epoch 13/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 211ms/step - accuracy: 0.5492 - loss: 0.1852 - val_accuracy: 0.7249 - val_loss: 0.1440\n",
      "Epoch 14/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 216ms/step - accuracy: 0.5520 - loss: 0.1754 - val_accuracy: 0.7169 - val_loss: 0.1372\n",
      "Epoch 15/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 216ms/step - accuracy: 0.5580 - loss: 0.1687 - val_accuracy: 0.7328 - val_loss: 0.1303\n",
      "Epoch 16/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 248ms/step - accuracy: 0.5678 - loss: 0.1627 - val_accuracy: 0.7302 - val_loss: 0.1264\n",
      "Epoch 17/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 249ms/step - accuracy: 0.5629 - loss: 0.1591 - val_accuracy: 0.7222 - val_loss: 0.1224\n",
      "Epoch 18/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 221ms/step - accuracy: 0.5643 - loss: 0.1552 - val_accuracy: 0.7381 - val_loss: 0.1171\n",
      "Epoch 19/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 216ms/step - accuracy: 0.5803 - loss: 0.1518 - val_accuracy: 0.7222 - val_loss: 0.1173\n",
      "Epoch 20/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 222ms/step - accuracy: 0.5755 - loss: 0.1493 - val_accuracy: 0.7249 - val_loss: 0.1145\n",
      "Epoch 21/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 250ms/step - accuracy: 0.5797 - loss: 0.1481 - val_accuracy: 0.7037 - val_loss: 0.1170\n",
      "Epoch 22/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 246ms/step - accuracy: 0.5850 - loss: 0.1446 - val_accuracy: 0.7090 - val_loss: 0.1155\n",
      "Epoch 23/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 213ms/step - accuracy: 0.5909 - loss: 0.1442 - val_accuracy: 0.7143 - val_loss: 0.1144\n",
      "Epoch 24/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 217ms/step - accuracy: 0.5935 - loss: 0.1423 - val_accuracy: 0.7143 - val_loss: 0.1161\n",
      "Epoch 25/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 222ms/step - accuracy: 0.5919 - loss: 0.1413 - val_accuracy: 0.7037 - val_loss: 0.1147\n",
      "Epoch 26/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 250ms/step - accuracy: 0.5993 - loss: 0.1399 - val_accuracy: 0.7011 - val_loss: 0.1173\n",
      "Epoch 27/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 247ms/step - accuracy: 0.6076 - loss: 0.1385 - val_accuracy: 0.6958 - val_loss: 0.1180\n",
      "Epoch 28/50\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 215ms/step - accuracy: 0.6060 - loss: 0.1374 - val_accuracy: 0.6958 - val_loss: 0.1150\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Fold 4 Test accuracy: 71.43%\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step\n",
      "Fold 4 - Sensitivity: 0.7143, Specificity: 0.9048, Score: 0.8095, Accuracy: 0.8571\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.78      0.89      0.83       296\n",
      "    Crackles       0.18      0.10      0.13        61\n",
      "     Wheezes       0.00      0.00      0.00        18\n",
      "        Both       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.71       378\n",
      "   macro avg       0.24      0.25      0.24       378\n",
      "weighted avg       0.64      0.71      0.67       378\n",
      "\n",
      "\n",
      "Training Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6399, 75, 50, 3), y_train shape: (6399, 4)\n",
      "X_test shape: (499, 75, 50, 3), y_test shape: (499, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 219ms/step - accuracy: 0.3655 - loss: 4.1926 - val_accuracy: 0.5892 - val_loss: 2.5220\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 224ms/step - accuracy: 0.4638 - loss: 2.1865 - val_accuracy: 0.6273 - val_loss: 1.3882\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - accuracy: 0.4903 - loss: 1.2322 - val_accuracy: 0.6613 - val_loss: 0.8476\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 252ms/step - accuracy: 0.5137 - loss: 0.7801 - val_accuracy: 0.6754 - val_loss: 0.5840\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 216ms/step - accuracy: 0.5224 - loss: 0.5537 - val_accuracy: 0.6814 - val_loss: 0.4428\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 219ms/step - accuracy: 0.5323 - loss: 0.4315 - val_accuracy: 0.7034 - val_loss: 0.3554\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 223ms/step - accuracy: 0.5302 - loss: 0.3549 - val_accuracy: 0.7034 - val_loss: 0.2991\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - accuracy: 0.5377 - loss: 0.3022 - val_accuracy: 0.7014 - val_loss: 0.2578\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 255ms/step - accuracy: 0.5449 - loss: 0.2630 - val_accuracy: 0.6934 - val_loss: 0.2263\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 218ms/step - accuracy: 0.5444 - loss: 0.2346 - val_accuracy: 0.6713 - val_loss: 0.2052\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 219ms/step - accuracy: 0.5564 - loss: 0.2124 - val_accuracy: 0.6854 - val_loss: 0.1854\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 223ms/step - accuracy: 0.5498 - loss: 0.1953 - val_accuracy: 0.6954 - val_loss: 0.1713\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - accuracy: 0.5579 - loss: 0.1820 - val_accuracy: 0.6713 - val_loss: 0.1622\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 250ms/step - accuracy: 0.5627 - loss: 0.1726 - val_accuracy: 0.6593 - val_loss: 0.1550\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 219ms/step - accuracy: 0.5652 - loss: 0.1659 - val_accuracy: 0.6493 - val_loss: 0.1519\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 220ms/step - accuracy: 0.5587 - loss: 0.1602 - val_accuracy: 0.6653 - val_loss: 0.1453\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 221ms/step - accuracy: 0.5730 - loss: 0.1545 - val_accuracy: 0.6373 - val_loss: 0.1432\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 253ms/step - accuracy: 0.5689 - loss: 0.1512 - val_accuracy: 0.6493 - val_loss: 0.1415\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 270ms/step - accuracy: 0.5753 - loss: 0.1482 - val_accuracy: 0.6513 - val_loss: 0.1389\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 260ms/step - accuracy: 0.5883 - loss: 0.1454 - val_accuracy: 0.6553 - val_loss: 0.1357\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 264ms/step - accuracy: 0.5797 - loss: 0.1425 - val_accuracy: 0.6353 - val_loss: 0.1379\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 262ms/step - accuracy: 0.5868 - loss: 0.1396 - val_accuracy: 0.6533 - val_loss: 0.1355\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 291ms/step - accuracy: 0.5946 - loss: 0.1387 - val_accuracy: 0.6613 - val_loss: 0.1349\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 280ms/step - accuracy: 0.5884 - loss: 0.1381 - val_accuracy: 0.6473 - val_loss: 0.1354\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - accuracy: 0.5937 - loss: 0.1365 - val_accuracy: 0.6313 - val_loss: 0.1361\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 256ms/step - accuracy: 0.5967 - loss: 0.1356 - val_accuracy: 0.6413 - val_loss: 0.1361\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 289ms/step - accuracy: 0.6015 - loss: 0.1338 - val_accuracy: 0.6393 - val_loss: 0.1370\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 291ms/step - accuracy: 0.6087 - loss: 0.1331 - val_accuracy: 0.6413 - val_loss: 0.1367\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Fold 5 Test accuracy: 66.13%\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step\n",
      "Fold 5 - Sensitivity: 0.6613, Specificity: 0.8871, Score: 0.7742, Accuracy: 0.8307\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.72      0.89      0.80       354\n",
      "    Crackles       0.24      0.24      0.24        50\n",
      "     Wheezes       0.25      0.03      0.06        61\n",
      "        Both       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.66       499\n",
      "   macro avg       0.30      0.29      0.27       499\n",
      "weighted avg       0.56      0.66      0.60       499\n",
      "\n",
      "\n",
      "Training Fold 6/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (6310, 75, 50, 3), y_train shape: (6310, 4)\n",
      "X_test shape: (588, 75, 50, 3), y_test shape: (588, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 256ms/step - accuracy: 0.3399 - loss: 4.2348 - val_accuracy: 0.3469 - val_loss: 2.6007\n",
      "Epoch 2/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 255ms/step - accuracy: 0.4986 - loss: 2.2324 - val_accuracy: 0.4286 - val_loss: 1.4541\n",
      "Epoch 3/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 283ms/step - accuracy: 0.5195 - loss: 1.2689 - val_accuracy: 0.4728 - val_loss: 0.8986\n",
      "Epoch 4/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 294ms/step - accuracy: 0.5230 - loss: 0.8037 - val_accuracy: 0.4694 - val_loss: 0.6247\n",
      "Epoch 5/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 266ms/step - accuracy: 0.5333 - loss: 0.5706 - val_accuracy: 0.4830 - val_loss: 0.4777\n",
      "Epoch 6/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 255ms/step - accuracy: 0.5400 - loss: 0.4422 - val_accuracy: 0.4813 - val_loss: 0.3882\n",
      "Epoch 7/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 269ms/step - accuracy: 0.5378 - loss: 0.3606 - val_accuracy: 0.4983 - val_loss: 0.3276\n",
      "Epoch 8/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 295ms/step - accuracy: 0.5455 - loss: 0.3051 - val_accuracy: 0.4932 - val_loss: 0.2862\n",
      "Epoch 9/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 283ms/step - accuracy: 0.5471 - loss: 0.2639 - val_accuracy: 0.5187 - val_loss: 0.2535\n",
      "Epoch 10/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 256ms/step - accuracy: 0.5599 - loss: 0.2348 - val_accuracy: 0.5119 - val_loss: 0.2337\n",
      "Epoch 11/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 262ms/step - accuracy: 0.5573 - loss: 0.2127 - val_accuracy: 0.5238 - val_loss: 0.2188\n",
      "Epoch 12/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 295ms/step - accuracy: 0.5516 - loss: 0.1956 - val_accuracy: 0.5272 - val_loss: 0.2046\n",
      "Epoch 13/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 290ms/step - accuracy: 0.5515 - loss: 0.1827 - val_accuracy: 0.5272 - val_loss: 0.1950\n",
      "Epoch 14/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 253ms/step - accuracy: 0.5571 - loss: 0.1722 - val_accuracy: 0.5323 - val_loss: 0.1874\n",
      "Epoch 15/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 258ms/step - accuracy: 0.5691 - loss: 0.1654 - val_accuracy: 0.5221 - val_loss: 0.1822\n",
      "Epoch 16/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 292ms/step - accuracy: 0.5629 - loss: 0.1596 - val_accuracy: 0.5255 - val_loss: 0.1787\n",
      "Epoch 17/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 293ms/step - accuracy: 0.5756 - loss: 0.1544 - val_accuracy: 0.5323 - val_loss: 0.1757\n",
      "Epoch 18/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 255ms/step - accuracy: 0.5730 - loss: 0.1513 - val_accuracy: 0.5289 - val_loss: 0.1736\n",
      "Epoch 19/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 257ms/step - accuracy: 0.5781 - loss: 0.1481 - val_accuracy: 0.5272 - val_loss: 0.1706\n",
      "Epoch 20/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 281ms/step - accuracy: 0.5756 - loss: 0.1461 - val_accuracy: 0.4983 - val_loss: 0.1718\n",
      "Epoch 21/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 294ms/step - accuracy: 0.5791 - loss: 0.1431 - val_accuracy: 0.5119 - val_loss: 0.1692\n",
      "Epoch 22/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 264ms/step - accuracy: 0.5831 - loss: 0.1417 - val_accuracy: 0.5051 - val_loss: 0.1674\n",
      "Epoch 23/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 257ms/step - accuracy: 0.5926 - loss: 0.1392 - val_accuracy: 0.5034 - val_loss: 0.1693\n",
      "Epoch 24/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 272ms/step - accuracy: 0.5887 - loss: 0.1377 - val_accuracy: 0.4796 - val_loss: 0.1701\n",
      "Epoch 25/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 295ms/step - accuracy: 0.5936 - loss: 0.1368 - val_accuracy: 0.5000 - val_loss: 0.1686\n",
      "Epoch 26/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 277ms/step - accuracy: 0.5933 - loss: 0.1358 - val_accuracy: 0.4813 - val_loss: 0.1699\n",
      "Epoch 27/50\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 258ms/step - accuracy: 0.5942 - loss: 0.1347 - val_accuracy: 0.4813 - val_loss: 0.1682\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Fold 6 Test accuracy: 50.51%\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step\n",
      "Fold 6 - Sensitivity: 0.5051, Specificity: 0.8350, Score: 0.6701, Accuracy: 0.7526\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.51      0.83      0.63       275\n",
      "    Crackles       0.67      0.32      0.44       191\n",
      "     Wheezes       0.14      0.10      0.12        67\n",
      "        Both       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.51       588\n",
      "   macro avg       0.33      0.31      0.30       588\n",
      "weighted avg       0.47      0.51      0.45       588\n",
      "\n",
      "\n",
      "Training Fold 7/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (6199, 75, 50, 3), y_train shape: (6199, 4)\n",
      "X_test shape: (699, 75, 50, 3), y_test shape: (699, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 263ms/step - accuracy: 0.3787 - loss: 4.2180 - val_accuracy: 0.5093 - val_loss: 2.5863\n",
      "Epoch 2/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 299ms/step - accuracy: 0.4850 - loss: 2.2477 - val_accuracy: 0.5165 - val_loss: 1.4591\n",
      "Epoch 3/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 299ms/step - accuracy: 0.5061 - loss: 1.2886 - val_accuracy: 0.5064 - val_loss: 0.9091\n",
      "Epoch 4/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 257ms/step - accuracy: 0.5246 - loss: 0.8191 - val_accuracy: 0.5079 - val_loss: 0.6343\n",
      "Epoch 5/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 262ms/step - accuracy: 0.5348 - loss: 0.5824 - val_accuracy: 0.5107 - val_loss: 0.4877\n",
      "Epoch 6/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 288ms/step - accuracy: 0.5311 - loss: 0.4530 - val_accuracy: 0.5351 - val_loss: 0.3982\n",
      "Epoch 7/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 300ms/step - accuracy: 0.5509 - loss: 0.3694 - val_accuracy: 0.5436 - val_loss: 0.3376\n",
      "Epoch 8/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 273ms/step - accuracy: 0.5453 - loss: 0.3146 - val_accuracy: 0.5551 - val_loss: 0.2947\n",
      "Epoch 9/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 261ms/step - accuracy: 0.5467 - loss: 0.2726 - val_accuracy: 0.5536 - val_loss: 0.2626\n",
      "Epoch 10/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 265ms/step - accuracy: 0.5429 - loss: 0.2419 - val_accuracy: 0.5508 - val_loss: 0.2382\n",
      "Epoch 11/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 302ms/step - accuracy: 0.5556 - loss: 0.2183 - val_accuracy: 0.5522 - val_loss: 0.2203\n",
      "Epoch 12/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 290ms/step - accuracy: 0.5612 - loss: 0.2001 - val_accuracy: 0.5536 - val_loss: 0.2078\n",
      "Epoch 13/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 259ms/step - accuracy: 0.5654 - loss: 0.1876 - val_accuracy: 0.5551 - val_loss: 0.1976\n",
      "Epoch 14/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 262ms/step - accuracy: 0.5709 - loss: 0.1767 - val_accuracy: 0.5536 - val_loss: 0.1908\n",
      "Epoch 15/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 289ms/step - accuracy: 0.5714 - loss: 0.1679 - val_accuracy: 0.5551 - val_loss: 0.1850\n",
      "Epoch 16/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 299ms/step - accuracy: 0.5752 - loss: 0.1622 - val_accuracy: 0.5522 - val_loss: 0.1821\n",
      "Epoch 17/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 269ms/step - accuracy: 0.5670 - loss: 0.1571 - val_accuracy: 0.5536 - val_loss: 0.1785\n",
      "Epoch 18/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 261ms/step - accuracy: 0.5888 - loss: 0.1525 - val_accuracy: 0.5565 - val_loss: 0.1766\n",
      "Epoch 19/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 264ms/step - accuracy: 0.5904 - loss: 0.1495 - val_accuracy: 0.5465 - val_loss: 0.1762\n",
      "Epoch 20/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 301ms/step - accuracy: 0.5847 - loss: 0.1468 - val_accuracy: 0.5522 - val_loss: 0.1756\n",
      "Epoch 21/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 286ms/step - accuracy: 0.5903 - loss: 0.1445 - val_accuracy: 0.5465 - val_loss: 0.1755\n",
      "Epoch 22/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 261ms/step - accuracy: 0.5942 - loss: 0.1428 - val_accuracy: 0.5451 - val_loss: 0.1745\n",
      "Epoch 23/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 261ms/step - accuracy: 0.5968 - loss: 0.1408 - val_accuracy: 0.5393 - val_loss: 0.1742\n",
      "Epoch 24/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 291ms/step - accuracy: 0.6047 - loss: 0.1386 - val_accuracy: 0.5308 - val_loss: 0.1750\n",
      "Epoch 25/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 298ms/step - accuracy: 0.6071 - loss: 0.1379 - val_accuracy: 0.5351 - val_loss: 0.1748\n",
      "Epoch 26/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 265ms/step - accuracy: 0.6073 - loss: 0.1358 - val_accuracy: 0.5336 - val_loss: 0.1749\n",
      "Epoch 27/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 262ms/step - accuracy: 0.6083 - loss: 0.1342 - val_accuracy: 0.5222 - val_loss: 0.1757\n",
      "Epoch 28/50\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 275ms/step - accuracy: 0.6122 - loss: 0.1323 - val_accuracy: 0.5193 - val_loss: 0.1769\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Fold 7 Test accuracy: 53.93%\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 282ms/step\n",
      "Fold 7 - Sensitivity: 0.5393, Specificity: 0.8464, Score: 0.6929, Accuracy: 0.7697\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.56      0.93      0.70       380\n",
      "    Crackles       0.44      0.14      0.22       145\n",
      "     Wheezes       0.12      0.02      0.03       112\n",
      "        Both       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.54       699\n",
      "   macro avg       0.28      0.27      0.24       699\n",
      "weighted avg       0.41      0.54      0.43       699\n",
      "\n",
      "\n",
      "Training Fold 8/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (6093, 75, 50, 3), y_train shape: (6093, 4)\n",
      "X_test shape: (805, 75, 50, 3), y_test shape: (805, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 307ms/step - accuracy: 0.4162 - loss: 4.2573 - val_accuracy: 0.4273 - val_loss: 2.6493\n",
      "Epoch 2/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 269ms/step - accuracy: 0.5135 - loss: 2.2897 - val_accuracy: 0.4224 - val_loss: 1.5155\n",
      "Epoch 3/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 267ms/step - accuracy: 0.5337 - loss: 1.3174 - val_accuracy: 0.4323 - val_loss: 0.9546\n",
      "Epoch 4/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 277ms/step - accuracy: 0.5427 - loss: 0.8375 - val_accuracy: 0.4360 - val_loss: 0.6730\n",
      "Epoch 5/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 304ms/step - accuracy: 0.5538 - loss: 0.5921 - val_accuracy: 0.4248 - val_loss: 0.5216\n",
      "Epoch 6/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 285ms/step - accuracy: 0.5446 - loss: 0.4563 - val_accuracy: 0.4149 - val_loss: 0.4298\n",
      "Epoch 7/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 264ms/step - accuracy: 0.5574 - loss: 0.3713 - val_accuracy: 0.4050 - val_loss: 0.3667\n",
      "Epoch 8/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 266ms/step - accuracy: 0.5564 - loss: 0.3127 - val_accuracy: 0.4012 - val_loss: 0.3222\n",
      "Epoch 9/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 294ms/step - accuracy: 0.5695 - loss: 0.2687 - val_accuracy: 0.3913 - val_loss: 0.2905\n",
      "Epoch 10/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 306ms/step - accuracy: 0.5656 - loss: 0.2391 - val_accuracy: 0.3975 - val_loss: 0.2655\n",
      "Epoch 11/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 260ms/step - accuracy: 0.5676 - loss: 0.2140 - val_accuracy: 0.3963 - val_loss: 0.2451\n",
      "Epoch 12/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5641 - loss: 0.1949 - val_accuracy: 0.4012 - val_loss: 0.2312\n",
      "Epoch 13/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 231ms/step - accuracy: 0.5719 - loss: 0.1815 - val_accuracy: 0.4037 - val_loss: 0.2195\n",
      "Epoch 14/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 264ms/step - accuracy: 0.5750 - loss: 0.1714 - val_accuracy: 0.4025 - val_loss: 0.2120\n",
      "Epoch 15/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 266ms/step - accuracy: 0.5821 - loss: 0.1617 - val_accuracy: 0.4075 - val_loss: 0.2061\n",
      "Epoch 16/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 231ms/step - accuracy: 0.5746 - loss: 0.1551 - val_accuracy: 0.4099 - val_loss: 0.2011\n",
      "Epoch 17/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5719 - loss: 0.1513 - val_accuracy: 0.4149 - val_loss: 0.1990\n",
      "Epoch 18/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5834 - loss: 0.1469 - val_accuracy: 0.4236 - val_loss: 0.1972\n",
      "Epoch 19/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 247ms/step - accuracy: 0.5885 - loss: 0.1423 - val_accuracy: 0.4248 - val_loss: 0.1964\n",
      "Epoch 20/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 267ms/step - accuracy: 0.5826 - loss: 0.1404 - val_accuracy: 0.4286 - val_loss: 0.1931\n",
      "Epoch 21/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 247ms/step - accuracy: 0.5875 - loss: 0.1372 - val_accuracy: 0.4360 - val_loss: 0.1916\n",
      "Epoch 22/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 233ms/step - accuracy: 0.5845 - loss: 0.1353 - val_accuracy: 0.4373 - val_loss: 0.1917\n",
      "Epoch 23/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 231ms/step - accuracy: 0.5926 - loss: 0.1341 - val_accuracy: 0.4348 - val_loss: 0.1917\n",
      "Epoch 24/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 249ms/step - accuracy: 0.5949 - loss: 0.1329 - val_accuracy: 0.4360 - val_loss: 0.1908\n",
      "Epoch 25/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 265ms/step - accuracy: 0.5963 - loss: 0.1310 - val_accuracy: 0.4360 - val_loss: 0.1939\n",
      "Epoch 26/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 243ms/step - accuracy: 0.6018 - loss: 0.1294 - val_accuracy: 0.4385 - val_loss: 0.1922\n",
      "Epoch 27/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5985 - loss: 0.1287 - val_accuracy: 0.4323 - val_loss: 0.1939\n",
      "Epoch 28/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 231ms/step - accuracy: 0.6044 - loss: 0.1270 - val_accuracy: 0.4348 - val_loss: 0.1949\n",
      "Epoch 29/50\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.6013 - loss: 0.1270 - val_accuracy: 0.4385 - val_loss: 0.1938\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Fold 8 Test accuracy: 43.60%\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step\n",
      "Fold 8 - Sensitivity: 0.4360, Specificity: 0.8120, Score: 0.6240, Accuracy: 0.7180\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.44      0.88      0.59       312\n",
      "    Crackles       0.43      0.27      0.33       234\n",
      "     Wheezes       0.39      0.04      0.08       168\n",
      "        Both       0.43      0.07      0.11        91\n",
      "\n",
      "    accuracy                           0.44       805\n",
      "   macro avg       0.42      0.31      0.28       805\n",
      "weighted avg       0.42      0.44      0.35       805\n",
      "\n",
      "\n",
      "Training Fold 9/10\n",
      "X_train shape: (5751, 75, 50, 3), y_train shape: (5751, 4)\n",
      "X_test shape: (1147, 75, 50, 3), y_test shape: (1147, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 286ms/step - accuracy: 0.3347 - loss: 4.2751 - val_accuracy: 0.4542 - val_loss: 2.7105\n",
      "Epoch 2/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 271ms/step - accuracy: 0.5003 - loss: 2.3740 - val_accuracy: 0.4629 - val_loss: 1.5808\n",
      "Epoch 3/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 241ms/step - accuracy: 0.5270 - loss: 1.4046 - val_accuracy: 0.4603 - val_loss: 0.9965\n",
      "Epoch 4/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - accuracy: 0.5385 - loss: 0.9048 - val_accuracy: 0.4629 - val_loss: 0.6936\n",
      "Epoch 5/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 246ms/step - accuracy: 0.5355 - loss: 0.6418 - val_accuracy: 0.4638 - val_loss: 0.5270\n",
      "Epoch 6/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 284ms/step - accuracy: 0.5434 - loss: 0.4938 - val_accuracy: 0.4690 - val_loss: 0.4257\n",
      "Epoch 7/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 283ms/step - accuracy: 0.5490 - loss: 0.4036 - val_accuracy: 0.4743 - val_loss: 0.3581\n",
      "Epoch 8/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 242ms/step - accuracy: 0.5527 - loss: 0.3413 - val_accuracy: 0.4856 - val_loss: 0.3078\n",
      "Epoch 9/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - accuracy: 0.5433 - loss: 0.2955 - val_accuracy: 0.4874 - val_loss: 0.2718\n",
      "Epoch 10/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 247ms/step - accuracy: 0.5526 - loss: 0.2603 - val_accuracy: 0.4839 - val_loss: 0.2467\n",
      "Epoch 11/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 278ms/step - accuracy: 0.5519 - loss: 0.2351 - val_accuracy: 0.4847 - val_loss: 0.2247\n",
      "Epoch 12/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 283ms/step - accuracy: 0.5612 - loss: 0.2149 - val_accuracy: 0.4839 - val_loss: 0.2101\n",
      "Epoch 13/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 245ms/step - accuracy: 0.5642 - loss: 0.1983 - val_accuracy: 0.4891 - val_loss: 0.1972\n",
      "Epoch 14/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - accuracy: 0.5706 - loss: 0.1851 - val_accuracy: 0.4987 - val_loss: 0.1868\n",
      "Epoch 15/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 245ms/step - accuracy: 0.5725 - loss: 0.1767 - val_accuracy: 0.4900 - val_loss: 0.1805\n",
      "Epoch 16/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 275ms/step - accuracy: 0.5676 - loss: 0.1692 - val_accuracy: 0.5004 - val_loss: 0.1743\n",
      "Epoch 17/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 282ms/step - accuracy: 0.5825 - loss: 0.1627 - val_accuracy: 0.4952 - val_loss: 0.1713\n",
      "Epoch 18/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 256ms/step - accuracy: 0.5844 - loss: 0.1563 - val_accuracy: 0.4856 - val_loss: 0.1681\n",
      "Epoch 19/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - accuracy: 0.5817 - loss: 0.1539 - val_accuracy: 0.4760 - val_loss: 0.1669\n",
      "Epoch 20/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 247ms/step - accuracy: 0.5848 - loss: 0.1498 - val_accuracy: 0.4891 - val_loss: 0.1638\n",
      "Epoch 21/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 255ms/step - accuracy: 0.5920 - loss: 0.1485 - val_accuracy: 0.5031 - val_loss: 0.1629\n",
      "Epoch 22/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 282ms/step - accuracy: 0.5945 - loss: 0.1443 - val_accuracy: 0.4778 - val_loss: 0.1623\n",
      "Epoch 23/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 275ms/step - accuracy: 0.5929 - loss: 0.1432 - val_accuracy: 0.4795 - val_loss: 0.1614\n",
      "Epoch 24/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - accuracy: 0.6014 - loss: 0.1413 - val_accuracy: 0.4917 - val_loss: 0.1599\n",
      "Epoch 25/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 245ms/step - accuracy: 0.5947 - loss: 0.1403 - val_accuracy: 0.4987 - val_loss: 0.1598\n",
      "Epoch 26/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 251ms/step - accuracy: 0.6050 - loss: 0.1374 - val_accuracy: 0.4804 - val_loss: 0.1610\n",
      "Epoch 27/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 282ms/step - accuracy: 0.6051 - loss: 0.1364 - val_accuracy: 0.4926 - val_loss: 0.1609\n",
      "Epoch 28/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 273ms/step - accuracy: 0.6107 - loss: 0.1358 - val_accuracy: 0.5004 - val_loss: 0.1589\n",
      "Epoch 29/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 242ms/step - accuracy: 0.6066 - loss: 0.1352 - val_accuracy: 0.5083 - val_loss: 0.1602\n",
      "Epoch 30/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - accuracy: 0.6135 - loss: 0.1336 - val_accuracy: 0.5004 - val_loss: 0.1605\n",
      "Epoch 31/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 247ms/step - accuracy: 0.6218 - loss: 0.1327 - val_accuracy: 0.4961 - val_loss: 0.1619\n",
      "Epoch 32/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 278ms/step - accuracy: 0.6257 - loss: 0.1312 - val_accuracy: 0.4926 - val_loss: 0.1636\n",
      "Epoch 33/50\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 282ms/step - accuracy: 0.6261 - loss: 0.1311 - val_accuracy: 0.5039 - val_loss: 0.1609\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Fold 9 Test accuracy: 50.04%\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step\n",
      "Fold 9 - Sensitivity: 0.5004, Specificity: 0.8335, Score: 0.6670, Accuracy: 0.7502\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.49      0.93      0.64       534\n",
      "    Crackles       0.63      0.17      0.27       439\n",
      "     Wheezes       0.18      0.03      0.05       106\n",
      "        Both       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.50      1147\n",
      "   macro avg       0.32      0.28      0.24      1147\n",
      "weighted avg       0.48      0.50      0.41      1147\n",
      "\n",
      "\n",
      "Training Fold 10/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (6117, 75, 50, 3), y_train shape: (6117, 4)\n",
      "X_test shape: (781, 75, 50, 3), y_test shape: (781, 4)\n",
      "VGG16 output shape: (None, 2, 1, 512)\n",
      "Epoch 1/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 227ms/step - accuracy: 0.3216 - loss: 4.2369 - val_accuracy: 0.5186 - val_loss: 2.6091\n",
      "Epoch 2/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 228ms/step - accuracy: 0.4802 - loss: 2.2767 - val_accuracy: 0.5237 - val_loss: 1.4810\n",
      "Epoch 3/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 228ms/step - accuracy: 0.5119 - loss: 1.3164 - val_accuracy: 0.5250 - val_loss: 0.9242\n",
      "Epoch 4/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 260ms/step - accuracy: 0.5115 - loss: 0.8406 - val_accuracy: 0.5186 - val_loss: 0.6403\n",
      "Epoch 5/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 263ms/step - accuracy: 0.5248 - loss: 0.5968 - val_accuracy: 0.5314 - val_loss: 0.4857\n",
      "Epoch 6/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 229ms/step - accuracy: 0.5212 - loss: 0.4617 - val_accuracy: 0.5403 - val_loss: 0.3920\n",
      "Epoch 7/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5281 - loss: 0.3771 - val_accuracy: 0.5275 - val_loss: 0.3299\n",
      "Epoch 8/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5344 - loss: 0.3184 - val_accuracy: 0.5480 - val_loss: 0.2839\n",
      "Epoch 9/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 252ms/step - accuracy: 0.5455 - loss: 0.2760 - val_accuracy: 0.5442 - val_loss: 0.2479\n",
      "Epoch 10/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 264ms/step - accuracy: 0.5456 - loss: 0.2448 - val_accuracy: 0.5455 - val_loss: 0.2263\n",
      "Epoch 11/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 236ms/step - accuracy: 0.5564 - loss: 0.2207 - val_accuracy: 0.5442 - val_loss: 0.2037\n",
      "Epoch 12/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 229ms/step - accuracy: 0.5560 - loss: 0.2029 - val_accuracy: 0.5634 - val_loss: 0.1913\n",
      "Epoch 13/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 229ms/step - accuracy: 0.5615 - loss: 0.1900 - val_accuracy: 0.5711 - val_loss: 0.1791\n",
      "Epoch 14/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 237ms/step - accuracy: 0.5740 - loss: 0.1795 - val_accuracy: 0.5787 - val_loss: 0.1706\n",
      "Epoch 15/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 267ms/step - accuracy: 0.5653 - loss: 0.1706 - val_accuracy: 0.5800 - val_loss: 0.1641\n",
      "Epoch 16/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 255ms/step - accuracy: 0.5652 - loss: 0.1644 - val_accuracy: 0.5826 - val_loss: 0.1594\n",
      "Epoch 17/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 229ms/step - accuracy: 0.5707 - loss: 0.1599 - val_accuracy: 0.5800 - val_loss: 0.1562\n",
      "Epoch 18/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 233ms/step - accuracy: 0.5747 - loss: 0.1564 - val_accuracy: 0.5826 - val_loss: 0.1536\n",
      "Epoch 19/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5824 - loss: 0.1521 - val_accuracy: 0.5890 - val_loss: 0.1521\n",
      "Epoch 20/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 256ms/step - accuracy: 0.5798 - loss: 0.1486 - val_accuracy: 0.5992 - val_loss: 0.1506\n",
      "Epoch 21/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 264ms/step - accuracy: 0.5746 - loss: 0.1467 - val_accuracy: 0.5903 - val_loss: 0.1496\n",
      "Epoch 22/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 234ms/step - accuracy: 0.5844 - loss: 0.1454 - val_accuracy: 0.6095 - val_loss: 0.1474\n",
      "Epoch 23/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 229ms/step - accuracy: 0.5849 - loss: 0.1434 - val_accuracy: 0.6095 - val_loss: 0.1468\n",
      "Epoch 24/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 232ms/step - accuracy: 0.5833 - loss: 0.1425 - val_accuracy: 0.5980 - val_loss: 0.1493\n",
      "Epoch 25/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 240ms/step - accuracy: 0.5878 - loss: 0.1404 - val_accuracy: 0.6018 - val_loss: 0.1472\n",
      "Epoch 26/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 266ms/step - accuracy: 0.5968 - loss: 0.1394 - val_accuracy: 0.6095 - val_loss: 0.1461\n",
      "Epoch 27/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 252ms/step - accuracy: 0.5954 - loss: 0.1373 - val_accuracy: 0.6044 - val_loss: 0.1482\n",
      "Epoch 28/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 228ms/step - accuracy: 0.5998 - loss: 0.1372 - val_accuracy: 0.6018 - val_loss: 0.1474\n",
      "Epoch 29/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.5923 - loss: 0.1368 - val_accuracy: 0.6095 - val_loss: 0.1480\n",
      "Epoch 30/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 230ms/step - accuracy: 0.6063 - loss: 0.1345 - val_accuracy: 0.6031 - val_loss: 0.1468\n",
      "Epoch 31/50\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 261ms/step - accuracy: 0.6090 - loss: 0.1340 - val_accuracy: 0.6005 - val_loss: 0.1503\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Fold 10 Test accuracy: 60.95%\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step\n",
      "Fold 10 - Sensitivity: 0.6095, Specificity: 0.8698, Score: 0.7397, Accuracy: 0.8047\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.61      0.89      0.72       428\n",
      "    Crackles       0.60      0.28      0.38       203\n",
      "     Wheezes       0.62      0.32      0.42       123\n",
      "        Both       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.61       781\n",
      "   macro avg       0.46      0.37      0.38       781\n",
      "weighted avg       0.59      0.61      0.56       781\n",
      "\n",
      "\n",
      "Average Metrics Across 10 Folds:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\anaconda\\envs\\lung\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensitivity: 0.5733\n",
      "Specificity: 0.8578\n",
      "Score: 0.7156\n",
      "Accuracy: 0.7867\n",
      "An error occurred: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set paths\n",
    "base_dir = os.path.normpath(r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\")\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Focal loss for one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "        ce_loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "        p_t = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        focal_weight = self.alpha * tf.pow(1.0 - p_t, self.gamma)\n",
    "        return tf.reduce_mean(focal_weight * ce_loss)\n",
    "\n",
    "class LungSoundClassifier:\n",
    "    def __init__(self, input_shape=(75, 50, 3), num_classes=4):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "\n",
    "    def load_and_preprocess_data(self, spectrograms_dir):\n",
    "        \"\"\"\n",
    "        Load pre-computed spectrograms, convert labels to one-hot, and load patient IDs.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(spectrograms_dir):\n",
    "            raise FileNotFoundError(f\"Directory not found: {spectrograms_dir}.\")\n",
    "\n",
    "        spectrogram_file = 'spectrograms_resized.npy'\n",
    "        label_file = 'labels.npy'\n",
    "        patient_id_file = 'patient_ids.npy'\n",
    "        spectrogram_path = os.path.join(spectrograms_dir, spectrogram_file)\n",
    "        label_path = os.path.join(spectrograms_dir, label_file)\n",
    "        patient_id_path = os.path.join(spectrograms_dir, patient_id_file)\n",
    "\n",
    "        if not os.path.exists(spectrogram_path):\n",
    "            raise FileNotFoundError(f\"Spectrogram file {spectrogram_path} not found.\")\n",
    "        spectrograms = np.load(spectrogram_path)\n",
    "        print(f\"Loaded spectrograms shape: {spectrograms.shape}\")\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            raise FileNotFoundError(f\"Labels file {label_path} not found.\")\n",
    "        labels = np.load(label_path)\n",
    "        print(f\"Loaded labels shape: {labels.shape}\")\n",
    "        # Convert labels to one-hot encoding\n",
    "        labels_one_hot = to_categorical(labels, num_classes=self.num_classes)\n",
    "        print(f\"Labels after one-hot encoding shape: {labels_one_hot.shape}\")\n",
    "\n",
    "        if not os.path.exists(patient_id_path):\n",
    "            raise FileNotFoundError(f\"Patient IDs file {patient_id_path} not found.\")\n",
    "        patient_ids = np.load(patient_id_path)\n",
    "        print(f\"Loaded patient IDs shape: {patient_ids.shape}\")\n",
    "\n",
    "        if spectrograms.shape[0] != labels.shape[0] or spectrograms.shape[0] != patient_ids.shape[0]:\n",
    "            raise ValueError(f\"Mismatch: {spectrograms.shape[0]} spectrograms, {labels.shape[0]} labels, {patient_ids.shape[0]} patient IDs.\")\n",
    "\n",
    "        if spectrograms.shape[1:] != (75, 50, 1):\n",
    "            raise ValueError(f\"Unexpected spectrogram shape: {spectrograms.shape[1:]}. Expected (75, 50, 1).\")\n",
    "\n",
    "        spectrograms = np.repeat(spectrograms, 3, axis=-1)\n",
    "        print(f\"Spectrograms after channel conversion: {spectrograms.shape}\")\n",
    "\n",
    "        return spectrograms, labels_one_hot, patient_ids\n",
    "\n",
    "    def spec_augment(self, spectrograms, time_mask_param=10, freq_mask_param=10):\n",
    "        \"\"\"\n",
    "        Apply SpecAugment to spectrograms for data augmentation.\n",
    "        \"\"\"\n",
    "        augmented_specs = spectrograms.copy()\n",
    "        for i in range(augmented_specs.shape[0]):\n",
    "            t = augmented_specs.shape[2]\n",
    "            if time_mask_param > 0:\n",
    "                t_masks = np.random.randint(0, time_mask_param, 1)[0]\n",
    "                t0 = np.random.randint(0, t - t_masks)\n",
    "                augmented_specs[i, :, t0:t0 + t_masks, :] = 0\n",
    "\n",
    "            f = augmented_specs.shape[1]\n",
    "            if freq_mask_param > 0:\n",
    "                f_masks = np.random.randint(0, freq_mask_param, 1)[0]\n",
    "                f0 = np.random.randint(0, f - f_masks)\n",
    "                augmented_specs[i, f0:f0 + f_masks, :, :] = 0\n",
    "\n",
    "        return augmented_specs\n",
    "\n",
    "    def build_transfer_learning_model(self):\n",
    "        \"\"\"\n",
    "        Build model with VGG16 and LSTM, with increased regularization.\n",
    "        \"\"\"\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(75, 50, 3))\n",
    "\n",
    "        # Freeze base model layers\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        inputs = layers.Input(shape=(75, 50, 3))\n",
    "        x = base_model(inputs, training=False)\n",
    "        print(f\"VGG16 output shape: {x.shape}\")\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        vgg_output_shape = x.shape[1:]\n",
    "        lstm_input_size = np.prod(vgg_output_shape).astype(int)\n",
    "        x = layers.Reshape((1, lstm_input_size))(x)\n",
    "\n",
    "        x = layers.LSTM(64, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "        x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "        x = layers.Dropout(0.5)(x)  # Increased dropout\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "        return model\n",
    "\n",
    "    def compute_metrics(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute micro-average sensitivity, specificity, score, and accuracy.\n",
    "        Convert one-hot y_true back to labels for confusion matrix.\n",
    "        \"\"\"\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "        TP = np.diag(cm)\n",
    "        FN = cm.sum(axis=1) - TP\n",
    "        FP = cm.sum(axis=0) - TP\n",
    "        TN = cm.sum() - (TP + FN + FP)\n",
    "\n",
    "        sensitivity = TP.sum() / (TP.sum() + FN.sum()) if (TP.sum() + FN.sum()) > 0 else 0\n",
    "        specificity = TN.sum() / (TN.sum() + FP.sum()) if (TN.sum() + FP.sum()) > 0 else 0\n",
    "        score = (sensitivity + specificity) / 2\n",
    "        accuracy = (TP.sum() + TN.sum()) / (TP.sum() + TN.sum() + FP.sum() + FN.sum()) if (TP.sum() + TN.sum() + FP.sum() + FN.sum()) > 0 else 0\n",
    "\n",
    "        return sensitivity, specificity, score, accuracy\n",
    "\n",
    "    def train(self, X, y, patient_ids, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train with 10-fold interpatient cross-validation, including early stopping.\n",
    "        \"\"\"\n",
    "        unique_patients = np.unique(patient_ids)\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "        fold_metrics = {\n",
    "            'sensitivity': [],\n",
    "            'specificity': [],\n",
    "            'score': [],\n",
    "            'accuracy': []\n",
    "        }\n",
    "\n",
    "        fold_histories = []\n",
    "        fold = 1\n",
    "        for train_idx, test_idx in kf.split(unique_patients):\n",
    "            print(f\"\\nTraining Fold {fold}/10\")\n",
    "            train_patients = unique_patients[train_idx]\n",
    "            test_patients = unique_patients[test_idx]\n",
    "\n",
    "            train_sample_idx = np.isin(patient_ids, train_patients)\n",
    "            test_sample_idx = np.isin(patient_ids, test_patients)\n",
    "\n",
    "            X_train = X[train_sample_idx]\n",
    "            y_train = y[train_sample_idx]\n",
    "            X_test = X[test_sample_idx]\n",
    "            y_test = y[test_sample_idx]\n",
    "\n",
    "            print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "            print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "            # Apply SpecAugment to training data\n",
    "            X_train = self.spec_augment(X_train)\n",
    "\n",
    "            self.model = self.build_transfer_learning_model()\n",
    "            self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                              loss=FocalLoss(gamma=2.0, alpha=0.25),\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "            # Add early stopping\n",
    "            early_stopping = callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            history = self.model.fit(X_train, y_train,\n",
    "                                    epochs=epochs,\n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_data=(X_test, y_test),\n",
    "                                    callbacks=[early_stopping],\n",
    "                                    verbose=1)\n",
    "\n",
    "            test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"Fold {fold} Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            sensitivity, specificity, score, accuracy = self.compute_metrics(y_test, y_pred)\n",
    "\n",
    "            fold_metrics['sensitivity'].append(sensitivity)\n",
    "            fold_metrics['specificity'].append(specificity)\n",
    "            fold_metrics['score'].append(score)\n",
    "            fold_metrics['accuracy'].append(accuracy)\n",
    "\n",
    "            print(f\"Fold {fold} - Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, Score: {score:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            y_test_labels = np.argmax(y_test, axis=1)\n",
    "            y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "            print(classification_report(y_test_labels, y_pred_labels, target_names=['Normal', 'Crackles', 'Wheezes', 'Both']))\n",
    "\n",
    "            fold_histories.append(history)\n",
    "            fold += 1\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        avg_metrics = {key: np.mean(values) for key, values in fold_metrics.items()}\n",
    "        print(\"\\nAverage Metrics Across 10 Folds:\")\n",
    "        print(f\"Sensitivity: {avg_metrics['sensitivity']:.4f}\")\n",
    "        print(f\"Specificity: {avg_metrics['specificity']:.4f}\")\n",
    "        print(f\"Score: {avg_metrics['score']:.4f}\")\n",
    "        print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "\n",
    "        return avg_metrics, fold_histories\n",
    "\n",
    "    def plot_training_history(self, fold_histories):\n",
    "        \"\"\"\n",
    "        Plot average training and validation metrics across folds.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        avg_train_acc = np.mean([h.history['accuracy'] for h in fold_histories], axis=0)\n",
    "        avg_val_acc = np.mean([h.history['val_accuracy'] for h in fold_histories], axis=0)\n",
    "        avg_train_loss = np.mean([h.history['loss'] for h in fold_histories], axis=0)\n",
    "        avg_val_loss = np.mean([h.history['val_loss'] for h in fold_histories], axis=0)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(avg_train_acc, label='Average Training Accuracy')\n",
    "        plt.plot(avg_val_acc, label='Average Validation Accuracy')\n",
    "        plt.title('Average Model Accuracy Across Folds')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(avg_train_loss, label='Average Training Loss')\n",
    "        plt.plot(avg_val_loss, label='Average Validation Loss')\n",
    "        plt.title('Average Model Loss Across Folds')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    classifier = LungSoundClassifier()\n",
    "    try:\n",
    "        X, y, patient_ids = classifier.load_and_preprocess_data(spectrograms_dir)\n",
    "        avg_metrics, fold_histories = classifier.train(X, y, patient_ids)\n",
    "        classifier.plot_training_history(fold_histories)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please ensure the spectrograms directory exists and contains spectrograms_resized.npy, labels.npy, and patient_ids.npy.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet18...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │      \u001b[38;5;34m3,200\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │     \u001b[38;5;34m73,856\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │      \u001b[38;5;34m8,320\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,180,160\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m131,584\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m2,052\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,445,764</span> (43.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,445,764\u001b[0m (43.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,437,956</span> (43.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,437,956\u001b[0m (43.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> (30.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,808\u001b[0m (30.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 - Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 320ms/step - accuracy: 0.4737 - loss: 0.0516 - val_accuracy: 0.5934 - val_loss: 0.0378\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.5530 - loss: 0.0324 - val_accuracy: 0.5878 - val_loss: 0.0392\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.5971 - loss: 0.0283 - val_accuracy: 0.5499 - val_loss: 0.0389\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.6408 - loss: 0.0233 - val_accuracy: 0.5435 - val_loss: 0.0423\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.6824 - loss: 0.0191 - val_accuracy: 0.4114 - val_loss: 0.0485\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.7293 - loss: 0.0146 - val_accuracy: 0.3285 - val_loss: 0.0968\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.7618 - loss: 0.0129 - val_accuracy: 0.4436 - val_loss: 0.0902\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.8052 - loss: 0.0100 - val_accuracy: 0.2818 - val_loss: 0.0887\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.8408 - loss: 0.0083 - val_accuracy: 0.5934 - val_loss: 0.0857\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.8652 - loss: 0.0074 - val_accuracy: 0.3986 - val_loss: 0.0767\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.8777 - loss: 0.0061 - val_accuracy: 0.4831 - val_loss: 0.0761\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9034 - loss: 0.0048 - val_accuracy: 0.5572 - val_loss: 0.0854\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9170 - loss: 0.0040 - val_accuracy: 0.5274 - val_loss: 0.0694\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9295 - loss: 0.0041 - val_accuracy: 0.5507 - val_loss: 0.0783\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9342 - loss: 0.0035 - val_accuracy: 0.5709 - val_loss: 0.0807\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9408 - loss: 0.0032 - val_accuracy: 0.5757 - val_loss: 0.0953\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9310 - loss: 0.0035 - val_accuracy: 0.5620 - val_loss: 0.0680\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9173 - loss: 0.0048 - val_accuracy: 0.4936 - val_loss: 0.0817\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9479 - loss: 0.0028 - val_accuracy: 0.5491 - val_loss: 0.0934\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9626 - loss: 0.0021 - val_accuracy: 0.5862 - val_loss: 0.0945\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9655 - loss: 0.0018 - val_accuracy: 0.5700 - val_loss: 0.0858\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9668 - loss: 0.0018 - val_accuracy: 0.5507 - val_loss: 0.1016\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9687 - loss: 0.0017 - val_accuracy: 0.5258 - val_loss: 0.0882\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9662 - loss: 0.0017 - val_accuracy: 0.5515 - val_loss: 0.0902\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9655 - loss: 0.0020 - val_accuracy: 0.5475 - val_loss: 0.0844\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9819 - loss: 0.0010 - val_accuracy: 0.5676 - val_loss: 0.1116\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9687 - loss: 0.0020 - val_accuracy: 0.5604 - val_loss: 0.0863\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9798 - loss: 0.0011 - val_accuracy: 0.5797 - val_loss: 0.1212\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9826 - loss: 8.6592e-04 - val_accuracy: 0.5636 - val_loss: 0.0805\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9584 - loss: 0.0024 - val_accuracy: 0.5499 - val_loss: 0.0899\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 0.9633 - loss: 0.0020 - val_accuracy: 0.5282 - val_loss: 0.0903\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9793 - loss: 0.0013 - val_accuracy: 0.5435 - val_loss: 0.1005\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 0.9740 - loss: 0.0011 - val_accuracy: 0.5000 - val_loss: 0.1041\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9846 - loss: 6.9433e-04 - val_accuracy: 0.4742 - val_loss: 0.1047\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9832 - loss: 9.8058e-04 - val_accuracy: 0.4783 - val_loss: 0.1038\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9790 - loss: 0.0013 - val_accuracy: 0.5692 - val_loss: 0.0778\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9738 - loss: 0.0014 - val_accuracy: 0.5274 - val_loss: 0.1434\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9912 - loss: 4.8369e-04 - val_accuracy: 0.5499 - val_loss: 0.1312\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9630 - loss: 0.0027 - val_accuracy: 0.5097 - val_loss: 0.1128\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9850 - loss: 8.0793e-04 - val_accuracy: 0.5250 - val_loss: 0.0906\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9722 - loss: 0.0017 - val_accuracy: 0.4573 - val_loss: 0.1295\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9695 - loss: 0.0016 - val_accuracy: 0.4919 - val_loss: 0.0882\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9732 - loss: 0.0016 - val_accuracy: 0.5612 - val_loss: 0.1149\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9722 - loss: 0.0016 - val_accuracy: 0.5378 - val_loss: 0.1089\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9766 - loss: 0.0014 - val_accuracy: 0.4855 - val_loss: 0.0849\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9829 - loss: 8.6597e-04 - val_accuracy: 0.4791 - val_loss: 0.1127\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9964 - loss: 2.1933e-04 - val_accuracy: 0.5435 - val_loss: 0.1379\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9827 - loss: 0.0013 - val_accuracy: 0.4944 - val_loss: 0.1014\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9874 - loss: 7.0180e-04 - val_accuracy: 0.4614 - val_loss: 0.1181\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9828 - loss: 9.9812e-04 - val_accuracy: 0.5306 - val_loss: 0.1153\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step\n",
      "ResNet18 - Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.8840 - loss: 0.0136 - val_accuracy: 0.5684 - val_loss: 0.0538\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9507 - loss: 0.0037 - val_accuracy: 0.5306 - val_loss: 0.0649\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 304ms/step - accuracy: 0.9775 - loss: 0.0014 - val_accuracy: 0.5564 - val_loss: 0.0918\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9586 - loss: 0.0025 - val_accuracy: 0.5137 - val_loss: 0.0874\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9780 - loss: 0.0012 - val_accuracy: 0.5515 - val_loss: 0.0996\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9754 - loss: 0.0012 - val_accuracy: 0.5242 - val_loss: 0.0905\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9894 - loss: 5.5294e-04 - val_accuracy: 0.5113 - val_loss: 0.0983\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9945 - loss: 4.3589e-04 - val_accuracy: 0.5064 - val_loss: 0.1062\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9784 - loss: 0.0013 - val_accuracy: 0.5419 - val_loss: 0.1129\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9903 - loss: 4.9278e-04 - val_accuracy: 0.5781 - val_loss: 0.1133\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9800 - loss: 0.0011 - val_accuracy: 0.5330 - val_loss: 0.1006\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9928 - loss: 5.9634e-04 - val_accuracy: 0.5169 - val_loss: 0.1005\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 0.9923 - loss: 4.2289e-04 - val_accuracy: 0.5169 - val_loss: 0.1202\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 0.9924 - loss: 4.9829e-04 - val_accuracy: 0.5628 - val_loss: 0.0901\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9635 - loss: 0.0022 - val_accuracy: 0.5129 - val_loss: 0.0895\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9899 - loss: 5.0013e-04 - val_accuracy: 0.5225 - val_loss: 0.1408\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9739 - loss: 0.0017 - val_accuracy: 0.5435 - val_loss: 0.0743\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 0.9734 - loss: 0.0015 - val_accuracy: 0.5008 - val_loss: 0.0933\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9852 - loss: 8.9210e-04 - val_accuracy: 0.5403 - val_loss: 0.0783\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 0.9688 - loss: 0.0017 - val_accuracy: 0.5233 - val_loss: 0.1031\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 0.9899 - loss: 5.6026e-04 - val_accuracy: 0.5539 - val_loss: 0.1076\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 0.9965 - loss: 1.9471e-04 - val_accuracy: 0.5370 - val_loss: 0.1176\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 0.9985 - loss: 8.9769e-05 - val_accuracy: 0.5588 - val_loss: 0.1163\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9870 - loss: 6.5698e-04 - val_accuracy: 0.5564 - val_loss: 0.1028\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 0.9859 - loss: 0.0011 - val_accuracy: 0.5258 - val_loss: 0.1020\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9744 - loss: 0.0015 - val_accuracy: 0.5378 - val_loss: 0.0964\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 0.9944 - loss: 3.1625e-04 - val_accuracy: 0.5193 - val_loss: 0.0973\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9977 - loss: 1.4656e-04 - val_accuracy: 0.5451 - val_loss: 0.1178\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9997 - loss: 3.3056e-05 - val_accuracy: 0.4952 - val_loss: 0.1200\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 8.8960e-06 - val_accuracy: 0.5153 - val_loss: 0.1335\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 2.6661e-06 - val_accuracy: 0.5217 - val_loss: 0.1356\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 1.9066e-06 - val_accuracy: 0.5217 - val_loss: 0.1383\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 1.5592e-06 - val_accuracy: 0.5193 - val_loss: 0.1413\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 1.4766e-06 - val_accuracy: 0.5233 - val_loss: 0.1417\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 6.6532e-07 - val_accuracy: 0.5233 - val_loss: 0.1427\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 6.3387e-07 - val_accuracy: 0.5242 - val_loss: 0.1443\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 6.3878e-07 - val_accuracy: 0.5250 - val_loss: 0.1451\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 7.4079e-07 - val_accuracy: 0.5209 - val_loss: 0.1463\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 5.2474e-07 - val_accuracy: 0.5217 - val_loss: 0.1477\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 4.1636e-07 - val_accuracy: 0.5209 - val_loss: 0.1486\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 4.9194e-07 - val_accuracy: 0.5242 - val_loss: 0.1496\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 4.6571e-07 - val_accuracy: 0.5169 - val_loss: 0.1502\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 2.1886e-07 - val_accuracy: 0.5209 - val_loss: 0.1512\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 2.5910e-07 - val_accuracy: 0.5185 - val_loss: 0.1521\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 2.4982e-07 - val_accuracy: 0.5201 - val_loss: 0.1536\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 2.3666e-07 - val_accuracy: 0.5193 - val_loss: 0.1544\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 2.0173e-07 - val_accuracy: 0.5225 - val_loss: 0.1554\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 3.0252e-07 - val_accuracy: 0.5169 - val_loss: 0.1573\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.9246e-07 - val_accuracy: 0.5209 - val_loss: 0.1583\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.5119e-07 - val_accuracy: 0.5250 - val_loss: 0.1592\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step\n",
      "ResNet18 - Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.7781 - loss: 0.0156 - val_accuracy: 0.4726 - val_loss: 0.1068\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.9104 - loss: 0.0051 - val_accuracy: 0.5821 - val_loss: 0.0907\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9691 - loss: 0.0016 - val_accuracy: 0.5564 - val_loss: 0.0866\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9713 - loss: 0.0017 - val_accuracy: 0.4952 - val_loss: 0.0819\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9860 - loss: 7.3973e-04 - val_accuracy: 0.3325 - val_loss: 0.1284\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9859 - loss: 6.9202e-04 - val_accuracy: 0.5467 - val_loss: 0.1258\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9978 - loss: 1.2507e-04 - val_accuracy: 0.5242 - val_loss: 0.1351\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.7984e-05 - val_accuracy: 0.5072 - val_loss: 0.1303\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.6482e-06 - val_accuracy: 0.5048 - val_loss: 0.1335\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 3.3740e-06 - val_accuracy: 0.5064 - val_loss: 0.1351\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 2.1407e-06 - val_accuracy: 0.5105 - val_loss: 0.1368\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.6086e-06 - val_accuracy: 0.5016 - val_loss: 0.1388\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.0656e-06 - val_accuracy: 0.5056 - val_loss: 0.1410\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 1.1621e-06 - val_accuracy: 0.5024 - val_loss: 0.1422\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.1254e-06 - val_accuracy: 0.5032 - val_loss: 0.1438\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.0078e-06 - val_accuracy: 0.5064 - val_loss: 0.1447\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 7.3189e-07 - val_accuracy: 0.5056 - val_loss: 0.1456\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 7.5611e-07 - val_accuracy: 0.5000 - val_loss: 0.1470\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 5.5700e-07 - val_accuracy: 0.5008 - val_loss: 0.1480\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 5.2799e-07 - val_accuracy: 0.5008 - val_loss: 0.1488\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 4.0122e-07 - val_accuracy: 0.5000 - val_loss: 0.1499\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 3.5945e-07 - val_accuracy: 0.5000 - val_loss: 0.1509\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 4.4344e-07 - val_accuracy: 0.5000 - val_loss: 0.1520\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 2.3620e-07 - val_accuracy: 0.5008 - val_loss: 0.1537\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 2.6540e-07 - val_accuracy: 0.4984 - val_loss: 0.1547\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 3.0279e-07 - val_accuracy: 0.4968 - val_loss: 0.1555\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.9214e-07 - val_accuracy: 0.5000 - val_loss: 0.1569\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.5219e-07 - val_accuracy: 0.5008 - val_loss: 0.1580\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.7158e-07 - val_accuracy: 0.5040 - val_loss: 0.1593\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.8346e-07 - val_accuracy: 0.5016 - val_loss: 0.1596\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.5835e-07 - val_accuracy: 0.5000 - val_loss: 0.1605\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 1.6208e-07 - val_accuracy: 0.4992 - val_loss: 0.1614\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.8236e-07 - val_accuracy: 0.4992 - val_loss: 0.1623\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.6506e-07 - val_accuracy: 0.5008 - val_loss: 0.1634\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.4972e-07 - val_accuracy: 0.5000 - val_loss: 0.1645\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 8.5375e-08 - val_accuracy: 0.4984 - val_loss: 0.1654\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.3824e-07 - val_accuracy: 0.5016 - val_loss: 0.1692\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.1549e-07 - val_accuracy: 0.5008 - val_loss: 0.1692\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 6.7318e-08 - val_accuracy: 0.5016 - val_loss: 0.1700\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 8.0194e-08 - val_accuracy: 0.5008 - val_loss: 0.1710\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 5.0030e-08 - val_accuracy: 0.5024 - val_loss: 0.1717\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 5.3259e-08 - val_accuracy: 0.4976 - val_loss: 0.1723\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 6.3051e-08 - val_accuracy: 0.5000 - val_loss: 0.1732\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 4.2878e-08 - val_accuracy: 0.5040 - val_loss: 0.1747\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.0472e-07 - val_accuracy: 0.4992 - val_loss: 0.1759\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 8.4937e-08 - val_accuracy: 0.5008 - val_loss: 0.1761\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 3.8581e-08 - val_accuracy: 0.4968 - val_loss: 0.1771\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 4.2071e-08 - val_accuracy: 0.4968 - val_loss: 0.1778\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 3.1118e-08 - val_accuracy: 0.4984 - val_loss: 0.1785\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 2.5553e-08 - val_accuracy: 0.4976 - val_loss: 0.1789\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "ResNet18 - Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.7906 - loss: 0.0174 - val_accuracy: 0.5725 - val_loss: 0.0567\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9141 - loss: 0.0052 - val_accuracy: 0.6345 - val_loss: 0.0653\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9698 - loss: 0.0017 - val_accuracy: 0.6039 - val_loss: 0.0797\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9919 - loss: 3.3560e-04 - val_accuracy: 0.5749 - val_loss: 0.0742\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9960 - loss: 1.7828e-04 - val_accuracy: 0.5700 - val_loss: 0.0997\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9990 - loss: 1.7814e-04 - val_accuracy: 0.5974 - val_loss: 0.0958\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.4009e-05 - val_accuracy: 0.5717 - val_loss: 0.1037\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 5.6787e-06 - val_accuracy: 0.5805 - val_loss: 0.1060\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.7786e-06 - val_accuracy: 0.5789 - val_loss: 0.1081\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.4171e-06 - val_accuracy: 0.5837 - val_loss: 0.1100\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 1.9650e-06 - val_accuracy: 0.5853 - val_loss: 0.1123\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.4544e-06 - val_accuracy: 0.5845 - val_loss: 0.1138\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.7306e-06 - val_accuracy: 0.5837 - val_loss: 0.1154\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.0378e-06 - val_accuracy: 0.5781 - val_loss: 0.1169\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.1372e-06 - val_accuracy: 0.5870 - val_loss: 0.1175\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 8.6226e-07 - val_accuracy: 0.5845 - val_loss: 0.1190\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 6.2952e-07 - val_accuracy: 0.5853 - val_loss: 0.1200\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.6531e-07 - val_accuracy: 0.5853 - val_loss: 0.1209\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 7.1392e-07 - val_accuracy: 0.5853 - val_loss: 0.1216\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 4.0454e-07 - val_accuracy: 0.5837 - val_loss: 0.1228\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 4.0535e-07 - val_accuracy: 0.5894 - val_loss: 0.1234\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 5.0156e-07 - val_accuracy: 0.5878 - val_loss: 0.1244\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 9.1145e-07 - val_accuracy: 0.5878 - val_loss: 0.1252\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 4.4534e-07 - val_accuracy: 0.5894 - val_loss: 0.1263\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 3.0844e-07 - val_accuracy: 0.5886 - val_loss: 0.1270\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 2.5356e-07 - val_accuracy: 0.5894 - val_loss: 0.1281\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 4.7854e-07 - val_accuracy: 0.5853 - val_loss: 0.1289\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 1.3616e-07 - val_accuracy: 0.5853 - val_loss: 0.1299\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 1.9200e-07 - val_accuracy: 0.5878 - val_loss: 0.1306\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.9845e-07 - val_accuracy: 0.5902 - val_loss: 0.1314\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.5200e-07 - val_accuracy: 0.5894 - val_loss: 0.1321\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.7493e-07 - val_accuracy: 0.5821 - val_loss: 0.1333\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.3183e-07 - val_accuracy: 0.5805 - val_loss: 0.1342\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 2.6171e-07 - val_accuracy: 0.5821 - val_loss: 0.1350\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.1390e-07 - val_accuracy: 0.5821 - val_loss: 0.1361\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.3759e-07 - val_accuracy: 0.5821 - val_loss: 0.1376\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 2.1797e-07 - val_accuracy: 0.5821 - val_loss: 0.1382\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.4768e-07 - val_accuracy: 0.5845 - val_loss: 0.1390\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 1.1171e-07 - val_accuracy: 0.5709 - val_loss: 0.1414\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.0503e-07 - val_accuracy: 0.5765 - val_loss: 0.1417\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 8.6123e-08 - val_accuracy: 0.5684 - val_loss: 0.1442\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 9.1056e-08 - val_accuracy: 0.5781 - val_loss: 0.1439\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.1272e-07 - val_accuracy: 0.5773 - val_loss: 0.1447\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 5.1062e-08 - val_accuracy: 0.5789 - val_loss: 0.1445\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.0385e-07 - val_accuracy: 0.5813 - val_loss: 0.1443\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 7.0020e-08 - val_accuracy: 0.5821 - val_loss: 0.1463\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 6.6560e-08 - val_accuracy: 0.5910 - val_loss: 0.1458\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 4.1954e-08 - val_accuracy: 0.5837 - val_loss: 0.1474\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 4.1094e-08 - val_accuracy: 0.5829 - val_loss: 0.1469\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 5.5479e-08 - val_accuracy: 0.5837 - val_loss: 0.1477\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step\n",
      "ResNet18 - Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.7718 - loss: 0.0191 - val_accuracy: 0.5089 - val_loss: 0.0602\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.8984 - loss: 0.0061 - val_accuracy: 0.5177 - val_loss: 0.0803\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9791 - loss: 0.0012 - val_accuracy: 0.5539 - val_loss: 0.0829\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9838 - loss: 8.4909e-04 - val_accuracy: 0.4976 - val_loss: 0.1046\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9875 - loss: 6.7983e-04 - val_accuracy: 0.4823 - val_loss: 0.1136\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9959 - loss: 2.5454e-04 - val_accuracy: 0.5386 - val_loss: 0.1154\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9937 - loss: 3.4163e-04 - val_accuracy: 0.4042 - val_loss: 0.1081\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9813 - loss: 0.0012 - val_accuracy: 0.5636 - val_loss: 0.0858\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9956 - loss: 1.7909e-04 - val_accuracy: 0.5531 - val_loss: 0.1144\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9973 - loss: 2.5139e-04 - val_accuracy: 0.5789 - val_loss: 0.1141\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9952 - loss: 2.2256e-04 - val_accuracy: 0.5652 - val_loss: 0.1121\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9994 - loss: 5.5554e-05 - val_accuracy: 0.5539 - val_loss: 0.1253\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 7.8674e-06 - val_accuracy: 0.5451 - val_loss: 0.1231\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 4.0757e-06 - val_accuracy: 0.5419 - val_loss: 0.1257\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 2.9701e-06 - val_accuracy: 0.5378 - val_loss: 0.1282\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 2.1058e-06 - val_accuracy: 0.5378 - val_loss: 0.1295\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.5203e-06 - val_accuracy: 0.5403 - val_loss: 0.1314\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.5274e-06 - val_accuracy: 0.5386 - val_loss: 0.1328\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.4595e-06 - val_accuracy: 0.5395 - val_loss: 0.1342\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 1.1690e-06 - val_accuracy: 0.5370 - val_loss: 0.1357\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.5988e-06 - val_accuracy: 0.5395 - val_loss: 0.1366\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 8.6725e-07 - val_accuracy: 0.5370 - val_loss: 0.1377\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 5.5763e-07 - val_accuracy: 0.5346 - val_loss: 0.1388\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 6.4858e-07 - val_accuracy: 0.5403 - val_loss: 0.1395\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 6.8984e-07 - val_accuracy: 0.5386 - val_loss: 0.1408\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 4.6233e-07 - val_accuracy: 0.5370 - val_loss: 0.1419\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 5.4902e-07 - val_accuracy: 0.5386 - val_loss: 0.1429\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 4.2718e-07 - val_accuracy: 0.5395 - val_loss: 0.1437\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.4913e-07 - val_accuracy: 0.5395 - val_loss: 0.1442\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 3.0315e-07 - val_accuracy: 0.5386 - val_loss: 0.1453\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 3.0486e-07 - val_accuracy: 0.5419 - val_loss: 0.1460\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 3.1576e-07 - val_accuracy: 0.5419 - val_loss: 0.1471\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.7585e-07 - val_accuracy: 0.5403 - val_loss: 0.1480\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.8408e-07 - val_accuracy: 0.5427 - val_loss: 0.1486\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.7043e-07 - val_accuracy: 0.5403 - val_loss: 0.1494\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 2.3241e-07 - val_accuracy: 0.5395 - val_loss: 0.1502\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 3.0655e-07 - val_accuracy: 0.5411 - val_loss: 0.1514\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.6895e-07 - val_accuracy: 0.5419 - val_loss: 0.1520\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.1670e-07 - val_accuracy: 0.5419 - val_loss: 0.1530\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 1.7879e-07 - val_accuracy: 0.5427 - val_loss: 0.1538\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 1.4536e-07 - val_accuracy: 0.5411 - val_loss: 0.1547\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.0104e-07 - val_accuracy: 0.5419 - val_loss: 0.1549\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 9.4968e-08 - val_accuracy: 0.5427 - val_loss: 0.1555\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.0730e-07 - val_accuracy: 0.5411 - val_loss: 0.1565\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.3347e-07 - val_accuracy: 0.5378 - val_loss: 0.1573\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 8.3912e-08 - val_accuracy: 0.5378 - val_loss: 0.1583\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 4.5678e-08 - val_accuracy: 0.5411 - val_loss: 0.1593\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 5.2722e-08 - val_accuracy: 0.5403 - val_loss: 0.1603\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 5.3352e-08 - val_accuracy: 0.5403 - val_loss: 0.1604\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.1994e-07 - val_accuracy: 0.5419 - val_loss: 0.1608\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n",
      "ResNet18 - Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.8433 - loss: 0.0129 - val_accuracy: 0.5797 - val_loss: 0.0551\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9586 - loss: 0.0026 - val_accuracy: 0.5628 - val_loss: 0.0783\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9862 - loss: 6.6588e-04 - val_accuracy: 0.5161 - val_loss: 0.1051\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9904 - loss: 5.6863e-04 - val_accuracy: 0.5121 - val_loss: 0.1028\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9922 - loss: 6.1335e-04 - val_accuracy: 0.5378 - val_loss: 0.0993\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9908 - loss: 6.6155e-04 - val_accuracy: 0.5145 - val_loss: 0.1036\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9913 - loss: 4.1393e-04 - val_accuracy: 0.4871 - val_loss: 0.1044\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9894 - loss: 5.8032e-04 - val_accuracy: 0.5934 - val_loss: 0.0848\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9947 - loss: 2.9115e-04 - val_accuracy: 0.5910 - val_loss: 0.0928\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9934 - loss: 3.7716e-04 - val_accuracy: 0.5700 - val_loss: 0.0934\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9944 - loss: 2.4007e-04 - val_accuracy: 0.5950 - val_loss: 0.1026\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9990 - loss: 3.7010e-05 - val_accuracy: 0.6047 - val_loss: 0.1096\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9997 - loss: 2.5107e-05 - val_accuracy: 0.5837 - val_loss: 0.1165\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.8035e-06 - val_accuracy: 0.5821 - val_loss: 0.1210\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.9898e-06 - val_accuracy: 0.5853 - val_loss: 0.1226\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.5014e-06 - val_accuracy: 0.5878 - val_loss: 0.1246\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 9.1251e-07 - val_accuracy: 0.5894 - val_loss: 0.1253\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 1.0800e-06 - val_accuracy: 0.5878 - val_loss: 0.1261\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 6.5142e-07 - val_accuracy: 0.5878 - val_loss: 0.1267\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 7.3954e-07 - val_accuracy: 0.5910 - val_loss: 0.1279\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 9.7243e-07 - val_accuracy: 0.5862 - val_loss: 0.1291\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 6.8624e-07 - val_accuracy: 0.5886 - val_loss: 0.1299\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 4.7672e-07 - val_accuracy: 0.5878 - val_loss: 0.1308\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 4.6500e-07 - val_accuracy: 0.5894 - val_loss: 0.1315\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 3.3132e-07 - val_accuracy: 0.5870 - val_loss: 0.1322\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 2.5446e-07 - val_accuracy: 0.5853 - val_loss: 0.1329\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 3.8691e-07 - val_accuracy: 0.5862 - val_loss: 0.1335\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 3.9522e-07 - val_accuracy: 0.5862 - val_loss: 0.1343\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 3.0098e-07 - val_accuracy: 0.5862 - val_loss: 0.1351\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 2.0138e-07 - val_accuracy: 0.5862 - val_loss: 0.1358\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.6455e-07 - val_accuracy: 0.5862 - val_loss: 0.1362\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.1584e-07 - val_accuracy: 0.5870 - val_loss: 0.1369\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.8580e-07 - val_accuracy: 0.5870 - val_loss: 0.1375\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 2.0922e-07 - val_accuracy: 0.5870 - val_loss: 0.1384\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.1897e-07 - val_accuracy: 0.5878 - val_loss: 0.1390\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.2696e-07 - val_accuracy: 0.5878 - val_loss: 0.1397\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.1663e-07 - val_accuracy: 0.5870 - val_loss: 0.1406\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.4003e-07 - val_accuracy: 0.5862 - val_loss: 0.1412\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 7.0298e-08 - val_accuracy: 0.5878 - val_loss: 0.1416\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 7.2096e-08 - val_accuracy: 0.5870 - val_loss: 0.1420\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 9.3443e-08 - val_accuracy: 0.5878 - val_loss: 0.1426\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 5.7520e-08 - val_accuracy: 0.5870 - val_loss: 0.1433\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 6.6414e-08 - val_accuracy: 0.5870 - val_loss: 0.1440\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.9636e-07 - val_accuracy: 0.5862 - val_loss: 0.1447\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 7.8859e-08 - val_accuracy: 0.5870 - val_loss: 0.1455\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 4.4503e-08 - val_accuracy: 0.5878 - val_loss: 0.1459\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 4.3595e-08 - val_accuracy: 0.5886 - val_loss: 0.1462\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.8162e-08 - val_accuracy: 0.5862 - val_loss: 0.1475\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 3.9956e-08 - val_accuracy: 0.5845 - val_loss: 0.1479\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 3.9259e-08 - val_accuracy: 0.5845 - val_loss: 0.1485\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "ResNet18 - Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.8855 - loss: 0.0093 - val_accuracy: 0.4090 - val_loss: 0.0868\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9631 - loss: 0.0021 - val_accuracy: 0.5201 - val_loss: 0.0841\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9934 - loss: 4.2998e-04 - val_accuracy: 0.5298 - val_loss: 0.1003\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9988 - loss: 5.8000e-05 - val_accuracy: 0.5660 - val_loss: 0.1011\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9991 - loss: 4.8136e-05 - val_accuracy: 0.5395 - val_loss: 0.1106\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9870 - loss: 7.8214e-04 - val_accuracy: 0.5757 - val_loss: 0.0804\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9901 - loss: 5.2942e-04 - val_accuracy: 0.5805 - val_loss: 0.0738\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9854 - loss: 8.3850e-04 - val_accuracy: 0.5395 - val_loss: 0.0701\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9928 - loss: 5.5534e-04 - val_accuracy: 0.5620 - val_loss: 0.0914\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9995 - loss: 4.6239e-05 - val_accuracy: 0.5741 - val_loss: 0.0959\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 4.7381e-06 - val_accuracy: 0.5733 - val_loss: 0.1014\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.2653e-06 - val_accuracy: 0.5741 - val_loss: 0.1043\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 2.0303e-06 - val_accuracy: 0.5741 - val_loss: 0.1067\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.5602e-06 - val_accuracy: 0.5725 - val_loss: 0.1088\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.8181e-06 - val_accuracy: 0.5692 - val_loss: 0.1105\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.1790e-06 - val_accuracy: 0.5700 - val_loss: 0.1124\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 9.1195e-07 - val_accuracy: 0.5668 - val_loss: 0.1144\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.0330e-06 - val_accuracy: 0.5692 - val_loss: 0.1154\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 7.7869e-07 - val_accuracy: 0.5692 - val_loss: 0.1167\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 5.2180e-07 - val_accuracy: 0.5684 - val_loss: 0.1178\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 3.1137e-07 - val_accuracy: 0.5684 - val_loss: 0.1183\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 4.2617e-07 - val_accuracy: 0.5684 - val_loss: 0.1197\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 8.3094e-07 - val_accuracy: 0.5692 - val_loss: 0.1207\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.4176e-07 - val_accuracy: 0.5700 - val_loss: 0.1215\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 2.5667e-07 - val_accuracy: 0.5660 - val_loss: 0.1227\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 3.9628e-07 - val_accuracy: 0.5676 - val_loss: 0.1236\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 2.5396e-07 - val_accuracy: 0.5644 - val_loss: 0.1245\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 2.3391e-07 - val_accuracy: 0.5636 - val_loss: 0.1254\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 2.4976e-07 - val_accuracy: 0.5620 - val_loss: 0.1266\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.6554e-07 - val_accuracy: 0.5636 - val_loss: 0.1275\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.7415e-07 - val_accuracy: 0.5636 - val_loss: 0.1282\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 1.7015e-07 - val_accuracy: 0.5620 - val_loss: 0.1289\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.4201e-07 - val_accuracy: 0.5660 - val_loss: 0.1296\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.4643e-07 - val_accuracy: 0.5636 - val_loss: 0.1307\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.6797e-07 - val_accuracy: 0.5652 - val_loss: 0.1323\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 9.1425e-08 - val_accuracy: 0.5668 - val_loss: 0.1329\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 1.0153e-07 - val_accuracy: 0.5636 - val_loss: 0.1335\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.4843e-07 - val_accuracy: 0.5620 - val_loss: 0.1344\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 8.8078e-08 - val_accuracy: 0.5644 - val_loss: 0.1351\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 6.5183e-08 - val_accuracy: 0.5636 - val_loss: 0.1359\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 6.0208e-08 - val_accuracy: 0.5620 - val_loss: 0.1368\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 9.6136e-08 - val_accuracy: 0.5612 - val_loss: 0.1376\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 9.9612e-08 - val_accuracy: 0.5684 - val_loss: 0.1382\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.0297e-07 - val_accuracy: 0.5668 - val_loss: 0.1388\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.7051e-08 - val_accuracy: 0.5652 - val_loss: 0.1396\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.0073e-07 - val_accuracy: 0.5644 - val_loss: 0.1405\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 6.1957e-08 - val_accuracy: 0.5652 - val_loss: 0.1418\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 7.4186e-08 - val_accuracy: 0.5636 - val_loss: 0.1423\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 3.3486e-08 - val_accuracy: 0.5620 - val_loss: 0.1430\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 5.7214e-08 - val_accuracy: 0.5628 - val_loss: 0.1443\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "ResNet18 - Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.8671 - loss: 0.0105 - val_accuracy: 0.4404 - val_loss: 0.0881\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9675 - loss: 0.0022 - val_accuracy: 0.5282 - val_loss: 0.0932\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9943 - loss: 4.4168e-04 - val_accuracy: 0.5217 - val_loss: 0.1282\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9932 - loss: 3.7479e-04 - val_accuracy: 0.4815 - val_loss: 0.1264\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9947 - loss: 2.6633e-04 - val_accuracy: 0.5032 - val_loss: 0.1399\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9959 - loss: 1.6551e-04 - val_accuracy: 0.5225 - val_loss: 0.1297\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9978 - loss: 1.1050e-04 - val_accuracy: 0.5137 - val_loss: 0.1351\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.8903e-05 - val_accuracy: 0.5314 - val_loss: 0.1482\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 3.7270e-06 - val_accuracy: 0.5266 - val_loss: 0.1517\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 2.4292e-06 - val_accuracy: 0.5266 - val_loss: 0.1539\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.9512e-06 - val_accuracy: 0.5274 - val_loss: 0.1560\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.4174e-06 - val_accuracy: 0.5266 - val_loss: 0.1576\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.2716e-06 - val_accuracy: 0.5266 - val_loss: 0.1593\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 7.7864e-07 - val_accuracy: 0.5266 - val_loss: 0.1607\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 7.1008e-07 - val_accuracy: 0.5274 - val_loss: 0.1622\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 6.6928e-07 - val_accuracy: 0.5266 - val_loss: 0.1633\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 6.4055e-07 - val_accuracy: 0.5266 - val_loss: 0.1640\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 6.2245e-07 - val_accuracy: 0.5266 - val_loss: 0.1653\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.4233e-07 - val_accuracy: 0.5258 - val_loss: 0.1665\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 6.4057e-07 - val_accuracy: 0.5242 - val_loss: 0.1676\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 4.1357e-07 - val_accuracy: 0.5225 - val_loss: 0.1688\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.5204e-07 - val_accuracy: 0.5233 - val_loss: 0.1696\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 2.4113e-07 - val_accuracy: 0.5217 - val_loss: 0.1706\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 3.9452e-07 - val_accuracy: 0.5217 - val_loss: 0.1718\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 2.0155e-07 - val_accuracy: 0.5233 - val_loss: 0.1726\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 3.2424e-07 - val_accuracy: 0.5217 - val_loss: 0.1737\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.8857e-07 - val_accuracy: 0.5201 - val_loss: 0.1749\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.7415e-07 - val_accuracy: 0.5209 - val_loss: 0.1756\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 2.0803e-07 - val_accuracy: 0.5193 - val_loss: 0.1767\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.4391e-07 - val_accuracy: 0.5201 - val_loss: 0.1777\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 4.5614e-07 - val_accuracy: 0.5185 - val_loss: 0.1783\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.0681e-07 - val_accuracy: 0.5185 - val_loss: 0.1796\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 7.0264e-08 - val_accuracy: 0.5217 - val_loss: 0.1805\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 3.7354e-07 - val_accuracy: 0.5193 - val_loss: 0.1811\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 6.4761e-08 - val_accuracy: 0.5201 - val_loss: 0.1821\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 7.3435e-08 - val_accuracy: 0.5201 - val_loss: 0.1828\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 4.9940e-08 - val_accuracy: 0.5201 - val_loss: 0.1834\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 7.3999e-08 - val_accuracy: 0.5193 - val_loss: 0.1849\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 4.8049e-08 - val_accuracy: 0.5193 - val_loss: 0.1854\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 4.6701e-08 - val_accuracy: 0.5209 - val_loss: 0.1858\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 7.2803e-08 - val_accuracy: 0.5250 - val_loss: 0.1876\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 6.3975e-08 - val_accuracy: 0.5233 - val_loss: 0.1881\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 5.3510e-08 - val_accuracy: 0.5201 - val_loss: 0.1887\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 4.7368e-08 - val_accuracy: 0.5209 - val_loss: 0.1893\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 7.4181e-08 - val_accuracy: 0.5169 - val_loss: 0.1902\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 3.8914e-08 - val_accuracy: 0.5201 - val_loss: 0.1910\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 6.4921e-08 - val_accuracy: 0.5217 - val_loss: 0.1923\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 4.3282e-08 - val_accuracy: 0.5209 - val_loss: 0.1931\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 2.8102e-08 - val_accuracy: 0.5201 - val_loss: 0.1940\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 4.0273e-08 - val_accuracy: 0.5209 - val_loss: 0.1944\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
      "ResNet18 - Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.8902 - loss: 0.0094 - val_accuracy: 0.5084 - val_loss: 0.0876\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 0.9706 - loss: 0.0018 - val_accuracy: 0.5020 - val_loss: 0.1100\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9959 - loss: 2.1487e-04 - val_accuracy: 0.5543 - val_loss: 0.1230\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9998 - loss: 3.2618e-05 - val_accuracy: 0.5527 - val_loss: 0.1255\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 7.0822e-06 - val_accuracy: 0.5519 - val_loss: 0.1376\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 4.4425e-06 - val_accuracy: 0.5535 - val_loss: 0.1423\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 3.0734e-06 - val_accuracy: 0.5535 - val_loss: 0.1437\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.5689e-06 - val_accuracy: 0.5551 - val_loss: 0.1466\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.3999e-06 - val_accuracy: 0.5543 - val_loss: 0.1483\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.1710e-06 - val_accuracy: 0.5551 - val_loss: 0.1499\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 9.6570e-07 - val_accuracy: 0.5559 - val_loss: 0.1523\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.0439e-06 - val_accuracy: 0.5559 - val_loss: 0.1537\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.0689e-06 - val_accuracy: 0.5543 - val_loss: 0.1561\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 7.3459e-07 - val_accuracy: 0.5543 - val_loss: 0.1581\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 3.6806e-07 - val_accuracy: 0.5543 - val_loss: 0.1590\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 6.4771e-07 - val_accuracy: 0.5559 - val_loss: 0.1597\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 4.2362e-07 - val_accuracy: 0.5567 - val_loss: 0.1616\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 5.3903e-07 - val_accuracy: 0.5567 - val_loss: 0.1631\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 5.1370e-07 - val_accuracy: 0.5559 - val_loss: 0.1631\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 2.6806e-07 - val_accuracy: 0.5551 - val_loss: 0.1643\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 3.5680e-07 - val_accuracy: 0.5543 - val_loss: 0.1659\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.7866e-07 - val_accuracy: 0.5543 - val_loss: 0.1666\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 2.7302e-07 - val_accuracy: 0.5543 - val_loss: 0.1680\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.8113e-07 - val_accuracy: 0.5543 - val_loss: 0.1690\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 3.5563e-07 - val_accuracy: 0.5527 - val_loss: 0.1682\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 1.4513e-07 - val_accuracy: 0.5527 - val_loss: 0.1699\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 2.7831e-07 - val_accuracy: 0.5527 - val_loss: 0.1722\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.1974e-07 - val_accuracy: 0.5527 - val_loss: 0.1733\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.2976e-07 - val_accuracy: 0.5503 - val_loss: 0.1743\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.9213e-07 - val_accuracy: 0.5527 - val_loss: 0.1764\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 6.8926e-08 - val_accuracy: 0.5559 - val_loss: 0.1772\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.0101e-07 - val_accuracy: 0.5551 - val_loss: 0.1784\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 8.7880e-08 - val_accuracy: 0.5551 - val_loss: 0.1787\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 5.1146e-08 - val_accuracy: 0.5551 - val_loss: 0.1793\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 7.4858e-08 - val_accuracy: 0.5551 - val_loss: 0.1807\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 6.9862e-08 - val_accuracy: 0.5543 - val_loss: 0.1811\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 5.9076e-08 - val_accuracy: 0.5551 - val_loss: 0.1827\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 5.8020e-08 - val_accuracy: 0.5559 - val_loss: 0.1832\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 4.1448e-08 - val_accuracy: 0.5551 - val_loss: 0.1839\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 6.6781e-08 - val_accuracy: 0.5543 - val_loss: 0.1842\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 5.3029e-08 - val_accuracy: 0.5551 - val_loss: 0.1853\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 4.1871e-08 - val_accuracy: 0.5543 - val_loss: 0.1869\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 1.1446e-07 - val_accuracy: 0.5519 - val_loss: 0.1873\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 7.5709e-08 - val_accuracy: 0.5511 - val_loss: 0.1883\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 3.3390e-08 - val_accuracy: 0.5519 - val_loss: 0.1889\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 2.9328e-08 - val_accuracy: 0.5519 - val_loss: 0.1883\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 3.5748e-08 - val_accuracy: 0.5503 - val_loss: 0.1887\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 3.3997e-08 - val_accuracy: 0.5511 - val_loss: 0.1896\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 1.6142e-08 - val_accuracy: 0.5503 - val_loss: 0.1900\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 1.7530e-08 - val_accuracy: 0.5519 - val_loss: 0.1913\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step\n",
      "ResNet18 - Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.8844 - loss: 0.0096 - val_accuracy: 0.5370 - val_loss: 0.0670\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9706 - loss: 0.0018 - val_accuracy: 0.5515 - val_loss: 0.1046\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9982 - loss: 9.8443e-05 - val_accuracy: 0.5741 - val_loss: 0.1081\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 0.9974 - loss: 1.9210e-04 - val_accuracy: 0.5773 - val_loss: 0.1026\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 0.9959 - loss: 2.5464e-04 - val_accuracy: 0.5483 - val_loss: 0.1210\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9993 - loss: 2.8776e-05 - val_accuracy: 0.5435 - val_loss: 0.1298\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 3.6150e-06 - val_accuracy: 0.5378 - val_loss: 0.1306\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 2.8454e-06 - val_accuracy: 0.5411 - val_loss: 0.1333\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 2.0090e-06 - val_accuracy: 0.5419 - val_loss: 0.1351\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 1.2508e-06 - val_accuracy: 0.5435 - val_loss: 0.1361\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 1.2339e-06 - val_accuracy: 0.5419 - val_loss: 0.1386\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 1.1992e-06 - val_accuracy: 0.5435 - val_loss: 0.1407\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 7.1404e-07 - val_accuracy: 0.5435 - val_loss: 0.1422\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 8.5383e-07 - val_accuracy: 0.5427 - val_loss: 0.1438\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 5.9317e-07 - val_accuracy: 0.5435 - val_loss: 0.1452\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 5.8459e-07 - val_accuracy: 0.5435 - val_loss: 0.1462\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 4.6680e-07 - val_accuracy: 0.5443 - val_loss: 0.1474\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 4.5939e-07 - val_accuracy: 0.5443 - val_loss: 0.1490\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 4.6348e-07 - val_accuracy: 0.5435 - val_loss: 0.1498\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 4.2333e-07 - val_accuracy: 0.5451 - val_loss: 0.1508\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 2.8066e-07 - val_accuracy: 0.5459 - val_loss: 0.1521\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 2.1461e-07 - val_accuracy: 0.5451 - val_loss: 0.1526\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 2.8988e-07 - val_accuracy: 0.5427 - val_loss: 0.1537\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 1.0000 - loss: 1.7978e-07 - val_accuracy: 0.5427 - val_loss: 0.1545\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 1.6305e-07 - val_accuracy: 0.5419 - val_loss: 0.1554\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 380ms/step - accuracy: 1.0000 - loss: 2.0370e-07 - val_accuracy: 0.5427 - val_loss: 0.1565\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 1.6458e-07 - val_accuracy: 0.5451 - val_loss: 0.1574\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 1.5263e-07 - val_accuracy: 0.5451 - val_loss: 0.1583\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 1.4292e-07 - val_accuracy: 0.5451 - val_loss: 0.1596\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 382ms/step - accuracy: 1.0000 - loss: 1.8064e-07 - val_accuracy: 0.5451 - val_loss: 0.1602\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 370ms/step - accuracy: 1.0000 - loss: 1.0207e-07 - val_accuracy: 0.5451 - val_loss: 0.1608\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 2.4297e-07 - val_accuracy: 0.5435 - val_loss: 0.1617\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 1.1311e-07 - val_accuracy: 0.5435 - val_loss: 0.1622\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 379ms/step - accuracy: 1.0000 - loss: 1.6942e-07 - val_accuracy: 0.5419 - val_loss: 0.1626\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 1.0966e-07 - val_accuracy: 0.5427 - val_loss: 0.1640\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 1.1027e-07 - val_accuracy: 0.5435 - val_loss: 0.1647\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 6.6397e-08 - val_accuracy: 0.5435 - val_loss: 0.1659\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 7.1531e-08 - val_accuracy: 0.5419 - val_loss: 0.1663\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 5.8108e-08 - val_accuracy: 0.5435 - val_loss: 0.1674\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 3.9642e-08 - val_accuracy: 0.5427 - val_loss: 0.1679\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 7.2098e-08 - val_accuracy: 0.5427 - val_loss: 0.1687\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 9.4896e-08 - val_accuracy: 0.5403 - val_loss: 0.1706\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 4.9669e-08 - val_accuracy: 0.5427 - val_loss: 0.1710\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 3.3315e-08 - val_accuracy: 0.5443 - val_loss: 0.1713\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 379ms/step - accuracy: 1.0000 - loss: 3.3141e-08 - val_accuracy: 0.5443 - val_loss: 0.1721\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 373ms/step - accuracy: 0.9809 - loss: 0.0017 - val_accuracy: 0.4541 - val_loss: 0.0662\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 362ms/step - accuracy: 0.9285 - loss: 0.0040 - val_accuracy: 0.5032 - val_loss: 0.0960\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 380ms/step - accuracy: 0.9861 - loss: 7.4586e-04 - val_accuracy: 0.5419 - val_loss: 0.0890\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 377ms/step - accuracy: 0.9981 - loss: 1.7699e-04 - val_accuracy: 0.5403 - val_loss: 0.1211\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 369ms/step - accuracy: 0.9987 - loss: 7.5233e-05 - val_accuracy: 0.5483 - val_loss: 0.1261\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
      "\n",
      "ResNet18 Average Results:\n",
      "Average Sensitivity: 0.7571\n",
      "Average Specificity: 0.9239\n",
      "Average Score: 0.8405\n",
      "Average Accuracy: 0.8067\n",
      "\n",
      "Training ResNet50...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,638,852</span> (93.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,638,852\u001b[0m (93.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,882,948</span> (64.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,882,948\u001b[0m (64.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,755,904</span> (29.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,755,904\u001b[0m (29.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 - Training fold 1/10\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 81, 56, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 75, 50, 1), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m labels_one_hot[train_idx], labels_one_hot[test_idx]\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m histories[model_name]\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m    128\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\lung\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda\\envs\\lung\\lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 81, 56, 1)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None, 75, 50, 1), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Focal loss definition\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1.0 - y_pred, gamma) * y_true\n",
    "        return tf.reduce_mean(alpha * weight * cross_entropy)\n",
    "    return focal_loss_fn\n",
    "\n",
    "# ResNet block\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1):\n",
    "    y = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = tf.keras.activations.relu(y)\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    if stride > 1 or x.shape[-1] != filters:\n",
    "        x = Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
    "    return tf.keras.activations.relu(Add()([x, y]))\n",
    "\n",
    "# ResNet18 model\n",
    "def build_resnet18(input_shape=(75, 50, 1), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 128, stride=2)\n",
    "    x = resnet_block(x, 128)\n",
    "    x = resnet_block(x, 256, stride=2)\n",
    "    x = resnet_block(x, 256)\n",
    "    x = resnet_block(x, 512, stride=2)\n",
    "    x = resnet_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ResNet50 model\n",
    "def build_resnet50(input_shape=(75, 50, 3), num_classes=4):\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Fine-tune the last 40 layers\n",
    "    for layer in base_model.layers[:-40]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-40:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Load spectrograms and labels\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "patient_ids = np.load(os.path.join(spectrograms_dir, \"patient_ids.npy\"))\n",
    "\n",
    "# Convert 1-channel spectrograms to 3 channels for ResNet50 compatibility\n",
    "spectrograms_resized_3ch = np.repeat(spectrograms_resized, 3, axis=-1)\n",
    "\n",
    "# Prepare data\n",
    "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=4)\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "folds = list(gkf.split(spectrograms_resized, labels, groups=patient_ids))\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true_classes = np.argmax(y_true, axis=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    sensitivity = np.mean(TP / (TP + FN + 1e-10))\n",
    "    specificity = np.mean(TN / (TN + FP + 1e-10))\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    return sensitivity, specificity, score, accuracy\n",
    "\n",
    "# Train and evaluate both models\n",
    "models = {'ResNet18': build_resnet18(), 'ResNet50': build_resnet50(input_shape=(75, 50, 3))}\n",
    "histories = {'ResNet18': [], 'ResNet50': []}\n",
    "metrics = {'ResNet18': {'sensitivity': [], 'specificity': [], 'score': [], 'accuracy': []},\n",
    "           'ResNet50': {'sensitivity': [], 'specificity': [], 'score': [], 'accuracy': []}}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(gamma=2.0), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train, X_test = (spectrograms_resized[train_idx], spectrograms_resized_3ch[train_idx]) if model_name == 'ResNet50' else (spectrograms_resized[train_idx], spectrograms_resized[test_idx])\n",
    "        y_train, y_test = labels_one_hot[train_idx], labels_one_hot[test_idx]\n",
    "        \n",
    "        print(f\"{model_name} - Training fold {fold_idx + 1}/10\")\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "        histories[model_name].append(history.history)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        sensitivity, specificity, score, accuracy = compute_metrics(y_test, y_pred)\n",
    "        \n",
    "        metrics[model_name]['sensitivity'].append(sensitivity)\n",
    "        metrics[model_name]['specificity'].append(specificity)\n",
    "        metrics[model_name]['score'].append(score)\n",
    "        metrics[model_name]['accuracy'].append(accuracy)\n",
    "\n",
    "    print(f\"\\n{model_name} Average Results:\")\n",
    "    print(f\"Average Sensitivity: {np.mean(metrics[model_name]['sensitivity']):.4f}\")\n",
    "    print(f\"Average Specificity: {np.mean(metrics[model_name]['specificity']):.4f}\")\n",
    "    print(f\"Average Score: {np.mean(metrics[model_name]['score']):.4f}\")\n",
    "    print(f\"Average Accuracy: {np.mean(metrics[model_name]['accuracy']):.4f}\")\n",
    "\n",
    "# Plotting functions\n",
    "def plot_metrics(histories, model_name, metric_type):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Find the minimum number of epochs across all folds\n",
    "    min_epochs = min(len(h[metric_type]) for h in histories)\n",
    "    avg_train = np.mean([h[metric_type][:min_epochs] for h in histories], axis=0)\n",
    "    avg_val = np.mean([h[f'val_{metric_type}'][:min_epochs] for h in histories], axis=0)\n",
    "    \n",
    "    plt.plot(avg_train, label=f'Average Training {metric_type.capitalize()}')\n",
    "    plt.plot(avg_val, label=f'Average Validation {metric_type.capitalize()}')\n",
    "    plt.title(f'{model_name} - Average {metric_type.capitalize()} Across Folds')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_type.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot for both models\n",
    "for model_name in ['ResNet18', 'ResNet50']:\n",
    "    plot_metrics(histories[model_name], model_name, 'accuracy')\n",
    "    plot_metrics(histories[model_name], model_name, 'loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity: Your ResNet18 (75.71%) far exceeds the proposed model (52.78%), indicating superior detection of positive cases (e.g., adventitious sounds).\n",
    "# Specificity: Your ResNet18 (92.39%) outperforms the proposed model (84.26%), showing better identification of negative cases (e.g., normal sounds).\n",
    "# Score: Your ResNet18 (84.05%) is significantly higher than the proposed model's (68.52%), reflecting a better overall balance.\n",
    "# Accuracy: Your ResNet18 (80.67%) slightly edges out the proposed model (76.39%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet50...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,638,852</span> (93.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,638,852\u001b[0m (93.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,882,948</span> (64.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,882,948\u001b[0m (64.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,755,904</span> (29.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,755,904\u001b[0m (29.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 - Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 567ms/step - accuracy: 0.4532 - loss: 0.0628 - val_accuracy: 0.5225 - val_loss: 0.0380\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 582ms/step - accuracy: 0.6454 - loss: 0.0268 - val_accuracy: 0.5958 - val_loss: 0.0408\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 591ms/step - accuracy: 0.7083 - loss: 0.0197 - val_accuracy: 0.5717 - val_loss: 0.0411\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 538ms/step - accuracy: 0.7818 - loss: 0.0139 - val_accuracy: 0.5660 - val_loss: 0.0494\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 557ms/step - accuracy: 0.8355 - loss: 0.0106 - val_accuracy: 0.5177 - val_loss: 0.0503\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 574ms/step - accuracy: 0.8687 - loss: 0.0083 - val_accuracy: 0.5121 - val_loss: 0.0602\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.8769 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.0605\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 547ms/step - accuracy: 0.9109 - loss: 0.0052 - val_accuracy: 0.5258 - val_loss: 0.0692\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9184 - loss: 0.0051 - val_accuracy: 0.5556 - val_loss: 0.0664\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 0.9297 - loss: 0.0041 - val_accuracy: 0.5378 - val_loss: 0.0671\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 542ms/step - accuracy: 0.9167 - loss: 0.0052 - val_accuracy: 0.5032 - val_loss: 0.0680\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9383 - loss: 0.0035 - val_accuracy: 0.5322 - val_loss: 0.0717\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 529ms/step - accuracy: 0.9408 - loss: 0.0041 - val_accuracy: 0.5386 - val_loss: 0.0717\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 531ms/step - accuracy: 0.9470 - loss: 0.0031 - val_accuracy: 0.5395 - val_loss: 0.0661\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 544ms/step - accuracy: 0.9588 - loss: 0.0021 - val_accuracy: 0.5209 - val_loss: 0.0723\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9681 - loss: 0.0021 - val_accuracy: 0.5523 - val_loss: 0.0759\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 529ms/step - accuracy: 0.9359 - loss: 0.0044 - val_accuracy: 0.5330 - val_loss: 0.0919\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9511 - loss: 0.0028 - val_accuracy: 0.5306 - val_loss: 0.0780\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 537ms/step - accuracy: 0.9340 - loss: 0.0039 - val_accuracy: 0.5177 - val_loss: 0.0769\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 539ms/step - accuracy: 0.9725 - loss: 0.0019 - val_accuracy: 0.5040 - val_loss: 0.0938\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9797 - loss: 0.0014 - val_accuracy: 0.5177 - val_loss: 0.0887\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 586ms/step - accuracy: 0.9751 - loss: 0.0015 - val_accuracy: 0.5346 - val_loss: 0.0939\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 595ms/step - accuracy: 0.9792 - loss: 0.0012 - val_accuracy: 0.5322 - val_loss: 0.0992\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 595ms/step - accuracy: 0.9796 - loss: 0.0014 - val_accuracy: 0.5153 - val_loss: 0.1070\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 579ms/step - accuracy: 0.9726 - loss: 0.0018 - val_accuracy: 0.5741 - val_loss: 0.0879\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 587ms/step - accuracy: 0.9561 - loss: 0.0029 - val_accuracy: 0.5499 - val_loss: 0.0932\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 604ms/step - accuracy: 0.9703 - loss: 0.0019 - val_accuracy: 0.5443 - val_loss: 0.0902\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 566ms/step - accuracy: 0.9812 - loss: 0.0012 - val_accuracy: 0.5201 - val_loss: 0.0911\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 596ms/step - accuracy: 0.9827 - loss: 0.0011 - val_accuracy: 0.5435 - val_loss: 0.0877\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 596ms/step - accuracy: 0.9802 - loss: 0.0013 - val_accuracy: 0.5539 - val_loss: 0.0924\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 572ms/step - accuracy: 0.9879 - loss: 9.3396e-04 - val_accuracy: 0.5121 - val_loss: 0.0964\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 600ms/step - accuracy: 0.9792 - loss: 0.0015 - val_accuracy: 0.5282 - val_loss: 0.0999\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 608ms/step - accuracy: 0.9840 - loss: 0.0011 - val_accuracy: 0.5483 - val_loss: 0.0955\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 598ms/step - accuracy: 0.9835 - loss: 0.0012 - val_accuracy: 0.5411 - val_loss: 0.1056\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 626ms/step - accuracy: 0.9761 - loss: 0.0016 - val_accuracy: 0.5475 - val_loss: 0.1024\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 572ms/step - accuracy: 0.9371 - loss: 0.0045 - val_accuracy: 0.5225 - val_loss: 0.0932\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 603ms/step - accuracy: 0.9712 - loss: 0.0017 - val_accuracy: 0.5427 - val_loss: 0.0987\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 593ms/step - accuracy: 0.9832 - loss: 0.0012 - val_accuracy: 0.5435 - val_loss: 0.1038\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 584ms/step - accuracy: 0.9856 - loss: 0.0012 - val_accuracy: 0.5539 - val_loss: 0.0976\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 591ms/step - accuracy: 0.9920 - loss: 4.4576e-04 - val_accuracy: 0.5459 - val_loss: 0.0997\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 575ms/step - accuracy: 0.9871 - loss: 0.0012 - val_accuracy: 0.5040 - val_loss: 0.1071\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9910 - loss: 6.6314e-04 - val_accuracy: 0.5411 - val_loss: 0.1089\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 539ms/step - accuracy: 0.9870 - loss: 9.1289e-04 - val_accuracy: 0.5539 - val_loss: 0.0993\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 548ms/step - accuracy: 0.9834 - loss: 0.0014 - val_accuracy: 0.5274 - val_loss: 0.0908\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.9761 - loss: 0.0018 - val_accuracy: 0.5338 - val_loss: 0.0992\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.9791 - loss: 0.0014 - val_accuracy: 0.4976 - val_loss: 0.0921\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 547ms/step - accuracy: 0.9839 - loss: 9.9187e-04 - val_accuracy: 0.5668 - val_loss: 0.0997\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 529ms/step - accuracy: 0.9814 - loss: 0.0014 - val_accuracy: 0.5403 - val_loss: 0.1110\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9753 - loss: 0.0017 - val_accuracy: 0.5386 - val_loss: 0.0951\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9726 - loss: 0.0021 - val_accuracy: 0.5201 - val_loss: 0.0982\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 293ms/step\n",
      "ResNet50 - Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 528ms/step - accuracy: 0.8904 - loss: 0.0115 - val_accuracy: 0.5556 - val_loss: 0.0557\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 573ms/step - accuracy: 0.9627 - loss: 0.0023 - val_accuracy: 0.5676 - val_loss: 0.0705\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 589ms/step - accuracy: 0.9817 - loss: 0.0013 - val_accuracy: 0.5515 - val_loss: 0.0839\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 535ms/step - accuracy: 0.9812 - loss: 0.0013 - val_accuracy: 0.5725 - val_loss: 0.0854\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 563ms/step - accuracy: 0.9920 - loss: 4.7921e-04 - val_accuracy: 0.5725 - val_loss: 0.0868\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9975 - loss: 2.2164e-04 - val_accuracy: 0.5564 - val_loss: 0.0924\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 502ms/step - accuracy: 0.9847 - loss: 0.0012 - val_accuracy: 0.5628 - val_loss: 0.0903\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 510ms/step - accuracy: 0.9875 - loss: 7.6718e-04 - val_accuracy: 0.5306 - val_loss: 0.0922\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9782 - loss: 0.0022 - val_accuracy: 0.5572 - val_loss: 0.0827\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 488ms/step - accuracy: 0.9733 - loss: 0.0017 - val_accuracy: 0.5499 - val_loss: 0.0857\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9742 - loss: 0.0024 - val_accuracy: 0.5781 - val_loss: 0.0875\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 501ms/step - accuracy: 0.9873 - loss: 0.0011 - val_accuracy: 0.5604 - val_loss: 0.0848\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 480ms/step - accuracy: 0.9893 - loss: 9.9134e-04 - val_accuracy: 0.5813 - val_loss: 0.0933\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 503ms/step - accuracy: 0.9880 - loss: 8.1011e-04 - val_accuracy: 0.5862 - val_loss: 0.1006\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 506ms/step - accuracy: 0.9958 - loss: 3.0672e-04 - val_accuracy: 0.5942 - val_loss: 0.0953\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 489ms/step - accuracy: 0.9819 - loss: 0.0013 - val_accuracy: 0.5942 - val_loss: 0.1124\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 496ms/step - accuracy: 0.9864 - loss: 9.9728e-04 - val_accuracy: 0.5773 - val_loss: 0.0821\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9883 - loss: 6.3982e-04 - val_accuracy: 0.5523 - val_loss: 0.0954\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 491ms/step - accuracy: 0.9915 - loss: 6.3502e-04 - val_accuracy: 0.5475 - val_loss: 0.1034\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 497ms/step - accuracy: 0.9829 - loss: 0.0016 - val_accuracy: 0.5169 - val_loss: 0.0949\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 502ms/step - accuracy: 0.9830 - loss: 9.5050e-04 - val_accuracy: 0.5209 - val_loss: 0.0839\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 487ms/step - accuracy: 0.9899 - loss: 5.5596e-04 - val_accuracy: 0.5628 - val_loss: 0.0996\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 496ms/step - accuracy: 0.9775 - loss: 0.0018 - val_accuracy: 0.5338 - val_loss: 0.0829\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 507ms/step - accuracy: 0.9734 - loss: 0.0019 - val_accuracy: 0.5499 - val_loss: 0.0867\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 493ms/step - accuracy: 0.9905 - loss: 7.7484e-04 - val_accuracy: 0.5612 - val_loss: 0.0900\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 507ms/step - accuracy: 0.9960 - loss: 2.3667e-04 - val_accuracy: 0.5523 - val_loss: 0.0878\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9967 - loss: 1.1087e-04 - val_accuracy: 0.5531 - val_loss: 0.1041\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 483ms/step - accuracy: 0.9970 - loss: 2.2888e-04 - val_accuracy: 0.5491 - val_loss: 0.0982\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 498ms/step - accuracy: 0.9996 - loss: 7.6213e-05 - val_accuracy: 0.5491 - val_loss: 0.1013\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 499ms/step - accuracy: 0.9902 - loss: 7.9642e-04 - val_accuracy: 0.5169 - val_loss: 0.1019\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 481ms/step - accuracy: 0.9930 - loss: 7.8955e-04 - val_accuracy: 0.5499 - val_loss: 0.0931\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 496ms/step - accuracy: 0.9882 - loss: 9.0991e-04 - val_accuracy: 0.5660 - val_loss: 0.0803\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9922 - loss: 5.3264e-04 - val_accuracy: 0.5604 - val_loss: 0.0906\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 531ms/step - accuracy: 0.9978 - loss: 1.6004e-04 - val_accuracy: 0.5572 - val_loss: 0.0982\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 506ms/step - accuracy: 0.9991 - loss: 8.2070e-05 - val_accuracy: 0.5676 - val_loss: 0.1007\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 3.0838e-05 - val_accuracy: 0.5684 - val_loss: 0.1069\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 492ms/step - accuracy: 0.9771 - loss: 0.0022 - val_accuracy: 0.5459 - val_loss: 0.1126\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 0.9907 - loss: 4.6339e-04 - val_accuracy: 0.5330 - val_loss: 0.0990\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 509ms/step - accuracy: 0.9939 - loss: 4.9824e-04 - val_accuracy: 0.5306 - val_loss: 0.1113\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 506ms/step - accuracy: 0.9903 - loss: 9.5411e-04 - val_accuracy: 0.5250 - val_loss: 0.0946\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9927 - loss: 6.0453e-04 - val_accuracy: 0.5403 - val_loss: 0.0946\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 521ms/step - accuracy: 0.9975 - loss: 1.3464e-04 - val_accuracy: 0.5338 - val_loss: 0.1011\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 517ms/step - accuracy: 0.9983 - loss: 2.2993e-04 - val_accuracy: 0.5548 - val_loss: 0.0995\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 520ms/step - accuracy: 0.9941 - loss: 4.1821e-04 - val_accuracy: 0.5451 - val_loss: 0.1334\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 528ms/step - accuracy: 0.9736 - loss: 0.0027 - val_accuracy: 0.5491 - val_loss: 0.0857\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 502ms/step - accuracy: 0.9878 - loss: 9.0137e-04 - val_accuracy: 0.5636 - val_loss: 0.0844\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 512ms/step - accuracy: 0.9905 - loss: 5.4901e-04 - val_accuracy: 0.5620 - val_loss: 0.0942\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 497ms/step - accuracy: 0.9906 - loss: 7.7251e-04 - val_accuracy: 0.5491 - val_loss: 0.0911\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 512ms/step - accuracy: 0.9919 - loss: 5.5135e-04 - val_accuracy: 0.5749 - val_loss: 0.0947\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 518ms/step - accuracy: 0.9971 - loss: 1.2624e-04 - val_accuracy: 0.5757 - val_loss: 0.0972\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step\n",
      "ResNet50 - Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 496ms/step - accuracy: 0.9739 - loss: 0.0027 - val_accuracy: 0.5427 - val_loss: 0.0736\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 534ms/step - accuracy: 0.9777 - loss: 0.0014 - val_accuracy: 0.5306 - val_loss: 0.0827\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9969 - loss: 2.0495e-04 - val_accuracy: 0.5370 - val_loss: 0.0889\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 494ms/step - accuracy: 0.9902 - loss: 9.7001e-04 - val_accuracy: 0.5419 - val_loss: 0.1009\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9910 - loss: 4.5537e-04 - val_accuracy: 0.5443 - val_loss: 0.0958\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9967 - loss: 3.6315e-04 - val_accuracy: 0.5652 - val_loss: 0.0997\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 503ms/step - accuracy: 0.9871 - loss: 0.0012 - val_accuracy: 0.5531 - val_loss: 0.1060\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 513ms/step - accuracy: 0.9927 - loss: 5.9581e-04 - val_accuracy: 0.5443 - val_loss: 0.0965\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 495ms/step - accuracy: 0.9917 - loss: 9.4411e-04 - val_accuracy: 0.5290 - val_loss: 0.1039\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9959 - loss: 3.9122e-04 - val_accuracy: 0.5483 - val_loss: 0.1110\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 550ms/step - accuracy: 0.9964 - loss: 2.1437e-04 - val_accuracy: 0.5459 - val_loss: 0.1069\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9985 - loss: 1.6839e-04 - val_accuracy: 0.5419 - val_loss: 0.1176\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 563ms/step - accuracy: 0.9994 - loss: 5.4379e-05 - val_accuracy: 0.5419 - val_loss: 0.1168\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 561ms/step - accuracy: 0.9990 - loss: 4.2904e-05 - val_accuracy: 0.5378 - val_loss: 0.1177\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 552ms/step - accuracy: 0.9997 - loss: 2.3949e-05 - val_accuracy: 0.5459 - val_loss: 0.1216\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 567ms/step - accuracy: 0.9981 - loss: 8.3374e-05 - val_accuracy: 0.5403 - val_loss: 0.1219\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 551ms/step - accuracy: 0.9939 - loss: 5.4670e-04 - val_accuracy: 0.5531 - val_loss: 0.1232\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 565ms/step - accuracy: 0.9877 - loss: 8.8491e-04 - val_accuracy: 0.5531 - val_loss: 0.1375\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 552ms/step - accuracy: 0.9794 - loss: 0.0020 - val_accuracy: 0.5451 - val_loss: 0.1003\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 560ms/step - accuracy: 0.9905 - loss: 0.0012 - val_accuracy: 0.5580 - val_loss: 0.0942\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 566ms/step - accuracy: 0.9789 - loss: 0.0015 - val_accuracy: 0.5411 - val_loss: 0.1007\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 517ms/step - accuracy: 0.9922 - loss: 5.7243e-04 - val_accuracy: 0.5467 - val_loss: 0.0925\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 523ms/step - accuracy: 0.9954 - loss: 4.4478e-04 - val_accuracy: 0.5483 - val_loss: 0.1068\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 520ms/step - accuracy: 0.9907 - loss: 5.9616e-04 - val_accuracy: 0.5636 - val_loss: 0.1093\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 518ms/step - accuracy: 0.9978 - loss: 1.4368e-04 - val_accuracy: 0.5829 - val_loss: 0.0980\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 0.9840 - loss: 0.0013 - val_accuracy: 0.5709 - val_loss: 0.0950\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9920 - loss: 5.6915e-04 - val_accuracy: 0.5660 - val_loss: 0.0969\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 0.9766 - loss: 0.0013 - val_accuracy: 0.5805 - val_loss: 0.0964\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9958 - loss: 2.9251e-04 - val_accuracy: 0.5749 - val_loss: 0.1045\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 497ms/step - accuracy: 0.9982 - loss: 1.2323e-04 - val_accuracy: 0.5556 - val_loss: 0.0995\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 516ms/step - accuracy: 0.9817 - loss: 0.0011 - val_accuracy: 0.5886 - val_loss: 0.0953\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9981 - loss: 1.6058e-04 - val_accuracy: 0.5684 - val_loss: 0.1007\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 511ms/step - accuracy: 0.9989 - loss: 5.5352e-05 - val_accuracy: 0.5628 - val_loss: 0.1099\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 519ms/step - accuracy: 0.9754 - loss: 0.0033 - val_accuracy: 0.5741 - val_loss: 0.0865\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 505ms/step - accuracy: 0.9974 - loss: 1.9326e-04 - val_accuracy: 0.5427 - val_loss: 0.0895\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 504ms/step - accuracy: 0.9975 - loss: 1.7285e-04 - val_accuracy: 0.5539 - val_loss: 0.0988\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 2.6400e-05 - val_accuracy: 0.5684 - val_loss: 0.1066\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 493ms/step - accuracy: 0.9887 - loss: 7.0967e-04 - val_accuracy: 0.5435 - val_loss: 0.1021\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 513ms/step - accuracy: 0.9877 - loss: 0.0011 - val_accuracy: 0.5684 - val_loss: 0.1049\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 505ms/step - accuracy: 0.9833 - loss: 0.0023 - val_accuracy: 0.5676 - val_loss: 0.1092\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 563ms/step - accuracy: 0.9953 - loss: 8.0241e-04 - val_accuracy: 0.5636 - val_loss: 0.1025\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 569ms/step - accuracy: 0.9959 - loss: 2.9424e-04 - val_accuracy: 0.5564 - val_loss: 0.1007\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9978 - loss: 1.5656e-04 - val_accuracy: 0.5491 - val_loss: 0.1083\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.9970 - loss: 1.7010e-04 - val_accuracy: 0.5700 - val_loss: 0.1193\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 517ms/step - accuracy: 0.9983 - loss: 8.8093e-05 - val_accuracy: 0.5644 - val_loss: 0.1146\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 510ms/step - accuracy: 0.9997 - loss: 3.2893e-05 - val_accuracy: 0.5717 - val_loss: 0.1133\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 0.9991 - loss: 1.4606e-04 - val_accuracy: 0.5580 - val_loss: 0.1142\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 1.0000 - loss: 6.7723e-06 - val_accuracy: 0.5636 - val_loss: 0.1151\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9969 - loss: 2.3761e-04 - val_accuracy: 0.5612 - val_loss: 0.1246\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9964 - loss: 2.1683e-04 - val_accuracy: 0.5636 - val_loss: 0.1272\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step\n",
      "ResNet50 - Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 513ms/step - accuracy: 0.9761 - loss: 0.0028 - val_accuracy: 0.5990 - val_loss: 0.0927\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 518ms/step - accuracy: 0.9897 - loss: 0.0012 - val_accuracy: 0.6248 - val_loss: 0.0824\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 529ms/step - accuracy: 0.9867 - loss: 8.0707e-04 - val_accuracy: 0.6006 - val_loss: 0.0940\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 500ms/step - accuracy: 0.9944 - loss: 5.4092e-04 - val_accuracy: 0.6490 - val_loss: 0.1032\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 0.9917 - loss: 8.3567e-04 - val_accuracy: 0.6192 - val_loss: 0.0907\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 571ms/step - accuracy: 0.9997 - loss: 8.1221e-05 - val_accuracy: 0.6320 - val_loss: 0.0950\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 590ms/step - accuracy: 1.0000 - loss: 1.5566e-05 - val_accuracy: 0.6320 - val_loss: 0.0971\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 567ms/step - accuracy: 0.9999 - loss: 2.7767e-05 - val_accuracy: 0.6361 - val_loss: 0.0989\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 574ms/step - accuracy: 0.9992 - loss: 4.4901e-05 - val_accuracy: 0.6256 - val_loss: 0.1017\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 579ms/step - accuracy: 1.0000 - loss: 1.2664e-05 - val_accuracy: 0.6208 - val_loss: 0.1036\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 570ms/step - accuracy: 0.9998 - loss: 4.5173e-05 - val_accuracy: 0.6393 - val_loss: 0.1181\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 537ms/step - accuracy: 0.9971 - loss: 2.8470e-04 - val_accuracy: 0.6433 - val_loss: 0.1331\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 564ms/step - accuracy: 0.9926 - loss: 3.1213e-04 - val_accuracy: 0.6184 - val_loss: 0.1011\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 559ms/step - accuracy: 0.9974 - loss: 1.7963e-04 - val_accuracy: 0.6167 - val_loss: 0.1408\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 561ms/step - accuracy: 0.9978 - loss: 2.8115e-04 - val_accuracy: 0.6240 - val_loss: 0.1068\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9958 - loss: 2.6024e-04 - val_accuracy: 0.6481 - val_loss: 0.0950\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 571ms/step - accuracy: 0.9923 - loss: 3.5022e-04 - val_accuracy: 0.6176 - val_loss: 0.0944\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 620ms/step - accuracy: 0.9945 - loss: 4.8739e-04 - val_accuracy: 0.6248 - val_loss: 0.0983\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 586ms/step - accuracy: 0.9950 - loss: 3.3000e-04 - val_accuracy: 0.6329 - val_loss: 0.0974\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 563ms/step - accuracy: 0.9963 - loss: 2.3208e-04 - val_accuracy: 0.6143 - val_loss: 0.0993\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 551ms/step - accuracy: 0.9989 - loss: 8.7499e-05 - val_accuracy: 0.6232 - val_loss: 0.1055\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 512ms/step - accuracy: 0.9991 - loss: 3.6705e-05 - val_accuracy: 0.6256 - val_loss: 0.1021\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 584ms/step - accuracy: 0.9992 - loss: 2.4274e-05 - val_accuracy: 0.6256 - val_loss: 0.1067\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 1.0000 - loss: 7.0279e-06 - val_accuracy: 0.6256 - val_loss: 0.1065\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 568ms/step - accuracy: 0.9996 - loss: 1.1576e-05 - val_accuracy: 0.6280 - val_loss: 0.1077\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 577ms/step - accuracy: 1.0000 - loss: 4.8867e-06 - val_accuracy: 0.6176 - val_loss: 0.1094\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9894 - loss: 8.6437e-04 - val_accuracy: 0.5942 - val_loss: 0.1097\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 583ms/step - accuracy: 0.9922 - loss: 5.2842e-04 - val_accuracy: 0.5813 - val_loss: 0.1001\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 575ms/step - accuracy: 0.9607 - loss: 0.0042 - val_accuracy: 0.5958 - val_loss: 0.0810\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 510ms/step - accuracy: 0.9761 - loss: 0.0031 - val_accuracy: 0.6240 - val_loss: 0.0787\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 554ms/step - accuracy: 0.9822 - loss: 0.0031 - val_accuracy: 0.6208 - val_loss: 0.0856\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 572ms/step - accuracy: 0.9993 - loss: 1.5777e-04 - val_accuracy: 0.6192 - val_loss: 0.0893\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 538ms/step - accuracy: 0.9994 - loss: 5.9482e-05 - val_accuracy: 0.6200 - val_loss: 0.0944\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 2.3472e-05 - val_accuracy: 0.6296 - val_loss: 0.0963\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 594ms/step - accuracy: 0.9997 - loss: 2.1262e-05 - val_accuracy: 0.6224 - val_loss: 0.0987\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 583ms/step - accuracy: 0.9996 - loss: 2.2809e-05 - val_accuracy: 0.6304 - val_loss: 0.0953\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 555ms/step - accuracy: 0.9997 - loss: 1.8608e-05 - val_accuracy: 0.6240 - val_loss: 0.0958\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 531ms/step - accuracy: 0.9993 - loss: 6.3766e-05 - val_accuracy: 0.6151 - val_loss: 0.0989\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 557ms/step - accuracy: 0.9954 - loss: 3.4150e-04 - val_accuracy: 0.6409 - val_loss: 0.0967\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 540ms/step - accuracy: 0.9885 - loss: 7.0619e-04 - val_accuracy: 0.6192 - val_loss: 0.1119\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9970 - loss: 3.1329e-04 - val_accuracy: 0.6031 - val_loss: 0.1078\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.9977 - loss: 1.4208e-04 - val_accuracy: 0.6159 - val_loss: 0.0992\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 563ms/step - accuracy: 1.0000 - loss: 2.7340e-05 - val_accuracy: 0.6280 - val_loss: 0.0966\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 530ms/step - accuracy: 0.9986 - loss: 4.9734e-05 - val_accuracy: 0.6369 - val_loss: 0.1009\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 1.0000 - loss: 9.1459e-06 - val_accuracy: 0.6353 - val_loss: 0.1059\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 520ms/step - accuracy: 1.0000 - loss: 4.2162e-06 - val_accuracy: 0.6385 - val_loss: 0.1061\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 506ms/step - accuracy: 0.9999 - loss: 8.7086e-06 - val_accuracy: 0.6288 - val_loss: 0.1068\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 526ms/step - accuracy: 0.9998 - loss: 8.9234e-06 - val_accuracy: 0.6337 - val_loss: 0.1088\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 1.0728e-05 - val_accuracy: 0.6369 - val_loss: 0.1107\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 509ms/step - accuracy: 0.9997 - loss: 2.6333e-05 - val_accuracy: 0.6151 - val_loss: 0.1002\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step\n",
      "ResNet50 - Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 531ms/step - accuracy: 0.9719 - loss: 0.0028 - val_accuracy: 0.5910 - val_loss: 0.1038\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 510ms/step - accuracy: 0.9844 - loss: 0.0014 - val_accuracy: 0.5950 - val_loss: 0.0858\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 516ms/step - accuracy: 0.9966 - loss: 2.2791e-04 - val_accuracy: 0.5974 - val_loss: 0.0929\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 521ms/step - accuracy: 0.9997 - loss: 5.1756e-05 - val_accuracy: 0.5805 - val_loss: 0.0965\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 510ms/step - accuracy: 0.9997 - loss: 2.4345e-05 - val_accuracy: 0.5974 - val_loss: 0.0984\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 522ms/step - accuracy: 0.9983 - loss: 8.7946e-05 - val_accuracy: 0.5845 - val_loss: 0.1030\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 509ms/step - accuracy: 0.9971 - loss: 1.9665e-04 - val_accuracy: 0.5644 - val_loss: 0.1130\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9884 - loss: 6.8383e-04 - val_accuracy: 0.5765 - val_loss: 0.1006\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 529ms/step - accuracy: 0.9995 - loss: 4.7330e-05 - val_accuracy: 0.5934 - val_loss: 0.1065\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 502ms/step - accuracy: 0.9984 - loss: 1.4768e-04 - val_accuracy: 0.6014 - val_loss: 0.1240\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 521ms/step - accuracy: 0.9940 - loss: 5.6025e-04 - val_accuracy: 0.5886 - val_loss: 0.1128\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9956 - loss: 3.4454e-04 - val_accuracy: 0.5773 - val_loss: 0.1160\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 504ms/step - accuracy: 0.9931 - loss: 7.1161e-04 - val_accuracy: 0.5829 - val_loss: 0.1128\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9979 - loss: 9.5614e-05 - val_accuracy: 0.5894 - val_loss: 0.1185\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 505ms/step - accuracy: 0.9988 - loss: 7.8337e-05 - val_accuracy: 0.5829 - val_loss: 0.1130\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 512ms/step - accuracy: 0.9992 - loss: 8.9644e-05 - val_accuracy: 0.5709 - val_loss: 0.1158\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 552ms/step - accuracy: 0.9989 - loss: 1.1605e-04 - val_accuracy: 0.5918 - val_loss: 0.1210\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 550ms/step - accuracy: 0.9838 - loss: 0.0022 - val_accuracy: 0.6111 - val_loss: 0.1174\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 583ms/step - accuracy: 0.9859 - loss: 0.0014 - val_accuracy: 0.5942 - val_loss: 0.1003\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 553ms/step - accuracy: 0.9980 - loss: 1.8508e-04 - val_accuracy: 0.5942 - val_loss: 0.1073\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 570ms/step - accuracy: 0.9966 - loss: 3.3441e-04 - val_accuracy: 0.6014 - val_loss: 0.1097\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 556ms/step - accuracy: 0.9940 - loss: 4.3520e-04 - val_accuracy: 0.5886 - val_loss: 0.1083\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 561ms/step - accuracy: 0.9957 - loss: 3.1697e-04 - val_accuracy: 0.6023 - val_loss: 0.0996\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 567ms/step - accuracy: 0.9989 - loss: 5.8023e-05 - val_accuracy: 0.6031 - val_loss: 0.1000\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 557ms/step - accuracy: 0.9977 - loss: 2.2014e-04 - val_accuracy: 0.5709 - val_loss: 0.1075\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 572ms/step - accuracy: 0.9942 - loss: 6.5307e-04 - val_accuracy: 0.6006 - val_loss: 0.1120\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 550ms/step - accuracy: 0.9994 - loss: 6.3505e-05 - val_accuracy: 0.5684 - val_loss: 0.1102\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 573ms/step - accuracy: 0.9981 - loss: 2.9405e-04 - val_accuracy: 0.5926 - val_loss: 0.1008\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 555ms/step - accuracy: 0.9955 - loss: 2.4363e-04 - val_accuracy: 0.5773 - val_loss: 0.1111\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 571ms/step - accuracy: 0.9987 - loss: 1.0467e-04 - val_accuracy: 0.5572 - val_loss: 0.1146\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 555ms/step - accuracy: 0.9995 - loss: 6.4632e-05 - val_accuracy: 0.5781 - val_loss: 0.1113\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 564ms/step - accuracy: 0.9973 - loss: 2.0581e-04 - val_accuracy: 0.5668 - val_loss: 0.1086\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 566ms/step - accuracy: 0.9974 - loss: 2.1538e-04 - val_accuracy: 0.5902 - val_loss: 0.1138\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 556ms/step - accuracy: 0.9968 - loss: 1.2709e-04 - val_accuracy: 0.5926 - val_loss: 0.1167\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 571ms/step - accuracy: 1.0000 - loss: 1.8354e-05 - val_accuracy: 0.5966 - val_loss: 0.1190\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 561ms/step - accuracy: 0.9995 - loss: 3.1674e-05 - val_accuracy: 0.5676 - val_loss: 0.1191\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 578ms/step - accuracy: 0.9996 - loss: 1.7182e-05 - val_accuracy: 0.5781 - val_loss: 0.1235\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 5.6565e-06 - val_accuracy: 0.5765 - val_loss: 0.1232\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 517ms/step - accuracy: 1.0000 - loss: 1.8313e-06 - val_accuracy: 0.5781 - val_loss: 0.1247\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 516ms/step - accuracy: 1.0000 - loss: 1.5395e-06 - val_accuracy: 0.5797 - val_loss: 0.1253\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 2.1039e-06 - val_accuracy: 0.5805 - val_loss: 0.1257\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 517ms/step - accuracy: 0.9918 - loss: 7.9882e-04 - val_accuracy: 0.5733 - val_loss: 0.1299\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9918 - loss: 7.8989e-04 - val_accuracy: 0.6023 - val_loss: 0.1236\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 495ms/step - accuracy: 0.9954 - loss: 6.5914e-04 - val_accuracy: 0.5765 - val_loss: 0.1161\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 519ms/step - accuracy: 0.9946 - loss: 4.0835e-04 - val_accuracy: 0.5958 - val_loss: 0.1248\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 508ms/step - accuracy: 0.9960 - loss: 2.7344e-04 - val_accuracy: 0.5741 - val_loss: 0.1245\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 500ms/step - accuracy: 0.9962 - loss: 1.6397e-04 - val_accuracy: 0.5902 - val_loss: 0.1170\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.9993 - loss: 5.0414e-05 - val_accuracy: 0.5837 - val_loss: 0.1193\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 1.4042e-05 - val_accuracy: 0.5886 - val_loss: 0.1206\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 5.8926e-06 - val_accuracy: 0.5797 - val_loss: 0.1235\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step\n",
      "ResNet50 - Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 542ms/step - accuracy: 0.9931 - loss: 5.5510e-04 - val_accuracy: 0.6047 - val_loss: 0.1005\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9900 - loss: 7.5739e-04 - val_accuracy: 0.6127 - val_loss: 0.0961\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 521ms/step - accuracy: 0.9976 - loss: 1.4548e-04 - val_accuracy: 0.6248 - val_loss: 0.0944\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 510ms/step - accuracy: 0.9974 - loss: 1.9158e-04 - val_accuracy: 0.6280 - val_loss: 0.0971\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 499ms/step - accuracy: 0.9997 - loss: 2.3237e-05 - val_accuracy: 0.6159 - val_loss: 0.1008\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9997 - loss: 1.9315e-05 - val_accuracy: 0.6200 - val_loss: 0.0997\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 6.5722e-06 - val_accuracy: 0.6119 - val_loss: 0.1019\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 1.1969e-05 - val_accuracy: 0.6208 - val_loss: 0.1022\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 5.9874e-06 - val_accuracy: 0.6127 - val_loss: 0.1027\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 504ms/step - accuracy: 0.9968 - loss: 2.7901e-04 - val_accuracy: 0.6184 - val_loss: 0.1041\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9973 - loss: 5.8022e-04 - val_accuracy: 0.6143 - val_loss: 0.1008\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 519ms/step - accuracy: 0.9962 - loss: 2.5844e-04 - val_accuracy: 0.6337 - val_loss: 0.1092\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 500ms/step - accuracy: 0.9994 - loss: 7.4061e-05 - val_accuracy: 0.5934 - val_loss: 0.1098\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 520ms/step - accuracy: 0.9969 - loss: 3.9633e-04 - val_accuracy: 0.5934 - val_loss: 0.1195\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 519ms/step - accuracy: 0.9991 - loss: 7.5581e-05 - val_accuracy: 0.5942 - val_loss: 0.1143\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 516ms/step - accuracy: 0.9921 - loss: 0.0012 - val_accuracy: 0.6071 - val_loss: 0.1072\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 538ms/step - accuracy: 0.9966 - loss: 2.8834e-04 - val_accuracy: 0.5757 - val_loss: 0.0950\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9917 - loss: 7.7147e-04 - val_accuracy: 0.6200 - val_loss: 0.0907\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 514ms/step - accuracy: 0.9947 - loss: 3.1140e-04 - val_accuracy: 0.6216 - val_loss: 0.0828\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 0.9968 - loss: 2.9182e-04 - val_accuracy: 0.6240 - val_loss: 0.0841\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 509ms/step - accuracy: 0.9986 - loss: 7.5218e-05 - val_accuracy: 0.6256 - val_loss: 0.0842\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 0.9994 - loss: 2.3061e-05 - val_accuracy: 0.6256 - val_loss: 0.0858\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.9996 - loss: 1.4041e-05 - val_accuracy: 0.6119 - val_loss: 0.0876\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 515ms/step - accuracy: 0.9995 - loss: 2.4775e-05 - val_accuracy: 0.6224 - val_loss: 0.0876\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 530ms/step - accuracy: 1.0000 - loss: 4.9311e-06 - val_accuracy: 0.6184 - val_loss: 0.0889\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 606ms/step - accuracy: 1.0000 - loss: 5.7621e-06 - val_accuracy: 0.6208 - val_loss: 0.0899\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 658ms/step - accuracy: 1.0000 - loss: 3.0893e-06 - val_accuracy: 0.6216 - val_loss: 0.0904\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 610ms/step - accuracy: 1.0000 - loss: 3.5931e-06 - val_accuracy: 0.6240 - val_loss: 0.0922\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 3.7838e-06 - val_accuracy: 0.6184 - val_loss: 0.0953\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 599ms/step - accuracy: 0.9984 - loss: 1.4021e-04 - val_accuracy: 0.6272 - val_loss: 0.1047\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 596ms/step - accuracy: 0.9997 - loss: 3.0635e-05 - val_accuracy: 0.6345 - val_loss: 0.1031\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 597ms/step - accuracy: 0.9963 - loss: 7.0707e-04 - val_accuracy: 0.6176 - val_loss: 0.1097\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 600ms/step - accuracy: 0.9972 - loss: 1.4301e-04 - val_accuracy: 0.6176 - val_loss: 0.1232\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 639ms/step - accuracy: 0.9925 - loss: 0.0012 - val_accuracy: 0.6361 - val_loss: 0.1362\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 622ms/step - accuracy: 0.9854 - loss: 0.0020 - val_accuracy: 0.5878 - val_loss: 0.0930\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 632ms/step - accuracy: 0.9960 - loss: 3.2657e-04 - val_accuracy: 0.6127 - val_loss: 0.0963\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 623ms/step - accuracy: 0.9973 - loss: 3.3307e-04 - val_accuracy: 0.6111 - val_loss: 0.0957\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 636ms/step - accuracy: 0.9986 - loss: 6.9024e-05 - val_accuracy: 0.6127 - val_loss: 0.0954\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 631ms/step - accuracy: 0.9989 - loss: 3.8218e-05 - val_accuracy: 0.6393 - val_loss: 0.1022\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 619ms/step - accuracy: 0.9987 - loss: 3.3026e-05 - val_accuracy: 0.6087 - val_loss: 0.1016\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 602ms/step - accuracy: 0.9996 - loss: 8.7034e-05 - val_accuracy: 0.6409 - val_loss: 0.1016\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 709ms/step - accuracy: 0.9986 - loss: 2.4299e-04 - val_accuracy: 0.6288 - val_loss: 0.1100\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 662ms/step - accuracy: 0.9986 - loss: 1.6258e-04 - val_accuracy: 0.5990 - val_loss: 0.1042\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 672ms/step - accuracy: 0.9983 - loss: 1.0897e-04 - val_accuracy: 0.6272 - val_loss: 0.1017\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 579ms/step - accuracy: 0.9985 - loss: 1.4469e-04 - val_accuracy: 0.6345 - val_loss: 0.1001\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 560ms/step - accuracy: 0.9998 - loss: 6.6477e-05 - val_accuracy: 0.6312 - val_loss: 0.1004\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.0317e-05 - val_accuracy: 0.6151 - val_loss: 0.1023\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 646ms/step - accuracy: 1.0000 - loss: 4.6131e-06 - val_accuracy: 0.6135 - val_loss: 0.1031\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 631ms/step - accuracy: 1.0000 - loss: 4.4556e-06 - val_accuracy: 0.6208 - val_loss: 0.1018\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 633ms/step - accuracy: 0.9997 - loss: 4.9806e-05 - val_accuracy: 0.6192 - val_loss: 0.1090\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step\n",
      "ResNet50 - Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 642ms/step - accuracy: 0.9947 - loss: 2.3265e-04 - val_accuracy: 0.6256 - val_loss: 0.1018\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 634ms/step - accuracy: 0.9887 - loss: 9.1941e-04 - val_accuracy: 0.6473 - val_loss: 0.0961\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 618ms/step - accuracy: 0.9966 - loss: 1.4467e-04 - val_accuracy: 0.6167 - val_loss: 0.0907\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 629ms/step - accuracy: 0.9966 - loss: 4.2353e-04 - val_accuracy: 0.6151 - val_loss: 0.0858\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 628ms/step - accuracy: 0.9939 - loss: 4.4236e-04 - val_accuracy: 0.6087 - val_loss: 0.0960\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 630ms/step - accuracy: 0.9998 - loss: 7.4934e-05 - val_accuracy: 0.6296 - val_loss: 0.0922\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 610ms/step - accuracy: 0.9970 - loss: 2.9923e-04 - val_accuracy: 0.6353 - val_loss: 0.0921\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 636ms/step - accuracy: 0.9974 - loss: 2.2885e-04 - val_accuracy: 0.6272 - val_loss: 0.0921\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 636ms/step - accuracy: 0.9992 - loss: 8.6558e-05 - val_accuracy: 0.6087 - val_loss: 0.0916\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 627ms/step - accuracy: 0.9989 - loss: 6.0204e-05 - val_accuracy: 0.6296 - val_loss: 0.0902\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 625ms/step - accuracy: 0.9968 - loss: 2.7937e-04 - val_accuracy: 0.6377 - val_loss: 0.0876\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 638ms/step - accuracy: 0.9999 - loss: 2.7240e-05 - val_accuracy: 0.6449 - val_loss: 0.0899\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 634ms/step - accuracy: 0.9995 - loss: 2.2699e-05 - val_accuracy: 0.6393 - val_loss: 0.0895\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 638ms/step - accuracy: 0.9997 - loss: 1.1777e-05 - val_accuracy: 0.6393 - val_loss: 0.0926\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 689ms/step - accuracy: 1.0000 - loss: 5.0985e-06 - val_accuracy: 0.6417 - val_loss: 0.0941\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 637ms/step - accuracy: 0.9999 - loss: 4.4041e-06 - val_accuracy: 0.6353 - val_loss: 0.0932\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 657ms/step - accuracy: 0.9999 - loss: 4.3796e-06 - val_accuracy: 0.6337 - val_loss: 0.0948\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 622ms/step - accuracy: 0.9995 - loss: 1.9476e-04 - val_accuracy: 0.6385 - val_loss: 0.0923\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 639ms/step - accuracy: 0.9986 - loss: 8.1363e-05 - val_accuracy: 0.6409 - val_loss: 0.0939\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 633ms/step - accuracy: 0.9986 - loss: 9.4539e-05 - val_accuracy: 0.6361 - val_loss: 0.0974\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 620ms/step - accuracy: 0.9985 - loss: 1.1163e-04 - val_accuracy: 0.6337 - val_loss: 0.1017\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 622ms/step - accuracy: 0.9986 - loss: 7.6896e-05 - val_accuracy: 0.6296 - val_loss: 0.0994\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 541ms/step - accuracy: 0.9999 - loss: 8.8626e-06 - val_accuracy: 0.6353 - val_loss: 0.0994\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 554ms/step - accuracy: 1.0000 - loss: 2.3530e-06 - val_accuracy: 0.6337 - val_loss: 0.0996\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 566ms/step - accuracy: 0.9988 - loss: 1.3904e-04 - val_accuracy: 0.6337 - val_loss: 0.1112\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 618ms/step - accuracy: 0.9950 - loss: 1.7912e-04 - val_accuracy: 0.6256 - val_loss: 0.0977\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 629ms/step - accuracy: 0.9981 - loss: 8.2194e-05 - val_accuracy: 0.6320 - val_loss: 0.1065\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9974 - loss: 2.4027e-04 - val_accuracy: 0.6184 - val_loss: 0.1115\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 564ms/step - accuracy: 0.9928 - loss: 6.3031e-04 - val_accuracy: 0.6425 - val_loss: 0.1115\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 548ms/step - accuracy: 0.9926 - loss: 8.7116e-04 - val_accuracy: 0.6393 - val_loss: 0.0975\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 0.9978 - loss: 3.9524e-04 - val_accuracy: 0.6192 - val_loss: 0.0908\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 539ms/step - accuracy: 0.9984 - loss: 7.4750e-05 - val_accuracy: 0.6280 - val_loss: 0.0886\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 519ms/step - accuracy: 0.9983 - loss: 1.3753e-04 - val_accuracy: 0.5990 - val_loss: 0.0852\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 534ms/step - accuracy: 0.9944 - loss: 0.0010 - val_accuracy: 0.6208 - val_loss: 0.0892\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9984 - loss: 7.5904e-05 - val_accuracy: 0.6272 - val_loss: 0.0908\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 529ms/step - accuracy: 0.9995 - loss: 2.6132e-05 - val_accuracy: 0.6280 - val_loss: 0.0945\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 538ms/step - accuracy: 0.9990 - loss: 1.1051e-04 - val_accuracy: 0.6361 - val_loss: 0.0939\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 542ms/step - accuracy: 0.9992 - loss: 3.0213e-05 - val_accuracy: 0.6224 - val_loss: 0.0971\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 521ms/step - accuracy: 0.9998 - loss: 2.1747e-05 - val_accuracy: 0.6200 - val_loss: 0.0964\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9996 - loss: 1.0389e-04 - val_accuracy: 0.6184 - val_loss: 0.0958\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 533ms/step - accuracy: 1.0000 - loss: 4.7188e-06 - val_accuracy: 0.6232 - val_loss: 0.0948\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 523ms/step - accuracy: 0.9993 - loss: 9.6991e-05 - val_accuracy: 0.6457 - val_loss: 0.1142\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9963 - loss: 4.3863e-04 - val_accuracy: 0.6184 - val_loss: 0.1083\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9978 - loss: 1.6847e-04 - val_accuracy: 0.6288 - val_loss: 0.0978\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.9909 - loss: 0.0011 - val_accuracy: 0.6377 - val_loss: 0.0990\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 545ms/step - accuracy: 0.9962 - loss: 4.4729e-04 - val_accuracy: 0.5934 - val_loss: 0.1085\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.9934 - loss: 0.0015 - val_accuracy: 0.6063 - val_loss: 0.1155\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 534ms/step - accuracy: 0.9935 - loss: 9.7582e-04 - val_accuracy: 0.6031 - val_loss: 0.1054\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 543ms/step - accuracy: 0.9947 - loss: 7.4184e-04 - val_accuracy: 0.6200 - val_loss: 0.0953\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 0.9987 - loss: 1.0025e-04 - val_accuracy: 0.6288 - val_loss: 0.0966\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step\n",
      "ResNet50 - Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 553ms/step - accuracy: 0.9915 - loss: 0.0013 - val_accuracy: 0.5515 - val_loss: 0.1335\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 542ms/step - accuracy: 0.9971 - loss: 2.8223e-04 - val_accuracy: 0.5346 - val_loss: 0.1393\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 541ms/step - accuracy: 0.9979 - loss: 6.7867e-05 - val_accuracy: 0.5346 - val_loss: 0.1407\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9999 - loss: 2.0500e-05 - val_accuracy: 0.5395 - val_loss: 0.1438\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 523ms/step - accuracy: 0.9996 - loss: 6.4891e-05 - val_accuracy: 0.5330 - val_loss: 0.1462\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9997 - loss: 2.7011e-05 - val_accuracy: 0.5419 - val_loss: 0.1410\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 0.9998 - loss: 2.5837e-05 - val_accuracy: 0.5443 - val_loss: 0.1482\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 9.7605e-06 - val_accuracy: 0.5499 - val_loss: 0.1466\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 4.3772e-06 - val_accuracy: 0.5459 - val_loss: 0.1486\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 663ms/step - accuracy: 0.9999 - loss: 6.4209e-06 - val_accuracy: 0.5435 - val_loss: 0.1478\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 649ms/step - accuracy: 0.9996 - loss: 9.5823e-05 - val_accuracy: 0.5386 - val_loss: 0.1469\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 653ms/step - accuracy: 0.9948 - loss: 4.5635e-04 - val_accuracy: 0.5499 - val_loss: 0.1442\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 634ms/step - accuracy: 0.9981 - loss: 2.0941e-04 - val_accuracy: 0.5475 - val_loss: 0.1451\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 655ms/step - accuracy: 0.9995 - loss: 3.9949e-05 - val_accuracy: 0.5386 - val_loss: 0.1386\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 649ms/step - accuracy: 0.9996 - loss: 1.2885e-04 - val_accuracy: 0.5596 - val_loss: 0.1434\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 636ms/step - accuracy: 0.9932 - loss: 9.7710e-04 - val_accuracy: 0.5097 - val_loss: 0.1455\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 649ms/step - accuracy: 0.9974 - loss: 2.5607e-04 - val_accuracy: 0.5346 - val_loss: 0.1352\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 648ms/step - accuracy: 0.9984 - loss: 9.1495e-05 - val_accuracy: 0.5475 - val_loss: 0.1306\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 659ms/step - accuracy: 0.9998 - loss: 1.4996e-05 - val_accuracy: 0.5572 - val_loss: 0.1349\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 657ms/step - accuracy: 0.9997 - loss: 2.2585e-05 - val_accuracy: 0.5346 - val_loss: 0.1365\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 669ms/step - accuracy: 1.0000 - loss: 1.6370e-05 - val_accuracy: 0.5362 - val_loss: 0.1397\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 722ms/step - accuracy: 1.0000 - loss: 5.1304e-06 - val_accuracy: 0.5250 - val_loss: 0.1388\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 716ms/step - accuracy: 1.0000 - loss: 3.4804e-06 - val_accuracy: 0.5282 - val_loss: 0.1400\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 701ms/step - accuracy: 1.0000 - loss: 6.3980e-06 - val_accuracy: 0.5266 - val_loss: 0.1425\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 729ms/step - accuracy: 1.0000 - loss: 3.6319e-06 - val_accuracy: 0.5306 - val_loss: 0.1438\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 719ms/step - accuracy: 1.0000 - loss: 2.8265e-06 - val_accuracy: 0.5201 - val_loss: 0.1445\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 731ms/step - accuracy: 0.9976 - loss: 1.6650e-04 - val_accuracy: 0.5411 - val_loss: 0.1440\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 732ms/step - accuracy: 0.9968 - loss: 1.8909e-04 - val_accuracy: 0.5572 - val_loss: 0.1615\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 713ms/step - accuracy: 0.9937 - loss: 7.9128e-04 - val_accuracy: 0.5306 - val_loss: 0.1521\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 745ms/step - accuracy: 0.9941 - loss: 5.4549e-04 - val_accuracy: 0.5467 - val_loss: 0.1376\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 749ms/step - accuracy: 0.9957 - loss: 3.7167e-04 - val_accuracy: 0.5330 - val_loss: 0.1293\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 732ms/step - accuracy: 0.9974 - loss: 1.7332e-04 - val_accuracy: 0.5403 - val_loss: 0.1465\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 730ms/step - accuracy: 0.9998 - loss: 1.5370e-05 - val_accuracy: 0.5386 - val_loss: 0.1506\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 737ms/step - accuracy: 1.0000 - loss: 1.0153e-05 - val_accuracy: 0.5370 - val_loss: 0.1532\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 743ms/step - accuracy: 0.9997 - loss: 1.0535e-05 - val_accuracy: 0.5483 - val_loss: 0.1477\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 739ms/step - accuracy: 0.9990 - loss: 3.7938e-05 - val_accuracy: 0.5451 - val_loss: 0.1491\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 733ms/step - accuracy: 1.0000 - loss: 4.5897e-06 - val_accuracy: 0.5491 - val_loss: 0.1485\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 751ms/step - accuracy: 1.0000 - loss: 2.6786e-06 - val_accuracy: 0.5467 - val_loss: 0.1471\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 718ms/step - accuracy: 0.9997 - loss: 3.7881e-05 - val_accuracy: 0.5491 - val_loss: 0.1521\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 739ms/step - accuracy: 0.9939 - loss: 7.2703e-04 - val_accuracy: 0.5290 - val_loss: 0.1583\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 724ms/step - accuracy: 0.9970 - loss: 1.5603e-04 - val_accuracy: 0.5362 - val_loss: 0.1655\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 707ms/step - accuracy: 0.9973 - loss: 1.2910e-04 - val_accuracy: 0.5588 - val_loss: 0.1778\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 717ms/step - accuracy: 0.9959 - loss: 2.5042e-04 - val_accuracy: 0.5531 - val_loss: 0.1587\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 723ms/step - accuracy: 0.9981 - loss: 1.4639e-04 - val_accuracy: 0.5411 - val_loss: 0.1631\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 727ms/step - accuracy: 0.9992 - loss: 4.6222e-05 - val_accuracy: 0.5362 - val_loss: 0.1554\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 708ms/step - accuracy: 0.9965 - loss: 4.9660e-04 - val_accuracy: 0.5258 - val_loss: 0.1626\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 728ms/step - accuracy: 0.9996 - loss: 4.3432e-05 - val_accuracy: 0.5386 - val_loss: 0.1532\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 702ms/step - accuracy: 0.9991 - loss: 2.9852e-05 - val_accuracy: 0.5386 - val_loss: 0.1504\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 744ms/step - accuracy: 0.9986 - loss: 8.3951e-05 - val_accuracy: 0.5443 - val_loss: 0.1542\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 731ms/step - accuracy: 0.9995 - loss: 3.2924e-05 - val_accuracy: 0.5467 - val_loss: 0.1559\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 299ms/step\n",
      "ResNet50 - Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 744ms/step - accuracy: 0.9973 - loss: 1.1709e-04 - val_accuracy: 0.5672 - val_loss: 0.1480\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 757ms/step - accuracy: 0.9995 - loss: 4.1897e-05 - val_accuracy: 0.5833 - val_loss: 0.1491\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 690ms/step - accuracy: 0.9993 - loss: 2.7770e-04 - val_accuracy: 0.5889 - val_loss: 0.1499\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 753ms/step - accuracy: 0.9984 - loss: 2.7115e-04 - val_accuracy: 0.5825 - val_loss: 0.1397\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 729ms/step - accuracy: 0.9989 - loss: 1.4550e-04 - val_accuracy: 0.5986 - val_loss: 0.1676\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 763ms/step - accuracy: 0.9948 - loss: 0.0010 - val_accuracy: 0.5833 - val_loss: 0.1585\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 723ms/step - accuracy: 0.9932 - loss: 7.4568e-04 - val_accuracy: 0.5792 - val_loss: 0.1430\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 749ms/step - accuracy: 0.9953 - loss: 2.6248e-04 - val_accuracy: 0.5977 - val_loss: 0.1357\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 725ms/step - accuracy: 0.9997 - loss: 2.6161e-05 - val_accuracy: 0.5849 - val_loss: 0.1341\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 735ms/step - accuracy: 0.9998 - loss: 1.0240e-05 - val_accuracy: 0.5857 - val_loss: 0.1333\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 734ms/step - accuracy: 0.9999 - loss: 9.5387e-06 - val_accuracy: 0.5881 - val_loss: 0.1354\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 737ms/step - accuracy: 0.9994 - loss: 1.4018e-05 - val_accuracy: 0.5849 - val_loss: 0.1326\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 731ms/step - accuracy: 1.0000 - loss: 1.2848e-05 - val_accuracy: 0.5833 - val_loss: 0.1405\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 725ms/step - accuracy: 1.0000 - loss: 6.7267e-06 - val_accuracy: 0.5817 - val_loss: 0.1409\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 689ms/step - accuracy: 0.9999 - loss: 4.1019e-06 - val_accuracy: 0.5849 - val_loss: 0.1386\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 698ms/step - accuracy: 1.0000 - loss: 6.2947e-06 - val_accuracy: 0.5865 - val_loss: 0.1423\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 719ms/step - accuracy: 1.0000 - loss: 5.2875e-06 - val_accuracy: 0.5913 - val_loss: 0.1416\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 693ms/step - accuracy: 1.0000 - loss: 1.0470e-06 - val_accuracy: 0.5929 - val_loss: 0.1432\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 710ms/step - accuracy: 1.0000 - loss: 1.8898e-06 - val_accuracy: 0.5897 - val_loss: 0.1441\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 690ms/step - accuracy: 0.9998 - loss: 1.5541e-05 - val_accuracy: 0.5953 - val_loss: 0.1495\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 708ms/step - accuracy: 0.9987 - loss: 7.6964e-05 - val_accuracy: 0.5857 - val_loss: 0.1459\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 697ms/step - accuracy: 0.9985 - loss: 3.5357e-04 - val_accuracy: 0.5720 - val_loss: 0.1462\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 739ms/step - accuracy: 0.9927 - loss: 6.7094e-04 - val_accuracy: 0.5800 - val_loss: 0.1519\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 717ms/step - accuracy: 0.9954 - loss: 4.9533e-04 - val_accuracy: 0.5865 - val_loss: 0.1453\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 739ms/step - accuracy: 0.9996 - loss: 2.8658e-05 - val_accuracy: 0.5809 - val_loss: 0.1443\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 707ms/step - accuracy: 1.0000 - loss: 7.4643e-06 - val_accuracy: 0.5881 - val_loss: 0.1491\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 682ms/step - accuracy: 0.9965 - loss: 3.0967e-04 - val_accuracy: 0.5865 - val_loss: 0.1503\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 655ms/step - accuracy: 1.0000 - loss: 1.2432e-05 - val_accuracy: 0.5825 - val_loss: 0.1511\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 630ms/step - accuracy: 0.9997 - loss: 1.0694e-05 - val_accuracy: 0.5792 - val_loss: 0.1535\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 572ms/step - accuracy: 1.0000 - loss: 7.1810e-06 - val_accuracy: 0.5889 - val_loss: 0.1470\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 3.7321e-06 - val_accuracy: 0.5873 - val_loss: 0.1487\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 550ms/step - accuracy: 0.9998 - loss: 9.1708e-06 - val_accuracy: 0.5849 - val_loss: 0.1507\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 538ms/step - accuracy: 0.9998 - loss: 6.9024e-06 - val_accuracy: 0.5720 - val_loss: 0.1559\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 547ms/step - accuracy: 0.9998 - loss: 2.8471e-05 - val_accuracy: 0.5881 - val_loss: 0.1584\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 8.5689e-06 - val_accuracy: 0.5881 - val_loss: 0.1564\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 2.6470e-06 - val_accuracy: 0.5817 - val_loss: 0.1553\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9999 - loss: 4.4763e-06 - val_accuracy: 0.5833 - val_loss: 0.1592\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 6.0381e-06 - val_accuracy: 0.5817 - val_loss: 0.1618\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 1.0000 - loss: 2.2110e-06 - val_accuracy: 0.5825 - val_loss: 0.1635\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 556ms/step - accuracy: 1.0000 - loss: 1.6214e-06 - val_accuracy: 0.5841 - val_loss: 0.1631\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 527ms/step - accuracy: 1.0000 - loss: 6.6567e-07 - val_accuracy: 0.5841 - val_loss: 0.1632\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 3.3567e-07 - val_accuracy: 0.5833 - val_loss: 0.1634\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 6.4819e-07 - val_accuracy: 0.5849 - val_loss: 0.1604\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 524ms/step - accuracy: 1.0000 - loss: 8.8121e-07 - val_accuracy: 0.5817 - val_loss: 0.1611\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 5.4927e-07 - val_accuracy: 0.5825 - val_loss: 0.1650\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 535ms/step - accuracy: 1.0000 - loss: 2.5636e-07 - val_accuracy: 0.5809 - val_loss: 0.1651\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 2.1205e-07 - val_accuracy: 0.5825 - val_loss: 0.1660\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 551ms/step - accuracy: 1.0000 - loss: 2.6677e-07 - val_accuracy: 0.5825 - val_loss: 0.1669\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 530ms/step - accuracy: 1.0000 - loss: 1.0061e-06 - val_accuracy: 0.5809 - val_loss: 0.1678\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 549ms/step - accuracy: 1.0000 - loss: 4.7395e-06 - val_accuracy: 0.5841 - val_loss: 0.1720\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step\n",
      "ResNet50 - Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9975 - loss: 3.3737e-04 - val_accuracy: 0.5926 - val_loss: 0.2121\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 540ms/step - accuracy: 0.9756 - loss: 0.0039 - val_accuracy: 0.5491 - val_loss: 0.2160\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 564ms/step - accuracy: 0.9835 - loss: 0.0025 - val_accuracy: 0.5580 - val_loss: 0.1244\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 546ms/step - accuracy: 0.9980 - loss: 1.9364e-04 - val_accuracy: 0.5902 - val_loss: 0.1219\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 558ms/step - accuracy: 0.9992 - loss: 3.8002e-05 - val_accuracy: 0.5886 - val_loss: 0.1247\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 565ms/step - accuracy: 0.9968 - loss: 8.3283e-04 - val_accuracy: 0.5853 - val_loss: 0.1227\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 535ms/step - accuracy: 0.9972 - loss: 2.9752e-04 - val_accuracy: 0.5926 - val_loss: 0.1286\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 552ms/step - accuracy: 0.9996 - loss: 8.0586e-05 - val_accuracy: 0.6039 - val_loss: 0.1397\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 542ms/step - accuracy: 0.9992 - loss: 1.1758e-04 - val_accuracy: 0.5950 - val_loss: 0.1356\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 536ms/step - accuracy: 0.9995 - loss: 2.4797e-05 - val_accuracy: 0.5902 - val_loss: 0.1373\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 569ms/step - accuracy: 0.9991 - loss: 2.3997e-05 - val_accuracy: 0.5942 - val_loss: 0.1389\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 610ms/step - accuracy: 1.0000 - loss: 5.5130e-06 - val_accuracy: 0.5942 - val_loss: 0.1407\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 620ms/step - accuracy: 0.9997 - loss: 1.4001e-05 - val_accuracy: 0.5845 - val_loss: 0.1438\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 589ms/step - accuracy: 0.9992 - loss: 1.0905e-04 - val_accuracy: 0.5821 - val_loss: 0.1429\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 601ms/step - accuracy: 0.9990 - loss: 9.5338e-05 - val_accuracy: 0.5950 - val_loss: 0.1578\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 594ms/step - accuracy: 0.9976 - loss: 8.9530e-05 - val_accuracy: 0.5918 - val_loss: 0.1475\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 770ms/step - accuracy: 0.9960 - loss: 4.3041e-04 - val_accuracy: 0.5918 - val_loss: 0.1443\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 766ms/step - accuracy: 0.9993 - loss: 5.3541e-05 - val_accuracy: 0.5934 - val_loss: 0.1433\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 771ms/step - accuracy: 0.9992 - loss: 1.1595e-04 - val_accuracy: 0.5982 - val_loss: 0.1446\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 759ms/step - accuracy: 0.9989 - loss: 1.8389e-04 - val_accuracy: 0.5990 - val_loss: 0.1450\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 803ms/step - accuracy: 0.9954 - loss: 4.8614e-04 - val_accuracy: 0.5966 - val_loss: 0.1333\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 771ms/step - accuracy: 0.9976 - loss: 1.1495e-04 - val_accuracy: 0.5934 - val_loss: 0.1305\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 789ms/step - accuracy: 0.9990 - loss: 7.5099e-05 - val_accuracy: 0.5950 - val_loss: 0.1354\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 724ms/step - accuracy: 0.9990 - loss: 3.8499e-05 - val_accuracy: 0.5934 - val_loss: 0.1375\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 659ms/step - accuracy: 0.9998 - loss: 2.1447e-05 - val_accuracy: 0.5765 - val_loss: 0.1385\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 664ms/step - accuracy: 1.0000 - loss: 9.4898e-06 - val_accuracy: 0.5966 - val_loss: 0.1406\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 660ms/step - accuracy: 1.0000 - loss: 6.2982e-06 - val_accuracy: 0.5950 - val_loss: 0.1411\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 704ms/step - accuracy: 1.0000 - loss: 3.0354e-06 - val_accuracy: 0.5910 - val_loss: 0.1418\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 664ms/step - accuracy: 0.9998 - loss: 1.2611e-05 - val_accuracy: 0.5813 - val_loss: 0.1454\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 670ms/step - accuracy: 0.9994 - loss: 3.3402e-05 - val_accuracy: 0.5652 - val_loss: 0.1447\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 663ms/step - accuracy: 0.9994 - loss: 3.7080e-05 - val_accuracy: 0.5733 - val_loss: 0.1443\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 631ms/step - accuracy: 0.9998 - loss: 1.2577e-05 - val_accuracy: 0.5886 - val_loss: 0.1466\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 703ms/step - accuracy: 0.9986 - loss: 1.6925e-04 - val_accuracy: 0.5821 - val_loss: 0.1501\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 703ms/step - accuracy: 0.9984 - loss: 9.4838e-05 - val_accuracy: 0.5862 - val_loss: 0.1619\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 688ms/step - accuracy: 0.9993 - loss: 8.8371e-05 - val_accuracy: 0.5668 - val_loss: 0.1796\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 686ms/step - accuracy: 0.9903 - loss: 0.0018 - val_accuracy: 0.5370 - val_loss: 0.1547\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 688ms/step - accuracy: 0.9953 - loss: 2.2799e-04 - val_accuracy: 0.5668 - val_loss: 0.1424\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 681ms/step - accuracy: 0.9984 - loss: 1.5125e-04 - val_accuracy: 0.5837 - val_loss: 0.1387\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 592ms/step - accuracy: 0.9988 - loss: 4.2551e-05 - val_accuracy: 0.5813 - val_loss: 0.1438\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 537ms/step - accuracy: 0.9969 - loss: 1.7923e-04 - val_accuracy: 0.5845 - val_loss: 0.1487\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 557ms/step - accuracy: 0.9991 - loss: 5.4516e-05 - val_accuracy: 0.5692 - val_loss: 0.1468\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 539ms/step - accuracy: 0.9998 - loss: 1.5762e-04 - val_accuracy: 0.5700 - val_loss: 0.1436\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 553ms/step - accuracy: 0.9987 - loss: 1.2382e-04 - val_accuracy: 0.5765 - val_loss: 0.1449\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 553ms/step - accuracy: 0.9998 - loss: 1.4473e-05 - val_accuracy: 0.5797 - val_loss: 0.1440\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 530ms/step - accuracy: 0.9993 - loss: 2.2486e-05 - val_accuracy: 0.5894 - val_loss: 0.1464\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 555ms/step - accuracy: 0.9966 - loss: 6.3374e-04 - val_accuracy: 0.5902 - val_loss: 0.1460\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 550ms/step - accuracy: 0.9966 - loss: 3.7558e-04 - val_accuracy: 0.5765 - val_loss: 0.1412\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 537ms/step - accuracy: 1.0000 - loss: 1.8242e-05 - val_accuracy: 0.5853 - val_loss: 0.1407\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 556ms/step - accuracy: 0.9988 - loss: 6.1048e-05 - val_accuracy: 0.5821 - val_loss: 0.1488\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 542ms/step - accuracy: 1.0000 - loss: 1.1023e-05 - val_accuracy: 0.5805 - val_loss: 0.1468\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step\n",
      "\n",
      "ResNet50 Average Results:\n",
      "Average Sensitivity: 0.7625\n",
      "Average Specificity: 0.9232\n",
      "Average Score: 0.8429\n",
      "Average Accuracy: 0.8160\n",
      "\n",
      "Training ResNet18...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ re_lu_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ re_lu_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ re_lu_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ re_lu_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ re_lu_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │      \u001b[38;5;34m3,200\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │     \u001b[38;5;34m73,856\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_22 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │      \u001b[38;5;34m8,320\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_23 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_24 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ re_lu_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_25 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ re_lu_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_26 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ re_lu_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_27 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_28 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_29 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,180,160\u001b[0m │ re_lu_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_30 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m131,584\u001b[0m │ re_lu_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_31 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_32 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ re_lu_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_33 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m2,052\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,445,764</span> (43.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,445,764\u001b[0m (43.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,437,956</span> (43.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,437,956\u001b[0m (43.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> (30.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,808\u001b[0m (30.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 - Training fold 1/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 328ms/step - accuracy: 0.4658 - loss: 0.0514 - val_accuracy: 0.5942 - val_loss: 0.0370\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.5610 - loss: 0.0316 - val_accuracy: 0.5870 - val_loss: 0.0395\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.6131 - loss: 0.0267 - val_accuracy: 0.5862 - val_loss: 0.0355\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.6382 - loss: 0.0241 - val_accuracy: 0.5290 - val_loss: 0.0409\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 0.6996 - loss: 0.0191 - val_accuracy: 0.5475 - val_loss: 0.0397\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.7459 - loss: 0.0149 - val_accuracy: 0.4614 - val_loss: 0.0484\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.7484 - loss: 0.0153 - val_accuracy: 0.4155 - val_loss: 0.0562\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.8197 - loss: 0.0090 - val_accuracy: 0.5684 - val_loss: 0.0569\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.8623 - loss: 0.0071 - val_accuracy: 0.4235 - val_loss: 0.0684\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.8922 - loss: 0.0054 - val_accuracy: 0.5354 - val_loss: 0.0683\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9058 - loss: 0.0047 - val_accuracy: 0.5805 - val_loss: 0.0696\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9192 - loss: 0.0044 - val_accuracy: 0.4187 - val_loss: 0.0833\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9227 - loss: 0.0037 - val_accuracy: 0.5700 - val_loss: 0.1092\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9388 - loss: 0.0037 - val_accuracy: 0.4509 - val_loss: 0.0825\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9113 - loss: 0.0048 - val_accuracy: 0.5692 - val_loss: 0.0617\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9400 - loss: 0.0032 - val_accuracy: 0.4718 - val_loss: 0.0737\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.8654 - loss: 0.0085 - val_accuracy: 0.5709 - val_loss: 0.0751\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9712 - loss: 0.0016 - val_accuracy: 0.5459 - val_loss: 0.0832\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9735 - loss: 0.0015 - val_accuracy: 0.5588 - val_loss: 0.0971\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.8765 - loss: 0.0082 - val_accuracy: 0.5427 - val_loss: 0.0792\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9549 - loss: 0.0023 - val_accuracy: 0.5411 - val_loss: 0.0824\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9825 - loss: 0.0011 - val_accuracy: 0.4968 - val_loss: 0.0822\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9689 - loss: 0.0018 - val_accuracy: 0.5741 - val_loss: 0.0951\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9834 - loss: 0.0011 - val_accuracy: 0.4992 - val_loss: 0.1018\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9897 - loss: 5.7911e-04 - val_accuracy: 0.4879 - val_loss: 0.1187\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9760 - loss: 0.0016 - val_accuracy: 0.4976 - val_loss: 0.0996\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9411 - loss: 0.0039 - val_accuracy: 0.4919 - val_loss: 0.0808\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9639 - loss: 0.0022 - val_accuracy: 0.5620 - val_loss: 0.0984\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9869 - loss: 0.0011 - val_accuracy: 0.5483 - val_loss: 0.1025\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.9854 - loss: 8.2432e-04 - val_accuracy: 0.5692 - val_loss: 0.1172\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9412 - loss: 0.0039 - val_accuracy: 0.4517 - val_loss: 0.0917\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9795 - loss: 0.0013 - val_accuracy: 0.5362 - val_loss: 0.0911\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 0.9820 - loss: 0.0011 - val_accuracy: 0.4614 - val_loss: 0.0935\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9839 - loss: 8.8424e-04 - val_accuracy: 0.5250 - val_loss: 0.0852\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9902 - loss: 4.8041e-04 - val_accuracy: 0.5072 - val_loss: 0.1089\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9769 - loss: 0.0016 - val_accuracy: 0.5177 - val_loss: 0.0940\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9834 - loss: 0.0011 - val_accuracy: 0.4710 - val_loss: 0.1041\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9946 - loss: 3.2344e-04 - val_accuracy: 0.5000 - val_loss: 0.1074\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 0.9766 - loss: 0.0012 - val_accuracy: 0.5064 - val_loss: 0.1000\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9805 - loss: 0.0011 - val_accuracy: 0.5451 - val_loss: 0.0967\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9596 - loss: 0.0025 - val_accuracy: 0.5121 - val_loss: 0.0840\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 0.9348 - loss: 0.0039 - val_accuracy: 0.4919 - val_loss: 0.0930\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9901 - loss: 9.1746e-04 - val_accuracy: 0.5419 - val_loss: 0.0951\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 0.9835 - loss: 0.0011 - val_accuracy: 0.4638 - val_loss: 0.1029\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9884 - loss: 6.4971e-04 - val_accuracy: 0.5346 - val_loss: 0.0970\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 0.9694 - loss: 0.0018 - val_accuracy: 0.4702 - val_loss: 0.0821\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 0.9338 - loss: 0.0051 - val_accuracy: 0.4839 - val_loss: 0.0891\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9658 - loss: 0.0021 - val_accuracy: 0.5507 - val_loss: 0.1035\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9913 - loss: 4.4842e-04 - val_accuracy: 0.5000 - val_loss: 0.0935\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 0.9932 - loss: 4.2846e-04 - val_accuracy: 0.4944 - val_loss: 0.1159\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step\n",
      "ResNet18 - Training fold 2/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.8955 - loss: 0.0122 - val_accuracy: 0.5081 - val_loss: 0.0497\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9658 - loss: 0.0028 - val_accuracy: 0.5008 - val_loss: 0.0752\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9781 - loss: 0.0016 - val_accuracy: 0.4340 - val_loss: 0.0813\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 306ms/step - accuracy: 0.9847 - loss: 0.0010 - val_accuracy: 0.5201 - val_loss: 0.0771\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9866 - loss: 8.1592e-04 - val_accuracy: 0.5290 - val_loss: 0.0838\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9925 - loss: 4.5228e-04 - val_accuracy: 0.4501 - val_loss: 0.1204\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9751 - loss: 0.0016 - val_accuracy: 0.4622 - val_loss: 0.0932\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9835 - loss: 0.0010 - val_accuracy: 0.5370 - val_loss: 0.1029\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9850 - loss: 9.5537e-04 - val_accuracy: 0.5242 - val_loss: 0.0814\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9936 - loss: 4.2770e-04 - val_accuracy: 0.5274 - val_loss: 0.1081\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9681 - loss: 0.0021 - val_accuracy: 0.5225 - val_loss: 0.0638\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9790 - loss: 0.0012 - val_accuracy: 0.5403 - val_loss: 0.0965\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9896 - loss: 6.8374e-04 - val_accuracy: 0.4895 - val_loss: 0.1096\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9908 - loss: 4.5569e-04 - val_accuracy: 0.5322 - val_loss: 0.1046\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9931 - loss: 3.8518e-04 - val_accuracy: 0.5467 - val_loss: 0.1072\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9986 - loss: 7.0956e-05 - val_accuracy: 0.5427 - val_loss: 0.1135\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9974 - loss: 2.0317e-04 - val_accuracy: 0.5411 - val_loss: 0.1121\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9982 - loss: 1.3733e-04 - val_accuracy: 0.5467 - val_loss: 0.0934\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9741 - loss: 0.0018 - val_accuracy: 0.5250 - val_loss: 0.0927\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 304ms/step - accuracy: 0.9790 - loss: 9.8723e-04 - val_accuracy: 0.4452 - val_loss: 0.0952\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9806 - loss: 0.0013 - val_accuracy: 0.4670 - val_loss: 0.0935\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9950 - loss: 2.3804e-04 - val_accuracy: 0.5201 - val_loss: 0.1141\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9955 - loss: 2.5447e-04 - val_accuracy: 0.5290 - val_loss: 0.0791\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9865 - loss: 0.0011 - val_accuracy: 0.4557 - val_loss: 0.0881\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9841 - loss: 8.9973e-04 - val_accuracy: 0.5145 - val_loss: 0.0782\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9841 - loss: 9.8771e-04 - val_accuracy: 0.4815 - val_loss: 0.1115\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9820 - loss: 0.0010 - val_accuracy: 0.5056 - val_loss: 0.1054\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9973 - loss: 1.8151e-04 - val_accuracy: 0.4960 - val_loss: 0.1062\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9929 - loss: 3.7971e-04 - val_accuracy: 0.5250 - val_loss: 0.1149\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9944 - loss: 4.3728e-04 - val_accuracy: 0.5064 - val_loss: 0.1097\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9899 - loss: 6.2864e-04 - val_accuracy: 0.4879 - val_loss: 0.0916\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 0.9910 - loss: 6.1449e-04 - val_accuracy: 0.5395 - val_loss: 0.0892\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9985 - loss: 1.0961e-04 - val_accuracy: 0.5242 - val_loss: 0.1188\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9922 - loss: 4.1641e-04 - val_accuracy: 0.4968 - val_loss: 0.1135\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9914 - loss: 5.5748e-04 - val_accuracy: 0.4928 - val_loss: 0.0869\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.8871 - loss: 0.0078 - val_accuracy: 0.4477 - val_loss: 0.0928\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 0.9905 - loss: 5.1486e-04 - val_accuracy: 0.4952 - val_loss: 0.1087\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 0.9976 - loss: 1.4084e-04 - val_accuracy: 0.5250 - val_loss: 0.1131\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 0.9992 - loss: 4.5958e-05 - val_accuracy: 0.4936 - val_loss: 0.1179\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9911 - loss: 7.6364e-04 - val_accuracy: 0.5209 - val_loss: 0.1005\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9947 - loss: 2.9300e-04 - val_accuracy: 0.5121 - val_loss: 0.1140\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 0.9960 - loss: 2.5735e-04 - val_accuracy: 0.5064 - val_loss: 0.1173\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9987 - loss: 6.4237e-05 - val_accuracy: 0.4791 - val_loss: 0.1129\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9971 - loss: 2.1610e-04 - val_accuracy: 0.5008 - val_loss: 0.1314\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9994 - loss: 3.7706e-05 - val_accuracy: 0.5072 - val_loss: 0.0894\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 0.9161 - loss: 0.0070 - val_accuracy: 0.5185 - val_loss: 0.0631\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 0.9898 - loss: 7.3720e-04 - val_accuracy: 0.5298 - val_loss: 0.1021\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9937 - loss: 3.5445e-04 - val_accuracy: 0.5193 - val_loss: 0.1098\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9993 - loss: 5.3248e-05 - val_accuracy: 0.5129 - val_loss: 0.1261\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9996 - loss: 3.1811e-05 - val_accuracy: 0.4952 - val_loss: 0.1245\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "ResNet18 - Training fold 3/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9704 - loss: 0.0030 - val_accuracy: 0.4517 - val_loss: 0.0765\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 0.9888 - loss: 6.3384e-04 - val_accuracy: 0.5072 - val_loss: 0.1147\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9971 - loss: 1.9887e-04 - val_accuracy: 0.4952 - val_loss: 0.1190\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9940 - loss: 3.3664e-04 - val_accuracy: 0.5201 - val_loss: 0.1073\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9988 - loss: 7.9714e-05 - val_accuracy: 0.5008 - val_loss: 0.1224\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 0.9989 - loss: 8.2412e-05 - val_accuracy: 0.4976 - val_loss: 0.1113\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9679 - loss: 0.0020 - val_accuracy: 0.5266 - val_loss: 0.0976\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9953 - loss: 2.6782e-04 - val_accuracy: 0.5097 - val_loss: 0.1164\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9984 - loss: 7.5473e-05 - val_accuracy: 0.5217 - val_loss: 0.0994\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 0.9782 - loss: 0.0013 - val_accuracy: 0.5064 - val_loss: 0.1145\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9883 - loss: 7.8475e-04 - val_accuracy: 0.5024 - val_loss: 0.1068\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 0.9975 - loss: 2.0280e-04 - val_accuracy: 0.4815 - val_loss: 0.1012\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 0.9982 - loss: 1.3398e-04 - val_accuracy: 0.5354 - val_loss: 0.1115\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 0.9997 - loss: 3.8045e-05 - val_accuracy: 0.5217 - val_loss: 0.1256\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 1.6777e-05 - val_accuracy: 0.5250 - val_loss: 0.1353\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.9898 - loss: 5.6854e-04 - val_accuracy: 0.5056 - val_loss: 0.1091\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 0.9846 - loss: 0.0012 - val_accuracy: 0.5016 - val_loss: 0.0819\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 337ms/step - accuracy: 0.9871 - loss: 6.5816e-04 - val_accuracy: 0.5419 - val_loss: 0.1073\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9953 - loss: 3.5356e-04 - val_accuracy: 0.4936 - val_loss: 0.0826\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9665 - loss: 0.0020 - val_accuracy: 0.5024 - val_loss: 0.1233\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9832 - loss: 0.0012 - val_accuracy: 0.5089 - val_loss: 0.1070\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9983 - loss: 1.4989e-04 - val_accuracy: 0.5000 - val_loss: 0.0867\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9978 - loss: 9.7389e-05 - val_accuracy: 0.5105 - val_loss: 0.1189\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.5908e-05 - val_accuracy: 0.5032 - val_loss: 0.1270\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9998 - loss: 8.7141e-06 - val_accuracy: 0.5250 - val_loss: 0.1234\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9999 - loss: 6.7678e-06 - val_accuracy: 0.5242 - val_loss: 0.1311\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 4.3936e-06 - val_accuracy: 0.5121 - val_loss: 0.1397\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 3.0416e-06 - val_accuracy: 0.5185 - val_loss: 0.1432\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 1.3294e-06 - val_accuracy: 0.5129 - val_loss: 0.1474\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 333ms/step - accuracy: 0.9999 - loss: 7.1655e-06 - val_accuracy: 0.5362 - val_loss: 0.1471\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 1.9483e-06 - val_accuracy: 0.5242 - val_loss: 0.1503\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9939 - loss: 5.5013e-04 - val_accuracy: 0.4251 - val_loss: 0.0802\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.9441 - loss: 0.0033 - val_accuracy: 0.4839 - val_loss: 0.0799\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9930 - loss: 4.0850e-04 - val_accuracy: 0.5040 - val_loss: 0.1057\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9932 - loss: 3.8336e-04 - val_accuracy: 0.5684 - val_loss: 0.1190\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9979 - loss: 1.5755e-04 - val_accuracy: 0.4525 - val_loss: 0.1014\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9963 - loss: 2.1958e-04 - val_accuracy: 0.5072 - val_loss: 0.1017\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9993 - loss: 3.9527e-05 - val_accuracy: 0.5250 - val_loss: 0.1312\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 8.4029e-06 - val_accuracy: 0.5209 - val_loss: 0.1318\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.4855e-06 - val_accuracy: 0.5113 - val_loss: 0.1310\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9947 - loss: 3.5437e-04 - val_accuracy: 0.4501 - val_loss: 0.0963\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9862 - loss: 8.8725e-04 - val_accuracy: 0.5443 - val_loss: 0.0855\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9926 - loss: 7.1278e-04 - val_accuracy: 0.5089 - val_loss: 0.0973\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9934 - loss: 4.1366e-04 - val_accuracy: 0.4477 - val_loss: 0.1219\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9935 - loss: 3.4561e-04 - val_accuracy: 0.5064 - val_loss: 0.1073\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9953 - loss: 3.3551e-04 - val_accuracy: 0.5427 - val_loss: 0.0969\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9852 - loss: 0.0010 - val_accuracy: 0.5137 - val_loss: 0.1109\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9987 - loss: 2.7309e-04 - val_accuracy: 0.5097 - val_loss: 0.1204\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9983 - loss: 1.4548e-04 - val_accuracy: 0.4911 - val_loss: 0.1143\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9949 - loss: 4.0955e-04 - val_accuracy: 0.4767 - val_loss: 0.1130\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "ResNet18 - Training fold 4/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9753 - loss: 0.0022 - val_accuracy: 0.5700 - val_loss: 0.0725\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9925 - loss: 4.1926e-04 - val_accuracy: 0.6143 - val_loss: 0.0767\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9979 - loss: 1.4480e-04 - val_accuracy: 0.5982 - val_loss: 0.1111\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9718 - loss: 0.0021 - val_accuracy: 0.5950 - val_loss: 0.0766\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9935 - loss: 4.6396e-04 - val_accuracy: 0.6071 - val_loss: 0.0971\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9900 - loss: 9.1350e-04 - val_accuracy: 0.6151 - val_loss: 0.0654\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.9971 - loss: 2.3961e-04 - val_accuracy: 0.5757 - val_loss: 0.0940\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9996 - loss: 6.1174e-05 - val_accuracy: 0.6095 - val_loss: 0.1014\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 8.6946e-06 - val_accuracy: 0.5982 - val_loss: 0.1009\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 5.8239e-06 - val_accuracy: 0.6079 - val_loss: 0.1050\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 2.5418e-06 - val_accuracy: 0.5982 - val_loss: 0.1097\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 3.0495e-06 - val_accuracy: 0.6006 - val_loss: 0.1092\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 1.2397e-06 - val_accuracy: 0.5998 - val_loss: 0.1122\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.0793e-06 - val_accuracy: 0.6006 - val_loss: 0.1137\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 2.2374e-06 - val_accuracy: 0.6031 - val_loss: 0.1140\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 3.2534e-06 - val_accuracy: 0.5556 - val_loss: 0.1092\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9788 - loss: 0.0015 - val_accuracy: 0.5556 - val_loss: 0.0721\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9767 - loss: 0.0013 - val_accuracy: 0.5507 - val_loss: 0.0989\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9917 - loss: 6.3111e-04 - val_accuracy: 0.5934 - val_loss: 0.0980\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 5.6502e-05 - val_accuracy: 0.5942 - val_loss: 0.1030\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 298ms/step - accuracy: 0.9964 - loss: 2.1399e-04 - val_accuracy: 0.5483 - val_loss: 0.0971\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9829 - loss: 9.2185e-04 - val_accuracy: 0.5435 - val_loss: 0.0924\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9985 - loss: 1.1803e-04 - val_accuracy: 0.6176 - val_loss: 0.0878\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 2.0072e-05 - val_accuracy: 0.6184 - val_loss: 0.0956\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 4.5652e-06 - val_accuracy: 0.6216 - val_loss: 0.0992\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 3.6845e-06 - val_accuracy: 0.6176 - val_loss: 0.1023\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 1.0380e-06 - val_accuracy: 0.6208 - val_loss: 0.1032\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.0946e-06 - val_accuracy: 0.6167 - val_loss: 0.1071\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.0277e-06 - val_accuracy: 0.6135 - val_loss: 0.1081\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 1.1150e-06 - val_accuracy: 0.6176 - val_loss: 0.1088\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 8.9972e-07 - val_accuracy: 0.6143 - val_loss: 0.1097\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 5.9222e-07 - val_accuracy: 0.6159 - val_loss: 0.1108\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 5.2556e-07 - val_accuracy: 0.6159 - val_loss: 0.1118\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 3.4639e-07 - val_accuracy: 0.6151 - val_loss: 0.1125\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 4.1513e-07 - val_accuracy: 0.6143 - val_loss: 0.1132\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.5559e-07 - val_accuracy: 0.6176 - val_loss: 0.1143\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 2.4012e-07 - val_accuracy: 0.6167 - val_loss: 0.1154\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.7667e-07 - val_accuracy: 0.6167 - val_loss: 0.1162\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 8.9313e-07 - val_accuracy: 0.6063 - val_loss: 0.1122\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 6.2755e-07 - val_accuracy: 0.6208 - val_loss: 0.1183\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.7296e-07 - val_accuracy: 0.6176 - val_loss: 0.1200\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.8574e-07 - val_accuracy: 0.6200 - val_loss: 0.1204\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 8.3774e-08 - val_accuracy: 0.6200 - val_loss: 0.1214\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.8130e-07 - val_accuracy: 0.6240 - val_loss: 0.1221\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.5095e-07 - val_accuracy: 0.6184 - val_loss: 0.1229\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 2.0115e-07 - val_accuracy: 0.6119 - val_loss: 0.1249\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.2183e-07 - val_accuracy: 0.6167 - val_loss: 0.1249\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 2.8394e-07 - val_accuracy: 0.6135 - val_loss: 0.1254\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 6.4338e-08 - val_accuracy: 0.6176 - val_loss: 0.1253\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 1.6372e-07 - val_accuracy: 0.6031 - val_loss: 0.1221\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step\n",
      "ResNet18 - Training fold 5/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 330ms/step - accuracy: 0.9229 - loss: 0.0063 - val_accuracy: 0.5161 - val_loss: 0.0640\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9649 - loss: 0.0023 - val_accuracy: 0.5467 - val_loss: 0.0797\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9879 - loss: 5.9614e-04 - val_accuracy: 0.5395 - val_loss: 0.1068\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9954 - loss: 3.8993e-04 - val_accuracy: 0.5298 - val_loss: 0.1135\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9980 - loss: 1.2431e-04 - val_accuracy: 0.5282 - val_loss: 0.1152\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9972 - loss: 1.8243e-04 - val_accuracy: 0.5040 - val_loss: 0.1088\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 0.9965 - loss: 2.5453e-04 - val_accuracy: 0.5378 - val_loss: 0.1208\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9911 - loss: 5.8849e-04 - val_accuracy: 0.4960 - val_loss: 0.1076\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9977 - loss: 1.6065e-04 - val_accuracy: 0.5008 - val_loss: 0.1129\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9931 - loss: 3.6747e-04 - val_accuracy: 0.5362 - val_loss: 0.1002\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9930 - loss: 3.6849e-04 - val_accuracy: 0.5370 - val_loss: 0.1225\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9994 - loss: 7.0479e-05 - val_accuracy: 0.5781 - val_loss: 0.1417\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9949 - loss: 3.1071e-04 - val_accuracy: 0.5008 - val_loss: 0.1088\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9910 - loss: 5.8514e-04 - val_accuracy: 0.5330 - val_loss: 0.1104\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9936 - loss: 5.2963e-04 - val_accuracy: 0.5354 - val_loss: 0.1161\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9990 - loss: 5.4462e-05 - val_accuracy: 0.5225 - val_loss: 0.1234\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9998 - loss: 8.7317e-06 - val_accuracy: 0.5274 - val_loss: 0.1206\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 4.8816e-06 - val_accuracy: 0.5282 - val_loss: 0.1319\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 2.1404e-06 - val_accuracy: 0.5282 - val_loss: 0.1323\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.1341e-06 - val_accuracy: 0.5322 - val_loss: 0.1346\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.6576e-06 - val_accuracy: 0.5274 - val_loss: 0.1363\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 9.1854e-07 - val_accuracy: 0.5258 - val_loss: 0.1381\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.2834e-06 - val_accuracy: 0.5225 - val_loss: 0.1390\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 6.9851e-07 - val_accuracy: 0.5217 - val_loss: 0.1409\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.1206e-06 - val_accuracy: 0.5274 - val_loss: 0.1414\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 5.3134e-07 - val_accuracy: 0.5306 - val_loss: 0.1441\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.4724e-06 - val_accuracy: 0.5282 - val_loss: 0.1454\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 3.6661e-07 - val_accuracy: 0.5250 - val_loss: 0.1454\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 3.9544e-07 - val_accuracy: 0.5201 - val_loss: 0.1482\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 2.4819e-07 - val_accuracy: 0.5250 - val_loss: 0.1475\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 1.6500e-07 - val_accuracy: 0.5250 - val_loss: 0.1494\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 3.0784e-07 - val_accuracy: 0.5282 - val_loss: 0.1505\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 4.2804e-07 - val_accuracy: 0.5346 - val_loss: 0.1515\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.9236e-07 - val_accuracy: 0.5330 - val_loss: 0.1513\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 3.0465e-07 - val_accuracy: 0.5306 - val_loss: 0.1530\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 1.1661e-07 - val_accuracy: 0.5314 - val_loss: 0.1526\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 2.2332e-07 - val_accuracy: 0.5330 - val_loss: 0.1545\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.5706e-07 - val_accuracy: 0.5314 - val_loss: 0.1547\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 9.6294e-08 - val_accuracy: 0.5330 - val_loss: 0.1547\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 1.0000 - loss: 1.3550e-07 - val_accuracy: 0.5306 - val_loss: 0.1556\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.4132e-07 - val_accuracy: 0.5338 - val_loss: 0.1561\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.0108e-07 - val_accuracy: 0.5346 - val_loss: 0.1578\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 8.1813e-08 - val_accuracy: 0.5330 - val_loss: 0.1585\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 7.1881e-08 - val_accuracy: 0.5338 - val_loss: 0.1584\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 5.2997e-08 - val_accuracy: 0.5274 - val_loss: 0.1598\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.3740e-07 - val_accuracy: 0.5314 - val_loss: 0.1604\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 6.1586e-08 - val_accuracy: 0.5258 - val_loss: 0.1604\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 5.1669e-08 - val_accuracy: 0.5233 - val_loss: 0.1610\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 5.7214e-08 - val_accuracy: 0.5274 - val_loss: 0.1615\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.4062e-07 - val_accuracy: 0.5314 - val_loss: 0.1631\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step\n",
      "ResNet18 - Training fold 6/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 0.8876 - loss: 0.0086 - val_accuracy: 0.5636 - val_loss: 0.0586\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9879 - loss: 9.2558e-04 - val_accuracy: 0.5789 - val_loss: 0.0796\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9984 - loss: 1.2616e-04 - val_accuracy: 0.5837 - val_loss: 0.1032\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 2.3294e-05 - val_accuracy: 0.5813 - val_loss: 0.1044\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9992 - loss: 7.5816e-05 - val_accuracy: 0.6200 - val_loss: 0.1034\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9923 - loss: 5.3477e-04 - val_accuracy: 0.5620 - val_loss: 0.0791\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9974 - loss: 1.1390e-04 - val_accuracy: 0.5668 - val_loss: 0.1080\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9995 - loss: 3.2528e-05 - val_accuracy: 0.5700 - val_loss: 0.1163\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.9308e-06 - val_accuracy: 0.5700 - val_loss: 0.1179\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 4.3152e-06 - val_accuracy: 0.5765 - val_loss: 0.1161\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 2.3076e-06 - val_accuracy: 0.5773 - val_loss: 0.1170\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 1.7467e-06 - val_accuracy: 0.5733 - val_loss: 0.1200\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 301ms/step - accuracy: 0.9998 - loss: 1.5028e-05 - val_accuracy: 0.5926 - val_loss: 0.1101\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9791 - loss: 0.0013 - val_accuracy: 0.5403 - val_loss: 0.0816\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 0.9828 - loss: 0.0010 - val_accuracy: 0.5773 - val_loss: 0.0804\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.9972 - loss: 1.6460e-04 - val_accuracy: 0.5556 - val_loss: 0.1077\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9985 - loss: 1.2570e-04 - val_accuracy: 0.5596 - val_loss: 0.1159\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 0.9995 - loss: 2.1248e-05 - val_accuracy: 0.5781 - val_loss: 0.1172\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 3.5270e-06 - val_accuracy: 0.5789 - val_loss: 0.1193\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.5258e-06 - val_accuracy: 0.5829 - val_loss: 0.1210\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.4812e-06 - val_accuracy: 0.5781 - val_loss: 0.1229\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 1.4867e-06 - val_accuracy: 0.5757 - val_loss: 0.1252\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.2513e-06 - val_accuracy: 0.5733 - val_loss: 0.1290\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 1.1269e-06 - val_accuracy: 0.5765 - val_loss: 0.1285\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 7.4062e-07 - val_accuracy: 0.5773 - val_loss: 0.1293\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 6.0897e-07 - val_accuracy: 0.5773 - val_loss: 0.1307\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 8.3966e-07 - val_accuracy: 0.5797 - val_loss: 0.1334\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 4.9041e-07 - val_accuracy: 0.5781 - val_loss: 0.1331\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 6.6953e-07 - val_accuracy: 0.5733 - val_loss: 0.1340\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 4.9055e-07 - val_accuracy: 0.5757 - val_loss: 0.1351\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 4.5535e-07 - val_accuracy: 0.5765 - val_loss: 0.1358\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 5.1993e-07 - val_accuracy: 0.5725 - val_loss: 0.1346\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 2.3492e-07 - val_accuracy: 0.5717 - val_loss: 0.1379\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 2.1834e-07 - val_accuracy: 0.5725 - val_loss: 0.1395\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 3.9849e-07 - val_accuracy: 0.5725 - val_loss: 0.1399\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.3868e-07 - val_accuracy: 0.5749 - val_loss: 0.1408\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 1.6709e-07 - val_accuracy: 0.5717 - val_loss: 0.1429\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.4817e-07 - val_accuracy: 0.5725 - val_loss: 0.1426\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.6043e-07 - val_accuracy: 0.5676 - val_loss: 0.1436\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 1.7966e-07 - val_accuracy: 0.5668 - val_loss: 0.1446\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 1.0614e-07 - val_accuracy: 0.5733 - val_loss: 0.1444\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 1.0205e-07 - val_accuracy: 0.5733 - val_loss: 0.1451\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 7.3898e-08 - val_accuracy: 0.5749 - val_loss: 0.1470\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 1.1523e-07 - val_accuracy: 0.5709 - val_loss: 0.1465\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 300ms/step - accuracy: 1.0000 - loss: 6.0109e-08 - val_accuracy: 0.5709 - val_loss: 0.1475\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 1.7522e-07 - val_accuracy: 0.5652 - val_loss: 0.1475\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 8.0879e-08 - val_accuracy: 0.5668 - val_loss: 0.1492\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 5.0323e-08 - val_accuracy: 0.5692 - val_loss: 0.1495\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 1.1768e-07 - val_accuracy: 0.5692 - val_loss: 0.1503\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 4.5985e-08 - val_accuracy: 0.5684 - val_loss: 0.1515\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "ResNet18 - Training fold 7/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.8991 - loss: 0.0091 - val_accuracy: 0.5684 - val_loss: 0.0602\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9825 - loss: 0.0012 - val_accuracy: 0.5386 - val_loss: 0.0864\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9960 - loss: 2.5292e-04 - val_accuracy: 0.5709 - val_loss: 0.0892\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9979 - loss: 1.4137e-04 - val_accuracy: 0.5411 - val_loss: 0.0851\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.9983 - loss: 8.7720e-05 - val_accuracy: 0.5717 - val_loss: 0.0960\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9998 - loss: 2.2933e-05 - val_accuracy: 0.5886 - val_loss: 0.0991\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 6.3034e-06 - val_accuracy: 0.5950 - val_loss: 0.1076\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 8.5487e-06 - val_accuracy: 0.5845 - val_loss: 0.1149\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.8521e-06 - val_accuracy: 0.5862 - val_loss: 0.1137\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 2.3047e-06 - val_accuracy: 0.5878 - val_loss: 0.1139\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 1.0756e-06 - val_accuracy: 0.5910 - val_loss: 0.1148\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 8.6432e-07 - val_accuracy: 0.5862 - val_loss: 0.1159\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 1.9139e-06 - val_accuracy: 0.5886 - val_loss: 0.1179\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 6.0639e-07 - val_accuracy: 0.5862 - val_loss: 0.1184\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.0051e-06 - val_accuracy: 0.5974 - val_loss: 0.1192\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 7.4250e-07 - val_accuracy: 0.5845 - val_loss: 0.1180\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9760 - loss: 0.0018 - val_accuracy: 0.5725 - val_loss: 0.0766\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.9850 - loss: 7.9066e-04 - val_accuracy: 0.5990 - val_loss: 0.0817\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.9867 - loss: 7.8223e-04 - val_accuracy: 0.5773 - val_loss: 0.0753\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 0.9959 - loss: 1.8043e-04 - val_accuracy: 0.5660 - val_loss: 0.0909\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9986 - loss: 8.3247e-05 - val_accuracy: 0.5290 - val_loss: 0.1015\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9999 - loss: 3.0126e-05 - val_accuracy: 0.5878 - val_loss: 0.1071\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9949 - loss: 2.7208e-04 - val_accuracy: 0.5580 - val_loss: 0.0822\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 0.9966 - loss: 1.6744e-04 - val_accuracy: 0.5459 - val_loss: 0.1159\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 1.4172e-05 - val_accuracy: 0.5668 - val_loss: 0.1123\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9999 - loss: 6.8651e-06 - val_accuracy: 0.5749 - val_loss: 0.1043\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9985 - loss: 1.0198e-04 - val_accuracy: 0.5483 - val_loss: 0.0864\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 0.9721 - loss: 0.0022 - val_accuracy: 0.5789 - val_loss: 0.0813\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 0.9952 - loss: 2.1550e-04 - val_accuracy: 0.5773 - val_loss: 0.0896\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9999 - loss: 2.8671e-05 - val_accuracy: 0.5660 - val_loss: 0.1041\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 0.9998 - loss: 6.0788e-05 - val_accuracy: 0.5845 - val_loss: 0.1018\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 9.8867e-06 - val_accuracy: 0.5878 - val_loss: 0.1096\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 2.6326e-06 - val_accuracy: 0.5902 - val_loss: 0.1119\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.3215e-06 - val_accuracy: 0.5878 - val_loss: 0.1140\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9976 - loss: 1.3940e-04 - val_accuracy: 0.5781 - val_loss: 0.0830\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 317ms/step - accuracy: 0.9781 - loss: 0.0017 - val_accuracy: 0.5531 - val_loss: 0.0730\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9909 - loss: 5.4242e-04 - val_accuracy: 0.5684 - val_loss: 0.0948\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 303ms/step - accuracy: 0.9983 - loss: 1.4667e-04 - val_accuracy: 0.5282 - val_loss: 0.0969\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 0.9989 - loss: 1.3070e-04 - val_accuracy: 0.5773 - val_loss: 0.0910\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 0.9974 - loss: 2.5247e-04 - val_accuracy: 0.5652 - val_loss: 0.0981\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.9992 - loss: 7.5927e-05 - val_accuracy: 0.5765 - val_loss: 0.0985\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 5.0669e-06 - val_accuracy: 0.5443 - val_loss: 0.1045\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 6.4425e-06 - val_accuracy: 0.5676 - val_loss: 0.1092\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 0.9999 - loss: 1.0328e-05 - val_accuracy: 0.5733 - val_loss: 0.1119\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 4.9683e-06 - val_accuracy: 0.5564 - val_loss: 0.1121\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 0.9904 - loss: 8.2577e-04 - val_accuracy: 0.5636 - val_loss: 0.0851\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 330ms/step - accuracy: 0.9905 - loss: 7.2017e-04 - val_accuracy: 0.5588 - val_loss: 0.0924\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9929 - loss: 3.3765e-04 - val_accuracy: 0.5330 - val_loss: 0.0885\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 0.9981 - loss: 1.6440e-04 - val_accuracy: 0.5548 - val_loss: 0.0911\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 0.9997 - loss: 1.6619e-05 - val_accuracy: 0.5652 - val_loss: 0.1032\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "ResNet18 - Training fold 8/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 0.9826 - loss: 0.0019 - val_accuracy: 0.5137 - val_loss: 0.1116\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 330ms/step - accuracy: 0.9948 - loss: 3.3480e-04 - val_accuracy: 0.5097 - val_loss: 0.1269\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 0.9991 - loss: 8.0939e-05 - val_accuracy: 0.4887 - val_loss: 0.1390\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 8.2128e-06 - val_accuracy: 0.5048 - val_loss: 0.1386\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 6.6277e-06 - val_accuracy: 0.5064 - val_loss: 0.1415\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 2.5727e-06 - val_accuracy: 0.5097 - val_loss: 0.1460\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 1.6443e-06 - val_accuracy: 0.5089 - val_loss: 0.1482\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.2406e-06 - val_accuracy: 0.5097 - val_loss: 0.1513\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 8.1067e-07 - val_accuracy: 0.5089 - val_loss: 0.1530\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 8.5612e-07 - val_accuracy: 0.5081 - val_loss: 0.1550\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 7.0507e-07 - val_accuracy: 0.5081 - val_loss: 0.1560\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 5.2587e-07 - val_accuracy: 0.5097 - val_loss: 0.1571\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 3.8579e-07 - val_accuracy: 0.5097 - val_loss: 0.1584\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 5.7208e-07 - val_accuracy: 0.5105 - val_loss: 0.1598\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 4.4100e-07 - val_accuracy: 0.5105 - val_loss: 0.1605\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 4.2243e-07 - val_accuracy: 0.5081 - val_loss: 0.1613\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 2.1297e-07 - val_accuracy: 0.5089 - val_loss: 0.1623\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 4.5107e-07 - val_accuracy: 0.5064 - val_loss: 0.1631\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 2.9785e-07 - val_accuracy: 0.5089 - val_loss: 0.1648\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 2.1016e-07 - val_accuracy: 0.5105 - val_loss: 0.1656\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.5533e-07 - val_accuracy: 0.5089 - val_loss: 0.1657\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 1.3063e-07 - val_accuracy: 0.5129 - val_loss: 0.1677\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 3.8049e-07 - val_accuracy: 0.5137 - val_loss: 0.1667\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 1.5442e-07 - val_accuracy: 0.5097 - val_loss: 0.1690\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.3349e-07 - val_accuracy: 0.5056 - val_loss: 0.1708\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.2156e-07 - val_accuracy: 0.5064 - val_loss: 0.1711\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 7.2776e-08 - val_accuracy: 0.5081 - val_loss: 0.1713\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 1.3862e-07 - val_accuracy: 0.5048 - val_loss: 0.1705\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 7.8713e-08 - val_accuracy: 0.5072 - val_loss: 0.1721\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 5.4065e-08 - val_accuracy: 0.5072 - val_loss: 0.1725\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 6.6016e-08 - val_accuracy: 0.5072 - val_loss: 0.1730\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 5.6874e-08 - val_accuracy: 0.5081 - val_loss: 0.1737\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 5.2041e-08 - val_accuracy: 0.5089 - val_loss: 0.1751\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 6.6162e-08 - val_accuracy: 0.4944 - val_loss: 0.1730\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 6.9227e-08 - val_accuracy: 0.5056 - val_loss: 0.1742\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 5.5914e-08 - val_accuracy: 0.5072 - val_loss: 0.1770\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 6.7768e-08 - val_accuracy: 0.5064 - val_loss: 0.1776\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 363ms/step - accuracy: 0.9943 - loss: 5.0262e-04 - val_accuracy: 0.4887 - val_loss: 0.2408\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.9550 - loss: 0.0026 - val_accuracy: 0.5072 - val_loss: 0.0921\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.9910 - loss: 4.7317e-04 - val_accuracy: 0.5097 - val_loss: 0.1249\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.9997 - loss: 3.9607e-05 - val_accuracy: 0.5161 - val_loss: 0.1454\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 6.3023e-06 - val_accuracy: 0.4903 - val_loss: 0.1482\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 8.6629e-06 - val_accuracy: 0.5072 - val_loss: 0.1525\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 2.8500e-06 - val_accuracy: 0.5137 - val_loss: 0.1548\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 2.0656e-06 - val_accuracy: 0.5129 - val_loss: 0.1565\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 1.6256e-06 - val_accuracy: 0.5121 - val_loss: 0.1588\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 1.9830e-06 - val_accuracy: 0.5016 - val_loss: 0.1613\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 9.7892e-07 - val_accuracy: 0.5040 - val_loss: 0.1640\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 6.3714e-07 - val_accuracy: 0.5072 - val_loss: 0.1644\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 1.6755e-06 - val_accuracy: 0.5121 - val_loss: 0.1640\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step\n",
      "ResNet18 - Training fold 9/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 357ms/step - accuracy: 0.9737 - loss: 0.0019 - val_accuracy: 0.5599 - val_loss: 0.1097\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 362ms/step - accuracy: 0.9872 - loss: 7.5264e-04 - val_accuracy: 0.5495 - val_loss: 0.0859\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 0.9937 - loss: 3.0907e-04 - val_accuracy: 0.5817 - val_loss: 0.1129\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 0.9977 - loss: 1.3176e-04 - val_accuracy: 0.5551 - val_loss: 0.1273\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 0.9993 - loss: 3.2568e-05 - val_accuracy: 0.5213 - val_loss: 0.1148\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.9999 - loss: 1.5849e-05 - val_accuracy: 0.5543 - val_loss: 0.1297\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 4.2039e-06 - val_accuracy: 0.5438 - val_loss: 0.1316\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 2.1969e-06 - val_accuracy: 0.5414 - val_loss: 0.1334\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 2.6425e-06 - val_accuracy: 0.5430 - val_loss: 0.1355\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 1.7163e-06 - val_accuracy: 0.5471 - val_loss: 0.1384\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 8.8202e-07 - val_accuracy: 0.5430 - val_loss: 0.1398\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 9.0675e-07 - val_accuracy: 0.5447 - val_loss: 0.1399\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 9.5750e-07 - val_accuracy: 0.5422 - val_loss: 0.1423\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 5.7561e-07 - val_accuracy: 0.5447 - val_loss: 0.1431\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 5.7521e-07 - val_accuracy: 0.5447 - val_loss: 0.1440\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 1.0110e-06 - val_accuracy: 0.5414 - val_loss: 0.1444\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 1.1490e-06 - val_accuracy: 0.5213 - val_loss: 0.1498\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 5.8321e-07 - val_accuracy: 0.5326 - val_loss: 0.1495\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 3.3193e-07 - val_accuracy: 0.5350 - val_loss: 0.1499\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 2.5620e-07 - val_accuracy: 0.5374 - val_loss: 0.1498\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 2.6499e-07 - val_accuracy: 0.5326 - val_loss: 0.1509\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 4.7301e-07 - val_accuracy: 0.5366 - val_loss: 0.1521\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 1.0382e-06 - val_accuracy: 0.5422 - val_loss: 0.1503\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 2.1709e-07 - val_accuracy: 0.5406 - val_loss: 0.1532\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 3.9505e-07 - val_accuracy: 0.5527 - val_loss: 0.1573\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 1.9084e-07 - val_accuracy: 0.5551 - val_loss: 0.1578\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 1.0000 - loss: 1.0246e-07 - val_accuracy: 0.5519 - val_loss: 0.1575\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 320ms/step - accuracy: 1.0000 - loss: 1.9058e-07 - val_accuracy: 0.5503 - val_loss: 0.1571\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 1.3577e-07 - val_accuracy: 0.5535 - val_loss: 0.1586\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 7.1335e-08 - val_accuracy: 0.5487 - val_loss: 0.1593\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 5.9145e-08 - val_accuracy: 0.5487 - val_loss: 0.1591\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 1.0992e-07 - val_accuracy: 0.5479 - val_loss: 0.1593\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 2.9851e-07 - val_accuracy: 0.5511 - val_loss: 0.1609\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 7.6197e-08 - val_accuracy: 0.5479 - val_loss: 0.1618\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 5.0880e-08 - val_accuracy: 0.5471 - val_loss: 0.1620\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 5.8582e-08 - val_accuracy: 0.5471 - val_loss: 0.1626\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 4.4762e-08 - val_accuracy: 0.5495 - val_loss: 0.1633\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 323ms/step - accuracy: 1.0000 - loss: 3.9548e-08 - val_accuracy: 0.5463 - val_loss: 0.1636\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 5.8594e-08 - val_accuracy: 0.5447 - val_loss: 0.1642\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 7.2254e-08 - val_accuracy: 0.5463 - val_loss: 0.1643\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 4.5487e-08 - val_accuracy: 0.5479 - val_loss: 0.1655\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 380ms/step - accuracy: 1.0000 - loss: 3.2407e-08 - val_accuracy: 0.5479 - val_loss: 0.1659\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 2.9223e-08 - val_accuracy: 0.5463 - val_loss: 0.1667\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 5.7460e-08 - val_accuracy: 0.5455 - val_loss: 0.1672\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 3.3466e-08 - val_accuracy: 0.5471 - val_loss: 0.1672\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 2.9118e-08 - val_accuracy: 0.5479 - val_loss: 0.1693\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 2.4156e-08 - val_accuracy: 0.5471 - val_loss: 0.1697\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 2.5682e-08 - val_accuracy: 0.5455 - val_loss: 0.1697\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 4.4148e-08 - val_accuracy: 0.5455 - val_loss: 0.1702\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 4.9276e-08 - val_accuracy: 0.5414 - val_loss: 0.1712\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step\n",
      "ResNet18 - Training fold 10/10\n",
      "Epoch 1/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.9575 - loss: 0.0037 - val_accuracy: 0.5290 - val_loss: 0.0648\n",
      "Epoch 2/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.9683 - loss: 0.0022 - val_accuracy: 0.5064 - val_loss: 0.0959\n",
      "Epoch 3/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 0.9893 - loss: 8.1249e-04 - val_accuracy: 0.5322 - val_loss: 0.0997\n",
      "Epoch 4/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.9847 - loss: 0.0013 - val_accuracy: 0.5322 - val_loss: 0.1083\n",
      "Epoch 5/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 0.9979 - loss: 1.9478e-04 - val_accuracy: 0.5193 - val_loss: 0.1207\n",
      "Epoch 6/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 0.9992 - loss: 4.3148e-05 - val_accuracy: 0.5322 - val_loss: 0.1341\n",
      "Epoch 7/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 335ms/step - accuracy: 0.9999 - loss: 1.4711e-05 - val_accuracy: 0.5338 - val_loss: 0.1371\n",
      "Epoch 8/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 335ms/step - accuracy: 0.9998 - loss: 1.9146e-05 - val_accuracy: 0.5330 - val_loss: 0.1342\n",
      "Epoch 9/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 7.3807e-06 - val_accuracy: 0.5330 - val_loss: 0.1407\n",
      "Epoch 10/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 3.6031e-06 - val_accuracy: 0.5322 - val_loss: 0.1446\n",
      "Epoch 11/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 3.8734e-06 - val_accuracy: 0.5338 - val_loss: 0.1484\n",
      "Epoch 12/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6000s\u001b[0m 39s/step - accuracy: 1.0000 - loss: 2.3088e-06 - val_accuracy: 0.5346 - val_loss: 0.1516\n",
      "Epoch 13/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 371ms/step - accuracy: 0.9996 - loss: 1.6638e-05 - val_accuracy: 0.5330 - val_loss: 0.1569\n",
      "Epoch 14/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 3.5995e-06 - val_accuracy: 0.5209 - val_loss: 0.1585\n",
      "Epoch 15/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 2.0936e-06 - val_accuracy: 0.5298 - val_loss: 0.1618\n",
      "Epoch 16/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 1.2336e-06 - val_accuracy: 0.5298 - val_loss: 0.1596\n",
      "Epoch 17/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 363ms/step - accuracy: 0.9916 - loss: 7.0122e-04 - val_accuracy: 0.5290 - val_loss: 0.0682\n",
      "Epoch 18/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 354ms/step - accuracy: 0.9867 - loss: 8.9091e-04 - val_accuracy: 0.5338 - val_loss: 0.0971\n",
      "Epoch 19/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 0.9969 - loss: 1.6695e-04 - val_accuracy: 0.5475 - val_loss: 0.1168\n",
      "Epoch 20/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 2.5902e-05 - val_accuracy: 0.5370 - val_loss: 0.1341\n",
      "Epoch 21/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 4.4786e-06 - val_accuracy: 0.5483 - val_loss: 0.1402\n",
      "Epoch 22/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 3.2219e-06 - val_accuracy: 0.5499 - val_loss: 0.1433\n",
      "Epoch 23/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 2.6535e-06 - val_accuracy: 0.5427 - val_loss: 0.1435\n",
      "Epoch 24/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 3.5458e-06 - val_accuracy: 0.5411 - val_loss: 0.1461\n",
      "Epoch 25/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 3.7334e-06 - val_accuracy: 0.5403 - val_loss: 0.1485\n",
      "Epoch 26/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 1.5142e-06 - val_accuracy: 0.5419 - val_loss: 0.1505\n",
      "Epoch 27/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 1.3054e-06 - val_accuracy: 0.5451 - val_loss: 0.1496\n",
      "Epoch 28/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.9736 - loss: 0.0022 - val_accuracy: 0.5097 - val_loss: 0.1256\n",
      "Epoch 29/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.9904 - loss: 6.7006e-04 - val_accuracy: 0.5596 - val_loss: 0.1165\n",
      "Epoch 30/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 0.9982 - loss: 9.4712e-05 - val_accuracy: 0.5290 - val_loss: 0.1353\n",
      "Epoch 31/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.9993 - loss: 2.1336e-05 - val_accuracy: 0.5467 - val_loss: 0.1409\n",
      "Epoch 32/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 1.0407e-05 - val_accuracy: 0.5298 - val_loss: 0.1435\n",
      "Epoch 33/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 6.0049e-06 - val_accuracy: 0.5298 - val_loss: 0.1443\n",
      "Epoch 34/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 1.9045e-06 - val_accuracy: 0.5282 - val_loss: 0.1452\n",
      "Epoch 35/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 1.2733e-06 - val_accuracy: 0.5282 - val_loss: 0.1465\n",
      "Epoch 36/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 9.0888e-07 - val_accuracy: 0.5290 - val_loss: 0.1490\n",
      "Epoch 37/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 6.9780e-07 - val_accuracy: 0.5298 - val_loss: 0.1504\n",
      "Epoch 38/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 4.6247e-06 - val_accuracy: 0.5330 - val_loss: 0.1575\n",
      "Epoch 39/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 1.8833e-06 - val_accuracy: 0.5201 - val_loss: 0.1574\n",
      "Epoch 40/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 9.8086e-07 - val_accuracy: 0.5250 - val_loss: 0.1589\n",
      "Epoch 41/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 5.8142e-07 - val_accuracy: 0.5258 - val_loss: 0.1592\n",
      "Epoch 42/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 6.6017e-07 - val_accuracy: 0.5298 - val_loss: 0.1604\n",
      "Epoch 43/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 3.2635e-07 - val_accuracy: 0.5266 - val_loss: 0.1610\n",
      "Epoch 44/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 2.0320e-07 - val_accuracy: 0.5258 - val_loss: 0.1620\n",
      "Epoch 45/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 2.9021e-07 - val_accuracy: 0.5266 - val_loss: 0.1634\n",
      "Epoch 46/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 7.6058e-07 - val_accuracy: 0.5258 - val_loss: 0.1636\n",
      "Epoch 47/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 1.3222e-07 - val_accuracy: 0.5225 - val_loss: 0.1633\n",
      "Epoch 48/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 2.4202e-07 - val_accuracy: 0.5266 - val_loss: 0.1651\n",
      "Epoch 49/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 4.4021e-07 - val_accuracy: 0.5266 - val_loss: 0.1661\n",
      "Epoch 50/50\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 5.5325e-07 - val_accuracy: 0.5556 - val_loss: 0.1502\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n",
      "\n",
      "ResNet18 Average Results:\n",
      "Average Sensitivity: 0.7273\n",
      "Average Specificity: 0.9143\n",
      "Average Score: 0.8208\n",
      "Average Accuracy: 0.7804\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Focal loss definition\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon())\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1.0 - y_pred, gamma) * y_true\n",
    "        return tf.reduce_mean(alpha * weight * cross_entropy)\n",
    "    return focal_loss_fn\n",
    "\n",
    "# ResNet block\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1):\n",
    "    y = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = tf.keras.activations.relu(y)\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    if stride > 1 or x.shape[-1] != filters:\n",
    "        x = Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
    "    return tf.keras.activations.relu(Add()([x, y]))\n",
    "\n",
    "# ResNet18 model\n",
    "def build_resnet18(input_shape=(75, 50, 1), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 128, stride=2)\n",
    "    x = resnet_block(x, 128)\n",
    "    x = resnet_block(x, 256, stride=2)\n",
    "    x = resnet_block(x, 256)\n",
    "    x = resnet_block(x, 512, stride=2)\n",
    "    x = resnet_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ResNet50 model\n",
    "def build_resnet50(input_shape=(75, 50, 3), num_classes=4):\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Fine-tune the last 40 layers\n",
    "    for layer in base_model.layers[:-40]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[-40:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define paths\n",
    "base_dir = r\"D:\\Main Project\\Respiratory_Sound_Database\\Respiratory_Sound_Database\"\n",
    "spectrograms_dir = os.path.join(base_dir, \"spectrograms\")\n",
    "\n",
    "# Load spectrograms and labels\n",
    "spectrograms_resized = np.load(os.path.join(spectrograms_dir, \"spectrograms_resized.npy\"))\n",
    "labels = np.load(os.path.join(spectrograms_dir, \"labels.npy\"))\n",
    "patient_ids = np.load(os.path.join(spectrograms_dir, \"patient_ids.npy\"))\n",
    "\n",
    "# Convert 1-channel spectrograms to 3 channels for ResNet50 compatibility\n",
    "spectrograms_resized_3ch = np.repeat(spectrograms_resized, 3, axis=-1)\n",
    "\n",
    "# Prepare data\n",
    "labels_one_hot = tf.keras.utils.to_categorical(labels, num_classes=4)\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "folds = list(gkf.split(spectrograms_resized, labels, groups=patient_ids))\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true_classes = np.argmax(y_true, axis=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    sensitivity = np.mean(TP / (TP + FN + 1e-10))\n",
    "    specificity = np.mean(TN / (TN + FP + 1e-10))\n",
    "    score = (sensitivity + specificity) / 2\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    return sensitivity, specificity, score, accuracy\n",
    "\n",
    "# Train and evaluate both models\n",
    "models = {'ResNet50': build_resnet50(input_shape=(75, 50, 3)),'ResNet18': build_resnet18()}\n",
    "histories = {'ResNet18': [], 'ResNet50': []}\n",
    "metrics = {'ResNet18': {'sensitivity': [], 'specificity': [], 'score': [], 'accuracy': []},\n",
    "           'ResNet50': {'sensitivity': [], 'specificity': [], 'score': [], 'accuracy': []}}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(gamma=2.0), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train = spectrograms_resized[train_idx] if model_name == 'ResNet18' else spectrograms_resized_3ch[train_idx]\n",
    "        X_test = spectrograms_resized[test_idx] if model_name == 'ResNet18' else spectrograms_resized_3ch[test_idx]\n",
    "        y_train, y_test = labels_one_hot[train_idx], labels_one_hot[test_idx]\n",
    "        \n",
    "        print(f\"{model_name} - Training fold {fold_idx + 1}/10\")\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "        histories[model_name].append(history.history)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        sensitivity, specificity, score, accuracy = compute_metrics(y_test, y_pred)\n",
    "        \n",
    "        metrics[model_name]['sensitivity'].append(sensitivity)\n",
    "        metrics[model_name]['specificity'].append(specificity)\n",
    "        metrics[model_name]['score'].append(score)\n",
    "        metrics[model_name]['accuracy'].append(accuracy)\n",
    "\n",
    "    print(f\"\\n{model_name} Average Results:\")\n",
    "    print(f\"Average Sensitivity: {np.mean(metrics[model_name]['sensitivity']):.4f}\")\n",
    "    print(f\"Average Specificity: {np.mean(metrics[model_name]['specificity']):.4f}\")\n",
    "    print(f\"Average Score: {np.mean(metrics[model_name]['score']):.4f}\")\n",
    "    print(f\"Average Accuracy: {np.mean(metrics[model_name]['accuracy']):.4f}\")\n",
    "\n",
    "# Plotting functions\n",
    "def plot_metrics(histories, model_name, metric_type):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Find the minimum number of epochs across all folds\n",
    "    min_epochs = min(len(h[metric_type]) for h in histories)\n",
    "    avg_train = np.mean([h[metric_type][:min_epochs] for h in histories], axis=0)\n",
    "    avg_val = np.mean([h[f'val_{metric_type}'][:min_epochs] for h in histories], axis=0)\n",
    "    \n",
    "    plt.plot(avg_train, label=f'Average Training {metric_type.capitalize()}')\n",
    "    plt.plot(avg_val, label=f'Average Validation {metric_type.capitalize()}')\n",
    "    plt.title(f'{model_name} - Average {metric_type.capitalize()} Across Folds')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_type.capitalize())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot for both models\n",
    "for model_name in ['ResNet18', 'ResNet50']:\n",
    "    plot_metrics(histories[model_name], model_name, 'accuracy')\n",
    "    plot_metrics(histories[model_name], model_name, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
